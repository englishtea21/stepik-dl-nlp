{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import scipy"
      ],
      "metadata": {
        "id": "fMtS7MiZjnnz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'Казнить нельзя, помиловать. Нельзя наказывать.',\n",
        "    'Казнить, нельзя помиловать. Нельзя освободить.',\n",
        "    'Нельзя не помиловать.',\n",
        "    'Обязательно освободить.']"
      ],
      "metadata": {
        "id": "KHHckg5HjvwH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Получаем счетчики слов\n",
        "TF = CountVectorizer().fit_transform(corpus)\n",
        "\n",
        "#Строим IDF. К сожалению, в этом задании нам нужно только vectorizer.idf_\n",
        "#Для стандартных случаев на этой строке все вычисления и заканчиваются.\n",
        "#Обычно  TFIDF = vectorizer.fit_transform(corpus)\n",
        "vectorizer = TfidfVectorizer(smooth_idf=False, use_idf=True)\n",
        "vectorizer.fit_transform(corpus)\n",
        "\n",
        "## из IDF  в DF\n",
        "word_doc_freq = 1/np.exp(vectorizer.idf_ - 1)"
      ],
      "metadata": {
        "id": "HjEFcSePjtHG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_doc_freq, vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VczER9kNaSyd",
        "outputId": "f2011545-9da3-45af-ac39-b528df30960f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.5 , 0.25, 0.25, 0.75, 0.25, 0.5 , 0.75]),\n",
              " {'казнить': 0,\n",
              "  'нельзя': 3,\n",
              "  'помиловать': 6,\n",
              "  'наказывать': 1,\n",
              "  'освободить': 5,\n",
              "  'не': 2,\n",
              "  'обязательно': 4})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF нормируем и сглаживаем логарифмом (требование задания)\n",
        "TFIDF = np.log1p(TF/TF.sum(axis=1)) / word_doc_freq\n"
      ],
      "metadata": {
        "id": "hC2xc1N8ZjlG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TFIDF.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXabOYoTZ4Lj",
        "outputId": "ef9813b7-625f-408b-d129-c27fa72b729c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.36464311, 0.72928623, 0.        , 0.44862965, 0.        ,\n",
              "        0.        , 0.24309541],\n",
              "       [0.36464311, 0.        , 0.        , 0.44862965, 0.        ,\n",
              "        0.36464311, 0.24309541],\n",
              "       [0.        , 0.        , 1.15072829, 0.3835761 , 0.        ,\n",
              "        0.        , 0.3835761 ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.62186043,\n",
              "        0.81093022, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Масштабируем признаки\n",
        "# тут задача немного искусственная, поэтому применяю toarray, чтобы нормализовать с вычитанием среднего.\n",
        "# просто для sparse matrix standardscaler работает вез вычитания среднего\n",
        "scaledTFIDF = StandardScaler().fit_transform(TFIDF.toarray())"
      ],
      "metadata": {
        "id": "80tWYLeMZo4H"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Домножаем на np.sqrt((4-1)/4) для перевода из DDOF(0) в DDOF(1) для 4 текстов\n",
        "#(требование задания)\n",
        "scaledTFIDF *= np.sqrt((len(corpus)-1)/len(corpus))\n",
        "\n",
        "#Вывод в порядке возрастания DF\n",
        "for l in scaledTFIDF[:,np.argsort(word_doc_freq)]:\n",
        "    print (\" \".join([ \"%.2f\" % d for d in l]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_4ZIyrwZ2Iq",
        "outputId": "9fdb8d1f-e20e-45d3-aff5-227f8282470f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.50 -0.50 -0.50 0.87 -0.76 0.60 0.16\n",
            "-0.50 -0.50 -0.50 0.87 0.18 0.60 0.16\n",
            "-0.50 1.50 -0.50 -0.87 -0.76 0.29 1.04\n",
            "-0.50 -0.50 1.50 -0.87 1.34 -1.48 -1.36\n"
          ]
        }
      ]
    }
  ]
}