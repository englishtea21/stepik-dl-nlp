{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Word2Vec","metadata":{"id":"-dLZ_Q-RQFhm"}},{"cell_type":"code","source":"# Если Вы запускаете ноутбук на colab или kaggle,\n# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n\n!git clone https://github.com/englishtea21/stepik-dl-nlp.git\n!pip install -r stepik-dl-nlp/requirements.txt\nimport sys;","metadata":{"id":"zymom8xfQFho","executionInfo":{"status":"ok","timestamp":1721216614138,"user_tz":-180,"elapsed":143407,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"a9319b80-130d-4f37-d380-cef972fe2732","execution":{"iopub.status.busy":"2024-07-21T15:12:36.786087Z","iopub.execute_input":"2024-07-21T15:12:36.786563Z","iopub.status.idle":"2024-07-21T15:13:41.161040Z","shell.execute_reply.started":"2024-07-21T15:12:36.786513Z","shell.execute_reply":"2024-07-21T15:13:41.159952Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"fatal: destination path 'stepik-dl-nlp' already exists and is not an empty directory.\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 1)) (1.2.2)\nCollecting spacy-udpipe (from -r stepik-dl-nlp/requirements.txt (line 2))\n  Downloading spacy_udpipe-1.0.0-py3-none-any.whl.metadata (5.5 kB)\nCollecting pymorphy2 (from -r stepik-dl-nlp/requirements.txt (line 3))\n  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: torch>=1.2 in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 4)) (2.1.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 5)) (3.7.5)\nCollecting ipymarkup (from -r stepik-dl-nlp/requirements.txt (line 6))\n  Downloading ipymarkup-0.9.0-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 7)) (5.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 8)) (1.11.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 9)) (2.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 10)) (4.66.4)\nCollecting youtokentome (from -r stepik-dl-nlp/requirements.txt (line 11))\n  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 12)) (0.12.2)\nRequirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 13)) (6.28.0)\nRequirement already satisfied: ipython in /opt/conda/lib/python3.10/site-packages (from -r stepik-dl-nlp/requirements.txt (line 14)) (8.20.0)\nCollecting pyconll (from -r stepik-dl-nlp/requirements.txt (line 15))\n  Downloading pyconll-3.2.0-py3-none-any.whl.metadata (8.0 kB)\nCollecting gensim==3.8.1 (from -r stepik-dl-nlp/requirements.txt (line 16))\n  Downloading gensim-3.8.1.tar.gz (23.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting wget (from -r stepik-dl-nlp/requirements.txt (line 17))\n  Downloading wget-3.2.zip (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting livelossplot==0.5.3 (from -r stepik-dl-nlp/requirements.txt (line 18))\n  Downloading livelossplot-0.5.3-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.10/site-packages (from gensim==3.8.1->-r stepik-dl-nlp/requirements.txt (line 16)) (1.26.4)\nRequirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from gensim==3.8.1->-r stepik-dl-nlp/requirements.txt (line 16)) (1.16.0)\nRequirement already satisfied: smart_open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim==3.8.1->-r stepik-dl-nlp/requirements.txt (line 16)) (6.4.0)\nRequirement already satisfied: bokeh in /opt/conda/lib/python3.10/site-packages (from livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (3.4.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (3.2.0)\nRequirement already satisfied: spacy<4.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.7.5)\nCollecting ufal.udpipe>=1.2.0 (from spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2))\n  Downloading ufal.udpipe-1.3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting dawg-python>=0.7.1 (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3))\n  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\nCollecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3))\n  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.10/site-packages (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3)) (0.6.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (2024.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.9.0.post0)\nCollecting intervaltree>=3 (from ipymarkup->-r stepik-dl-nlp/requirements.txt (line 6))\n  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r stepik-dl-nlp/requirements.txt (line 9)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->-r stepik-dl-nlp/requirements.txt (line 9)) (2023.4)\nRequirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.10/site-packages (from youtokentome->-r stepik-dl-nlp/requirements.txt (line 11)) (8.1.7)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (0.2.1)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (1.8.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.7.1)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (0.1.6)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (1.5.8)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.9.3)\nRequirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (6.3.3)\nRequirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.9.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.19.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (3.0.42)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (2.17.2)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.8.0)\nRequirement already satisfied: sortedcontainers<3.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from intervaltree>=3->ipymarkup->-r stepik-dl-nlp/requirements.txt (line 6)) (2.4.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.8.3)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (0.4)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (3.11.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.2.13)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.12.3)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.5.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (69.0.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.4.0)\nRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (6.0.1)\nRequirement already satisfied: xyzservices>=2021.09.1 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (2024.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (2.1.3)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.2.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (1.3.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.2.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2024.7.4)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.1.4)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (13.7.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.18.1)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.1.2)\nDownloading livelossplot-0.5.3-py3-none-any.whl (30 kB)\nDownloading spacy_udpipe-1.0.0-py3-none-any.whl (11 kB)\nDownloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\nDownloading pyconll-3.2.0-py3-none-any.whl (27 kB)\nDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\nDownloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ufal.udpipe-1.3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (936 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m936.8/936.8 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: gensim, youtokentome, wget, intervaltree\n  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gensim: filename=gensim-3.8.1-cp310-cp310-linux_x86_64.whl size=23986009 sha256=f60b7411b796ebc5926d0857db38ece4822b61a59578f385fea8c70187c92053\n  Stored in directory: /root/.cache/pip/wheels/92/23/5d/b5ce54b3760acfebee170a8fe4d91cb303fafbefd8f93f3723\n  Building wheel for youtokentome (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp310-cp310-linux_x86_64.whl size=187956 sha256=96049135675a4b6bd69fc84cbca28c35de3ed5c808e32ec3ecdb8991238983d1\n  Stored in directory: /root/.cache/pip/wheels/df/85/f8/301d2ba45f43f30bed2fe413efa760bc726b8b660ed9c2900c\n  Building wheel for wget (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=bbea3974656ddff7237c718c380b9b0d2a9d003e5d81ce0c4dfdf2ae0caa4bd0\n  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26095 sha256=2651114f1dfa850fc7902470c54a519b0387c0c11af00b94cb3158dfdbf5b019\n  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\nSuccessfully built gensim youtokentome wget intervaltree\nInstalling collected packages: wget, ufal.udpipe, pymorphy2-dicts-ru, dawg-python, youtokentome, pymorphy2, pyconll, intervaltree, ipymarkup, gensim, livelossplot, spacy-udpipe\n  Attempting uninstall: gensim\n    Found existing installation: gensim 4.3.2\n    Uninstalling gensim-4.3.2:\n      Successfully uninstalled gensim-4.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nscattertext 0.1.19 requires gensim>=4.0.0, but you have gensim 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dawg-python-0.7.2 gensim-3.8.1 intervaltree-3.1.0 ipymarkup-0.9.0 livelossplot-0.5.3 pyconll-3.2.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 spacy-udpipe-1.0.0 ufal.udpipe-1.3.1.1 wget-3.2 youtokentome-1.0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"# %cd /content/stepik-dl-nlp\n%cd /kaggle/working/stepik-dl-nlp","metadata":{"id":"L64MeARwUFr2","executionInfo":{"status":"ok","timestamp":1721216614637,"user_tz":-180,"elapsed":507,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"d174aade-5aa3-4dc2-bdae-f115180e99ad","execution":{"iopub.status.busy":"2024-07-21T15:13:41.163203Z","iopub.execute_input":"2024-07-21T15:13:41.163574Z","iopub.status.idle":"2024-07-21T15:13:41.174407Z","shell.execute_reply.started":"2024-07-21T15:13:41.163519Z","shell.execute_reply":"2024-07-21T15:13:41.173041Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/stepik-dl-nlp\n","output_type":"stream"}]},{"cell_type":"code","source":"# from google.colab import userdata\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()","metadata":{"id":"8SbLn5NGZmxE","execution":{"iopub.status.busy":"2024-07-21T15:13:41.175807Z","iopub.execute_input":"2024-07-21T15:13:41.176124Z","iopub.status.idle":"2024-07-21T15:13:41.192456Z","shell.execute_reply.started":"2024-07-21T15:13:41.176097Z","shell.execute_reply":"2024-07-21T15:13:41.191605Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# !git remote remove origin\n# !git remote add origin https://englishtea21:{userdata.get('stepik-samsung-nlp-github-token')}@github.com/englishtea21/stepik-dl-nlp.git\n!git remote remove origin\n!git remote add origin https://englishtea21:{user_secrets.get_secret('stepik-samsung-nlp-github-token')}@github.com/englishtea21/stepik-dl-nlp.git","metadata":{"id":"CUR3TeM9T4Ep","execution":{"iopub.status.busy":"2024-07-21T15:13:41.194836Z","iopub.execute_input":"2024-07-21T15:13:41.195206Z","iopub.status.idle":"2024-07-21T15:13:43.395333Z","shell.execute_reply.started":"2024-07-21T15:13:41.195176Z","shell.execute_reply":"2024-07-21T15:13:43.394210Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!git config --global user.email \"englishtea21@mail.ru\"\n!git config --global user.name \"englishtea21\"\n","metadata":{"id":"8wi0SkDqWhXV","execution":{"iopub.status.busy":"2024-07-21T15:13:43.396762Z","iopub.execute_input":"2024-07-21T15:13:43.397041Z","iopub.status.idle":"2024-07-21T15:13:45.371800Z","shell.execute_reply.started":"2024-07-21T15:13:43.397015Z","shell.execute_reply":"2024-07-21T15:13:45.370709Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!git status","metadata":{"id":"gfTbfuKeOUzv","executionInfo":{"status":"ok","timestamp":1721213889429,"user_tz":-180,"elapsed":510,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"2f5380c7-2eb8-4fa6-f119-5c04c3f4286e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nimport random\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nimport dlnlputils\nfrom dlnlputils.data import tokenize_corpus, build_vocabulary, texts_to_token_ids, \\\n    PaddedSequenceDataset, Embeddings\nfrom dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\nfrom dlnlputils.visualization import plot_vectors\n\ninit_random_seed()","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:30.785285Z","start_time":"2019-10-29T19:19:29.542846Z"},"id":"hDNC0HJQQFhp","execution":{"iopub.status.busy":"2024-07-21T15:13:45.373583Z","iopub.execute_input":"2024-07-21T15:13:45.374391Z","iopub.status.idle":"2024-07-21T15:13:54.046065Z","shell.execute_reply.started":"2024-07-21T15:13:45.374359Z","shell.execute_reply":"2024-07-21T15:13:54.045026Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка данных и подготовка корпуса","metadata":{"id":"uVIJHTFGQFhp"}},{"cell_type":"code","source":"# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\nfull_dataset = list(pd.read_csv('./datasets/nyt-ingredients-snapshot-2015.csv')['input'].dropna())\nrandom.shuffle(full_dataset)\n\nTRAIN_VAL_SPLIT = int(len(full_dataset) * 0.7)\ntrain_source = full_dataset[:TRAIN_VAL_SPLIT]\ntest_source = full_dataset[TRAIN_VAL_SPLIT:]\nprint(\"Обучающая выборка\", len(train_source))\nprint(\"Тестовая выборка\", len(test_source))\nprint()\nprint('\\n'.join(train_source[:10]))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:31.270503Z","start_time":"2019-10-29T19:19:30.787789Z"},"id":"FZxoyZDjQFhp","executionInfo":{"status":"ok","timestamp":1721215250674,"user_tz":-180,"elapsed":980,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"fb01585a-5811-44d8-ce48-de6ca1c88922"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# токенизируем\ntrain_tokenized = tokenize_corpus(train_source)\ntest_tokenized = tokenize_corpus(test_source)\nprint('\\n'.join(' '.join(sent) for sent in train_tokenized[:10]))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.137838Z","start_time":"2019-10-29T19:19:31.272363Z"},"id":"Z9eOg0nBQFhq","executionInfo":{"status":"ok","timestamp":1721215255332,"user_tz":-180,"elapsed":1095,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"2e72cc75-6439-427f-9049-1c29cd0c344a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# строим словарь\n# Вводим фиктивный токен паддинга для того, чтобы в дальнейшем можно было объединить предложения разной длины в один прямоугольный тензор\nPAD_WORD = '<PAD>'\nvocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=0.9, min_count=5, pad_word=PAD_WORD)\nprint(\"Размер словаря\", len(vocabulary))\nprint(list(vocabulary.items())[:10])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.325205Z","start_time":"2019-10-29T19:19:32.140837Z"},"id":"8h2oImf_QFhq","executionInfo":{"status":"ok","timestamp":1721215255871,"user_tz":-180,"elapsed":541,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"5c6038e9-d27d-4fb8-edd9-f5a06008e388"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# отображаем в номера токенов\ntrain_token_ids = texts_to_token_ids(train_tokenized, vocabulary)\ntest_token_ids = texts_to_token_ids(test_tokenized, vocabulary)\n\nprint('\\n'.join(' '.join(str(t) for t in sent)\n                for sent in train_token_ids[:10]))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.686258Z","start_time":"2019-10-29T19:19:32.327711Z"},"id":"EGWGfdffQFhq","executionInfo":{"status":"ok","timestamp":1721215256963,"user_tz":-180,"elapsed":539,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"6005ee39-4489-426f-a0da-7955d40b3384"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist([len(s) for s in train_token_ids], bins=20);\nplt.title('Гистограмма длин предложений');","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.967989Z","start_time":"2019-10-29T19:19:32.688319Z"},"id":"71Mwdzv1QFhq","executionInfo":{"status":"ok","timestamp":1721213903747,"user_tz":-180,"elapsed":658,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"a45ea981-e7bf-46f1-af73-b28960dccc0d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Видим что большая часть предожений укладывается в 20 токенов","metadata":{"id":"yhJMU981Rtn8"}},{"cell_type":"code","source":"MAX_SENTENCE_LEN = 20\n# Представляем корупс текстов в виже прямоугольной матрицы предложений,\n# выравниваем длину предложений фиктивным словом\ntrain_dataset = PaddedSequenceDataset(train_token_ids,\n                                      np.zeros(len(train_token_ids)),\n                                      out_len=MAX_SENTENCE_LEN, pad_value=vocabulary[PAD_WORD])\ntest_dataset = PaddedSequenceDataset(test_token_ids,\n                                     np.zeros(len(test_token_ids)),\n                                     out_len=MAX_SENTENCE_LEN, pad_value=vocabulary[PAD_WORD])\nprint(train_dataset[0])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.001487Z","start_time":"2019-10-29T19:19:32.970153Z"},"id":"OYd7JgQmQFhq","executionInfo":{"status":"ok","timestamp":1721215262744,"user_tz":-180,"elapsed":620,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"65db262c-d8ea-4702-efbb-75575c30df7f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Алгоритм обучения - Skip Gram Negative Sampling\n\n**Skip Gram** - предсказываем соседние слова по центральному слову\n\n**Negative Sampling** - аппроксимация softmax\n\n$$ W, D \\in \\mathbb{R}^{Vocab \\times EmbSize} $$\n\n$$ \\sum_{CenterW_i} P(CtxW_{-2}, CtxW_{-1}, CtxW_{+1}, CtxW_{+2} | CenterW_i; W, D) \\rightarrow \\max_{W,D} $$\n\n$$ P(CtxW_{-2}, CtxW_{-1}, CtxW_{+1}, CtxW_{+2} | CenterW_i; W, D) = \\prod_j P(CtxW_j | CenterW_i; W, D) $$\n    \n$$ P(CtxW_j | CenterW_i; W, D) = \\frac{e^{w_i \\cdot d_j}} { \\sum_{j=1}^{|V|} e^{w_i \\cdot d_j}} = softmax \\simeq \\frac{e^{w_i \\cdot d_j^+}} { \\sum_{j=1}^{k} e^{w_i \\cdot d_j^-}}, \\quad k \\ll |V| $$","metadata":{"id":"WRS_38Q9QFhq"}},{"cell_type":"code","source":"def make_diag_mask(size, radius):\n    \"\"\"Квадратная матрица размера Size x Size с двумя полосами ширины radius вдоль главной диагонали\"\"\"\n    # Этой маской мы задаем все возможные контекстные окна на нашем предложении\n    idxs = torch.arange(size)\n    abs_idx_diff = (idxs.unsqueeze(0) - idxs.unsqueeze(1)).abs()\n    mask = ((abs_idx_diff <= radius) & (abs_idx_diff > 0)).float()\n    return mask\n\nmake_diag_mask(10, 3)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.065376Z","start_time":"2019-10-29T19:19:33.003081Z"},"id":"3FzJWtiLQFhq","executionInfo":{"status":"ok","timestamp":1721216626343,"user_tz":-180,"elapsed":10,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"7bad78d8-79ce-4879-8f29-11fbb59afac9","execution":{"iopub.status.busy":"2024-07-21T15:13:54.047625Z","iopub.execute_input":"2024-07-21T15:13:54.048411Z","iopub.status.idle":"2024-07-21T15:13:54.192257Z","shell.execute_reply.started":"2024-07-21T15:13:54.048383Z","shell.execute_reply":"2024-07-21T15:13:54.191363Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"tensor([[0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n        [1., 1., 0., 1., 1., 1., 0., 0., 0., 0.],\n        [1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n        [0., 1., 1., 1., 0., 1., 1., 1., 0., 0.],\n        [0., 0., 1., 1., 1., 0., 1., 1., 1., 0.],\n        [0., 0., 0., 1., 1., 1., 0., 1., 1., 1.],\n        [0., 0., 0., 0., 1., 1., 1., 0., 1., 1.],\n        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1.],\n        [0., 0., 0., 0., 0., 0., 1., 1., 1., 0.]])"},"metadata":{}}]},{"cell_type":"markdown","source":"**Negative Sampling** работает следующим образом - мы **максимизируем сумму вероятностей двух событий**:\n\n* \"этот пример центрального слова вместе с контекстными словами взят **из тренировочной выборки**\": $$ P(y=1 | CenterW_i; CtxW_j) = sigmoid(w_i \\cdot d_j) = \\frac{1}{1+e^{-w_i \\cdot d_j}} $$\n\n$$ \\\\ $$\n\n* \"этот пример центрального слова вместе со случайми контекстными словами **выдуман** \": $$ P(y=0 | CenterW_i; CtxW_{noise}) = 1 - P(y=1 | CenterW_i;  CtxW_{noise}) = \\frac{1}{1+e^{w_i \\cdot d_{noise}}} $$\n\n$$ \\\\ $$\n\n$$ NEG(CtxW_j, CenterW_i) = log(\\frac{1}{1+e^{-w_i \\cdot d_j}}) + \\sum_{l=1}^{k}log(\\frac{1}{1+e^{w_i \\cdot d_{noise_l}}})  \\rightarrow \\max_{W,D} $$","metadata":{"id":"x6kHg7yhQFhq"}},{"cell_type":"code","source":"class SkipGramNegativeSamplingTrainer(nn.Module):\n    def __init__(self, vocab_size, emb_size, sentence_len, radius=5, negative_samples_n=5):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.negative_samples_n = negative_samples_n\n\n        # Эмбеддинги центральных слов\n        # указываем индекс для паддинга, чтобы показать, что его учить не нужно\n        self.center_emb = nn.Embedding(self.vocab_size, emb_size, padding_idx=vocabulary[PAD_WORD])\n        # Такая инициализация эмбеддингов равномерным шумом нужна для поддержиния инварианта того, что норма векторов = 1\n        self.center_emb.weight.data.uniform_(-1.0 / emb_size, 1.0 / emb_size)\n        self.center_emb.weight.data[vocabulary[PAD_WORD]] = 0\n\n        # Эмбеддинги контекстных слов\n        self.context_emb = nn.Embedding(self.vocab_size, emb_size, padding_idx=vocabulary[PAD_WORD])\n        self.context_emb.weight.data.uniform_(-1.0 / emb_size, 1.0 / emb_size)\n        self.context_emb.weight.data[vocabulary[PAD_WORD]] = 0\n\n        # маска для выделения всевозможных контекстных окон заданного радиуса во всех предложения при обучении\n        self.positive_sim_mask = make_diag_mask(sentence_len, radius)\n\n    def forward(self, sentences):\n        \"\"\"sentences - Batch x MaxSentLength - идентификаторы токенов\"\"\"\n        batch_size = sentences.shape[0]\n\n        #получает на вход LongTensor с idx (т.е. индексами токенов), возвращает тензор + 1 измерения\n        #в котором индексы заменены на соответствующие им embedding'и (это центральные слова)\n        #Итого(для batch=1): мы получаем тензор предложения фиксированной длины, где каждое слово\n        #заменено на embedding из центральных слов, все отсутствующие слова (нет в словаре или\n        #закончилось реальное предложение), заменяются на embedding из 0\n        center_embeddings = self.center_emb(sentences)  # Batch x MaxSentLength x EmbSize\n\n\n        ### оценить сходство с настоящими соседними словами\n\n        #получает на вход LongTensor с idx (т.е. индексами токенов), возвращает тензор + 1 измерения\n        #в котором индексы заменены на соответствующие им embedding'и, (это контекстные слова)\n        #дополнительно транспонируем для целей последующего тензорного (матричного) умножения\n        #Итого(для batch=1): мы получаем тензор предложения фиксированной длины, где каждое слово\n        #заменено на embedding из контекстных слов, все отсутствующие слова (нет в словаре или\n        #закончилось реальное предложение), заменяются на embedding из 0\n        positive_context_embs = self.context_emb(sentences).permute(0, 2, 1)  # Batch x EmbSize x MaxSentLength\n\n        #перемножение тензоров, по сути, скалярное произведение эмбеддингов,\n        #Важно отметить, что изначально я предполагал, что эта операция равносильна нахождению косинусных расстояний,\n        #т.к. на основе анализа итоговых эмбеддингов, сделал неверный вывод, что длина каждого из векторов уже здесь = 1\n        #(т.е. они сразу нормализуются в пределах каждого embedding (например внутри класса torch.nn.Embedding),\n        #но это не так, нормализация происходит уже после полного обучения модели, через передачу весов в конструктор\n        #созданного вручную класса Embedding)\n        #Итого(для batch=1): мы получаем матрицу MaxSentLength x MaxSentLength, скалярных произведений,\n        #между векторами каждого центрального слова и каждого контекстного слова (значения [-inf; inf])\n        positive_sims = torch.bmm(center_embeddings, positive_context_embs)  # Batch x MaxSentLength x MaxSentLength\n\n        #преобразуем в \"условные вероятности\" через взятие сигмоиды, т.е. получаем как бы\n        #\"условные вероятности\" встретить пары слов вместе, по факту для каждой пары, скалярное произведение,\n        #обернутое в сигмоиду и как следствие в диапазон значений (0; 1)\n        positive_probs = torch.sigmoid(positive_sims)\n\n\n        ### увеличить оценку вероятности встретить эти пары слов вместе\n\n        #переводим тензор self.positive_sim_mask на тот же девайс, на котором positive_sims\n        positive_mask = self.positive_sim_mask.to(positive_sims.device)\n\n        #.expand_as - Expand this tensor to the same size as other.\n        #self.expand_as(other) is equivalent to self.expand(other.size())\n        #positive_probs * positive_mask - мы оставляем только позиции пересечения центральных слов в контекстными,\n        #все остальные позиции зануляются\n        #подсчитываем бинарную кросс энтропию вычисленных \"условных вероятностей\" (сигмоид) и целевых = 1 для всех\n        #пересечений центральных и контекстных слов, все остальные позиции в обоих матрицах = 0\n        #Примечание: т.к. по умолчанию BCEloss в реализации torch высчитывает итоговое значение как 'mean',\n        #а не 'sum' из всех полученных, то количество 0 так же влияет на итоговое значение, имеет ли это какой\n        #то эффект, и измениться ли что то, если выставить reduction='sum', не очевидно и нужно проверять на практике\n        #Примечание: для всех позиций, которые занулены, их эмбеддинги соответствуют эмбеддинг-вектору с idx=0, для\n        #для которого мы при создании мы указали паддинг nn.Embedding(..., padding_idx=0), это означает, что эти веса\n        #фиксированы, и не подлежат изменению через градиентных шаг\n        #\n        #Итого: важно понимать, что если бы оптимизировали только данную loss функцию, без отрицательных примеров,\n        #которые идут ниже, то, все сводилось бы к тому, что минимальное значение loss было бы, если бы мы все\n        #вектора (и центральных слов и контекстных) устремили бы в бесконечность, в одном направлении (например всем\n        #их весам присвоили бы значение inf или любые подобные варианты)\n        positive_loss = F.binary_cross_entropy(positive_probs * positive_mask,\n                                               positive_mask.expand_as(positive_probs))\n\n\n        ### выбрать случайные \"отрицательные\" слова\n        # важно отметить что есть много подходов выбора отрицательных слов, иногда учитывают их частотность\n        negative_words = torch.randint(1, self.vocab_size,\n                                       size=(batch_size, self.negative_samples_n),\n                                       device=sentences.device)  # Batch x NegSamplesN\n        negative_context_embs = self.context_emb(negative_words).permute(0, 2, 1)  # Batch x EmbSize x NegSamplesN\n        negative_sims = torch.bmm(center_embeddings, negative_context_embs)  # Batch x MaxSentLength x NegSamplesN\n\n        ### уменьшить оценку вероятность встретить эти пары слов вместе\n        #Важно отметить, что BCEWithLogitsLoss равносильна последовательному применению Sigmoid -> BCELoss\n        #но в реализации torch она является более численно стабильной, чем раздельное применение\n        #Итого: здесь все целевые (target) значения = 0, и если бы мы минимизировали только эту loss функцию, то минимальное\n        #ее значение было бы, если бы мы устремили все вектора центральных слов в бесконечность одного направления,\n        #а вектора контекстных слов в бесконечность противоположного направления\n        negative_loss = F.binary_cross_entropy_with_logits(negative_sims,\n                                                           negative_sims.new_zeros(negative_sims.shape))\n\n        return positive_loss + negative_loss\n\n\ndef no_loss(pred, target):\n    \"\"\"Фиктивная функция потерь - когда модель сама считает функцию потерь\"\"\"\n    return pred","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.101379Z","start_time":"2019-10-29T19:19:33.068154Z"},"id":"M6X7R_vrQFhr","execution":{"iopub.status.busy":"2024-07-21T15:13:54.262565Z","iopub.execute_input":"2024-07-21T15:13:54.263031Z","iopub.status.idle":"2024-07-21T15:13:54.332720Z","shell.execute_reply.started":"2024-07-21T15:13:54.262999Z","shell.execute_reply":"2024-07-21T15:13:54.331863Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Обучение","metadata":{"id":"AETNISiPQFhr"}},{"cell_type":"code","source":"trainer = SkipGramNegativeSamplingTrainer(len(vocabulary), 100, MAX_SENTENCE_LEN,\n                                          radius=5, negative_samples_n=25)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.130307Z","start_time":"2019-10-29T19:19:33.103036Z"},"id":"okef7tgxQFhr","executionInfo":{"status":"error","timestamp":1721216626953,"user_tz":-180,"elapsed":7,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"5eed3ae9-a8b1-4ceb-af23-623d122e0974"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss, best_model = train_eval_loop(trainer,\n                                            train_dataset,\n                                            test_dataset,\n                                            no_loss,\n                                            lr=1e-2,\n                                            epoch_n=10,\n                                            batch_size=16,\n                                            device='cuda',\n                                            early_stopping_patience=10,\n                                            max_batches_per_epoch_train=2000,\n                                            max_batches_per_epoch_val=len(test_dataset),\n                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=1, verbose=True))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.830221Z","start_time":"2019-10-29T19:19:33.132062Z"},"id":"lblCRlVnQFhr","executionInfo":{"status":"ok","timestamp":1721213995373,"user_tz":-180,"elapsed":91002,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"7cff8404-8d26-4dc7-928e-151c5a258ed4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\ntorch.save(trainer.state_dict(), './models/task2_word_embeddings/custom_sgns.pth')","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.862018Z","start_time":"2019-10-29T19:20:12.832046Z"},"id":"JcpgVXdVQFhr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  !unzip models.zip","metadata":{"id":"zVR57IvLIdb0","executionInfo":{"status":"ok","timestamp":1720873059871,"user_tz":-180,"elapsed":272,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"58dc889c-a727-4dc1-f4ad-93d9cbc9fe2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\ntrainer.load_state_dict(torch.load('./models/task2_word_embeddings/custom_sgns.pth'))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.888270Z","start_time":"2019-10-29T19:20:12.864706Z"},"id":"T1vFyB_zQFhr","executionInfo":{"status":"ok","timestamp":1721214024186,"user_tz":-180,"elapsed":476,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"d85b673e-5d74-4b54-cc88-2c21540cccce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  !zip -r models.zip models/","metadata":{"id":"KFRbC4KpGj9M","executionInfo":{"status":"ok","timestamp":1720790446082,"user_tz":-180,"elapsed":406,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"ada0588a-c3b1-4557-98b5-4ef2cba3eb78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git status","metadata":{"id":"U2KjabZqNGYw","executionInfo":{"status":"ok","timestamp":1721214086091,"user_tz":-180,"elapsed":355,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"2994d5da-83f4-4834-8361-ffbd22871588"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git add models/task2_word_embeddings/","metadata":{"id":"y96Uy24LPwsj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git commit -m 'Word embeddings save baseline model'","metadata":{"id":"rfNkjPOpP1rT","executionInfo":{"status":"ok","timestamp":1721214091099,"user_tz":-180,"elapsed":389,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"986315e9-57a5-449f-ca43-6b3a4a6cdae2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git push --set-upstream origin main","metadata":{"id":"uJm-ehhWQdQp","executionInfo":{"status":"ok","timestamp":1721214124814,"user_tz":-180,"elapsed":3498,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"fd014452-ae1c-43a9-ac74-7aea2a90f992"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Исследуем характеристики полученных векторов","metadata":{"id":"2PM1RDsHQFhr"}},{"cell_type":"code","source":"embeddings = Embeddings(trainer.center_emb.weight.detach().cpu().numpy(), vocabulary)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.919904Z","start_time":"2019-10-29T19:20:12.890671Z"},"id":"7o34WlofQFhr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings.most_similar('chicken')","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.942708Z","start_time":"2019-10-29T19:20:12.921619Z"},"id":"7_UffvqfQFhr","executionInfo":{"status":"ok","timestamp":1721214253325,"user_tz":-180,"elapsed":341,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"21fb2a13-122b-44c9-9342-a0fc50714265"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings.analogy('cake', 'cacao', 'cheese')","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.965936Z","start_time":"2019-10-29T19:20:12.944423Z"},"id":"niUS0CkoQFhs","executionInfo":{"status":"ok","timestamp":1721214261208,"user_tz":-180,"elapsed":370,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"9558a956-6fae-4c93-b476-199492736b4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_words = ['salad', 'fish', 'salmon', 'sauvignon', 'beef', 'pork', 'steak', 'beer', 'cake', 'coffee', 'sausage', 'wine', 'merlot', 'zinfandel', 'trout', 'chardonnay', 'champagne', 'cacao']\ntest_vectors = embeddings.get_vectors(*test_words)\nprint(test_vectors.shape)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.991060Z","start_time":"2019-10-29T19:20:12.967532Z"},"id":"WfbtmoCIQFhs","executionInfo":{"status":"ok","timestamp":1721214273991,"user_tz":-180,"elapsed":506,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"8afac024-605f-4095-9dcc-ee71e6599059"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches((10, 10))\nplot_vectors(test_vectors, test_words, how='svd', ax=ax)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:13.318676Z","start_time":"2019-10-29T19:20:12.996595Z"},"id":"-jWsJxiLQFhs","executionInfo":{"status":"ok","timestamp":1721214277635,"user_tz":-180,"elapsed":873,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"4f6f11ca-74d1-4bd6-f3db-e6d056cb9c05"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение Word2Vec с помощью Gensim","metadata":{"id":"bLGF8c0uQFhs"}},{"cell_type":"code","source":"!pip install -U gensim","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:13.613797Z","start_time":"2019-10-29T19:20:13.321353Z"},"id":"mX75lg1sQFhs","executionInfo":{"status":"ok","timestamp":1721215289299,"user_tz":-180,"elapsed":14855,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"658ea9ce-da89-483f-c607-f87ba36e345f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim","metadata":{"id":"fuvmBfGQZAIw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word2vec = gensim.models.Word2Vec(sentences=train_tokenized, vector_size=100,\n                                  window=5, min_count=5, workers=4,\n                                  sg=1, epochs=10)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:17.075005Z","start_time":"2019-10-29T19:20:13.615729Z"},"id":"UCx267leQFhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word2vec.wv.most_similar('chicken')","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:17.109583Z","start_time":"2019-10-29T19:20:17.076599Z"},"id":"10PemQKnQFhs","executionInfo":{"status":"ok","timestamp":1721215336463,"user_tz":-180,"elapsed":417,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"88beaeb7-23f5-406e-bcc9-b0314480b81e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_words = ['salad', 'fish', 'salmon', 'sauvignon', 'beef', 'pork', 'steak', 'beer', 'cake', 'coffee', 'sausage', 'wine', 'merlot', 'zinfandel', 'trout', 'chardonnay', 'champagne', 'cacao']","metadata":{"id":"XMONOXWyNCPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gensim_words = [w for w in test_words if w in word2vec.wv.key_to_index]\ngensim_vectors = np.stack([word2vec.wv[w] for w in gensim_words])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:17.176357Z","start_time":"2019-10-29T19:20:17.112948Z"},"id":"CGF5DkSnQFhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches((10, 10))\nplot_vectors(gensim_vectors, test_words, how='svd', ax=ax)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:17.428874Z","start_time":"2019-10-29T19:20:17.179311Z"},"id":"DZRcvXMEQFhs","executionInfo":{"status":"ok","timestamp":1721215346046,"user_tz":-180,"elapsed":530,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"07bffeec-89ad-41ff-e67c-6bc5316901f4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка предобученного Word2Vec\n\nИсточники готовых векторов:\n\nhttps://rusvectores.org/ru/ - для русского языка\n\nhttps://wikipedia2vec.github.io/wikipedia2vec/pretrained/ - много разных языков","metadata":{"id":"kR259PXeQFhs"}},{"cell_type":"code","source":"import gensim.downloader as api","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:17.460133Z","start_time":"2019-10-29T19:20:17.430563Z"},"id":"n42rtDjWQFht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"available_models = api.info()['models'].keys()\nprint('\\n'.join(available_models))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:17.980509Z","start_time":"2019-10-29T19:20:17.462239Z"},"id":"_1RCrmc2QFht","executionInfo":{"status":"ok","timestamp":1721215362431,"user_tz":-180,"elapsed":2,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"b205932c-e26c-4107-d5a1-b0d3ff410f50"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Эта модель ниже была обучена кроме просто слов ещё и а биграмах\n- Чтобы такое провернуть, нужно взять достаточно частовстречающиеся вместе пары слов, слить их и сделать из них фиктивное \"слово\"","metadata":{"id":"RnCkZTbuO3xt"}},{"cell_type":"code","source":"pretrained = api.load('word2vec-google-news-300')  # > 1.5 GB!","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:22:12.649035Z","start_time":"2019-10-29T19:20:17.984118Z"},"id":"mjg98urCQFht","executionInfo":{"status":"ok","timestamp":1721215916096,"user_tz":-180,"elapsed":536079,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"ba8f5684-1ef2-4e2e-fe7b-d75c368822c8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained.most_similar('cheese')","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:22:12.651388Z","start_time":"2019-10-29T19:19:29.817Z"},"id":"c2wX0OEQQFht","executionInfo":{"status":"ok","timestamp":1721215924519,"user_tz":-180,"elapsed":7318,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"4932e2ca-241f-49f9-a3c2-9163d7a351a3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained.most_similar(positive=['man', 'queen'], negative=['king'])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:22:12.652649Z","start_time":"2019-10-29T19:19:29.820Z"},"id":"VGLJnfhGQFht","executionInfo":{"status":"ok","timestamp":1721215925125,"user_tz":-180,"elapsed":615,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"02548733-de0f-4073-e9bd-5b1d9d0b9788"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_words = [w for w in test_words if w in pretrained.key_to_index]\npretrained_vectors = np.stack([pretrained[w] for w in pretrained_words])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:22:12.653584Z","start_time":"2019-10-29T19:19:29.823Z"},"id":"fy40x0JUQFht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches((10, 10))\nplot_vectors(pretrained_vectors, test_words, how='svd', ax=ax)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:22:12.654594Z","start_time":"2019-10-29T19:19:29.828Z"},"id":"5025uWuXQFht","executionInfo":{"status":"ok","timestamp":1721215963506,"user_tz":-180,"elapsed":1122,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"cc73e42f-cd28-46fc-842c-f78008b13502"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Заключение\n\n* Реализовали Skip Gram Negative Sampling на PyTorch\n* Обучили на корпусе рецептов\n    * Сходство слов модель выучила неплохо\n    * Для аналогий мало данных\n* Обучили SGNS с помощью библиотеки Gensim\n* Загрузили веса Word2Vec, полученные с помощью большого корпуса (GoogleNews)\n    * Списки похожих слов отличаются!\n    * Аналогии работают","metadata":{"id":"5GZQ2r2aQFhz"}},{"cell_type":"markdown","source":"# TODO:\n1. Узнать как измерять качество построенного эмбеддинга\n2. В качестве домашнего задания мы предлагаем Вам поэкспериментировать с кодом этого семинара, чтобы лучше понять свойства эмбеддингов и попробовать улучшить их качество. Что можно попробовать сделать:\n\n- поиграться с параметрами - количеством отрицательных слов, размером батча, скоростью обучения, размером окна\n- убрать разбиение текстов на предложения и увеличить окно\n- изменить токенизацию, например, разобравшись с библиотекой SpaCy и подключив лемматизацию и POS-теггинг, чтобы строить эмбеддинги не для словоформ, а для лемм (например, chicked_NOUN)\n- реализовать FastText и сравнить, как отличаются списки похожих документов, получаемых с помощью Word2Vec и FastText\n- усложнить алгоритм оценки вероятности совместной встречаемости слов, например, заменив скалярное произведение на нейросеть с парой слоёв\n- Также мы предлагаем Вам не ограничиваться этим списком, а придумать свои способы заставить Word2Vec выучить что-то интересное и полезное.\n\nОпишите то, что у Вас получилось, в ответе к этому шагу.","metadata":{"id":"t0TlJKfBQeq-"}},{"cell_type":"markdown","source":"## Оценка качества эмбеддингов","metadata":{"id":"KZyxGYkg5scm"}},{"cell_type":"code","source":"# import urllib.request\n\n# # Скачивание файла questions-words.txt\n# url = 'https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/word2vec/source-archive.zip'\n# urllib.request.urlretrieve(url, 'word2vec.zip')","metadata":{"id":"Ub9A-4i-QFh0","executionInfo":{"status":"ok","timestamp":1721216653670,"user_tz":-180,"elapsed":365,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"a4c93dec-44f8-449e-948d-0922b7736834","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\n# Распаковка архива\nwith zipfile.ZipFile('datasets/word2vec.zip', 'r') as zip_ref:\n    zip_ref.extractall('datasets/word2vec')","metadata":{"id":"mJR5XwvU8Dec","execution":{"iopub.status.busy":"2024-07-18T10:05:54.045132Z","iopub.execute_input":"2024-07-18T10:05:54.045566Z","iopub.status.idle":"2024-07-18T10:05:54.115852Z","shell.execute_reply.started":"2024-07-18T10:05:54.045535Z","shell.execute_reply":"2024-07-18T10:05:54.114864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# dir_to_delete = 'word2vec'\n# with os.scandir(dir_to_delete) as entries:\n#     for entry in entries:\n#         file_to_delete = f\"{dir_to_delete}{entry.name}\"\n#         if os.path.isfile(file_to_delete):\n#             print(file_to_delete)\n#             os.remove(file_to_delete)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T10:08:31.794032Z","iopub.execute_input":"2024-07-18T10:08:31.794892Z","iopub.status.idle":"2024-07-18T10:08:31.852247Z","shell.execute_reply.started":"2024-07-18T10:08:31.794856Z","shell.execute_reply":"2024-07-18T10:08:31.851224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to parse the text file\ndef parse_file_to_dfs(file_path):\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n\n    dfs = {}\n    current_section = []\n    current_name = None\n\n    for line in lines:\n        line = line.strip()\n        if line.startswith(':'):\n            if current_section:\n                # Convert current section to DataFrame and add to list\n                df = pd.DataFrame([row.split() for row in current_section], columns=[\"1st_a\", \"1st_b\", \"2nd_a\", \"2nd_b\"])\n                dfs[current_name]=df\n                current_section = []\n            current_name = line[1:].strip()  # Get the name of the new data piece\n        else:\n            current_section.append(line)\n\n    # Don't forget to add the last section\n    if current_section:\n        df = pd.DataFrame([row.split() for row in current_section], columns=[\"1st_a\", \"1st_b\", \"2nd_a\", \"2nd_b\"])\n        dfs[current_name]=df\n\n    return dfs","metadata":{"id":"AgjAzgv1DYpx","execution":{"iopub.status.busy":"2024-07-21T15:16:25.396479Z","iopub.execute_input":"2024-07-21T15:16:25.397382Z","iopub.status.idle":"2024-07-21T15:16:25.457888Z","shell.execute_reply.started":"2024-07-21T15:16:25.397345Z","shell.execute_reply":"2024-07-21T15:16:25.456925Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!cp -f word2vec.zip datasets/word2vec.zip","metadata":{"id":"33oLSkh1gjdG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git add datasets","metadata":{"id":"uzaIi2KthEuF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git status","metadata":{"id":"ci3CHZJrhIiq","executionInfo":{"status":"ok","timestamp":1721216838555,"user_tz":-180,"elapsed":359,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"3f1c3b22-a197-4eb3-a52f-67a78ad9d8de"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git commit -m 'word2vec google dataset added'","metadata":{"executionInfo":{"status":"ok","timestamp":1721216857857,"user_tz":-180,"elapsed":404,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"5e5042ed-b147-4e9c-ad6f-0d97b34676bb","id":"QrLraUc6hEuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git push --set-upstream origin main","metadata":{"executionInfo":{"status":"ok","timestamp":1721216870421,"user_tz":-180,"elapsed":1872,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"f7bee733-1864-4cc4-ef73-c7c13d1a4466","id":"AeO7fl8whEuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Чтение файла questions-words.txt\nfile_path = 'datasets/word2vec/word2vec/trunk/questions-words.txt'\n\ngoogle_analogies = parse_file_to_dfs(file_path)","metadata":{"id":"sh8brL1eADAl","execution":{"iopub.status.busy":"2024-07-21T15:16:30.481770Z","iopub.execute_input":"2024-07-21T15:16:30.482133Z","iopub.status.idle":"2024-07-21T15:16:30.589393Z","shell.execute_reply.started":"2024-07-21T15:16:30.482104Z","shell.execute_reply":"2024-07-21T15:16:30.588142Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 1.  Поиграемся с параметрами обучения, уберем разбиение текста на предложения","metadata":{"id":"D-dkJ53BArnT"}},{"cell_type":"markdown","source":"По ощущениям убирать разбиение текста на предложения при обучении имеет смысл, когда эти предложения как-то семантически связаны друг с другом, т.е. когда контекст слова не ограничивается одним предлодением, а какой-то областью текста","metadata":{"id":"Jn0nRdbsTMc5"}},{"cell_type":"markdown","source":"Ну заметим что прошлый датасет для обучения был из очень узкой области - рецепты блюд, там предложения короткие и грамматически скудные, поэтому будем использовать другой","metadata":{"id":"nXXhhY5SEkel"}},{"cell_type":"code","source":"# !unzip imdb_dataset.zip","metadata":{"id":"Uvk8YXlWSw7J","executionInfo":{"status":"ok","timestamp":1720946181049,"user_tz":-180,"elapsed":1204,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"b056a322-6750-42c4-b05e-02714c2c5bb2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_dataset = list(pd.read_csv('datasets/IMDB Dataset.csv')['review'].dropna())\nrandom.shuffle(full_dataset)\n\nTRAIN_VAL_SPLIT = int(len(full_dataset) * 0.7)\ntrain_source = full_dataset[:TRAIN_VAL_SPLIT]\ntest_source = full_dataset[TRAIN_VAL_SPLIT:]\nprint(\"Обучающая выборка\", len(train_source))\nprint(\"Тестовая выборка\", len(test_source))","metadata":{"id":"6O-FbGNpTk2d","executionInfo":{"status":"ok","timestamp":1721216954873,"user_tz":-180,"elapsed":2006,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"4026275d-7af2-4c1a-cca1-94e5fc59015f","execution":{"iopub.status.busy":"2024-07-21T15:16:41.264526Z","iopub.execute_input":"2024-07-21T15:16:41.265398Z","iopub.status.idle":"2024-07-21T15:16:41.999599Z","shell.execute_reply.started":"2024-07-21T15:16:41.265364Z","shell.execute_reply":"2024-07-21T15:16:41.998664Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Обучающая выборка 35000\nТестовая выборка 15000\n","output_type":"stream"}]},{"cell_type":"code","source":"print(''.join(train_source[9]))","metadata":{"id":"IhXQsPTaU8WB","executionInfo":{"status":"ok","timestamp":1721216960862,"user_tz":-180,"elapsed":356,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"01f0a8e2-015e-48ef-91d4-9fc9b4b51e60","execution":{"iopub.status.busy":"2024-07-18T10:29:10.055239Z","iopub.execute_input":"2024-07-18T10:29:10.055631Z","iopub.status.idle":"2024-07-18T10:29:10.119206Z","shell.execute_reply.started":"2024-07-18T10:29:10.055600Z","shell.execute_reply":"2024-07-18T10:29:10.118118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef tokenize_text(txt, TOKEN_RE=re.compile(r'[\\w\\d]+'), min_token_size=2):\n    txt = txt.lower()\n    all_tokens = TOKEN_RE.findall(txt)\n    return [token for token in all_tokens if len(token) >= min_token_size]","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:16:07.965069Z","iopub.execute_input":"2024-07-21T15:16:07.965408Z","iopub.status.idle":"2024-07-21T15:16:08.019435Z","shell.execute_reply.started":"2024-07-21T15:16:07.965381Z","shell.execute_reply":"2024-07-21T15:16:08.018527Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# токенизируем\ntrain_tokenized = tokenize_corpus(train_source, tokenize_text)\ntest_tokenized = tokenize_corpus(test_source, tokenize_text)\nprint('\\n'.join(' '.join(sent) for sent in train_tokenized[:10]))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.137838Z","start_time":"2019-10-29T19:19:31.272363Z"},"executionInfo":{"status":"ok","timestamp":1721216974508,"user_tz":-180,"elapsed":8375,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"79d7f0bd-aa6d-431c-e267-0ac937d22ed1","id":"o6KjW7FuV2b0","execution":{"iopub.status.busy":"2024-07-18T10:35:21.697078Z","iopub.execute_input":"2024-07-18T10:35:21.697467Z","iopub.status.idle":"2024-07-18T10:35:28.853166Z","shell.execute_reply.started":"2024-07-18T10:35:21.697434Z","shell.execute_reply":"2024-07-18T10:35:28.852202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# строим словарь\n# Вводим фиктивный токен паддинга для того, чтобы в дальнейшем можно было объединить предложения разной длины в один прямоугольный тензор\nPAD_WORD = '<PAD>'\nvocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=0.9, min_count=5, pad_word=PAD_WORD)\nprint(\"Размер словаря\", len(vocabulary))\nprint(list(vocabulary.items())[:10])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.325205Z","start_time":"2019-10-29T19:19:32.140837Z"},"executionInfo":{"status":"ok","timestamp":1721216993247,"user_tz":-180,"elapsed":1747,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"692f1a44-fe64-448d-c4f1-4f865ad769d1","id":"MEJspdm_V2b7","execution":{"iopub.status.busy":"2024-07-18T10:35:40.738804Z","iopub.execute_input":"2024-07-18T10:35:40.739773Z","iopub.status.idle":"2024-07-18T10:35:42.476022Z","shell.execute_reply.started":"2024-07-18T10:35:40.739738Z","shell.execute_reply":"2024-07-18T10:35:42.475031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# отображаем в номера токенов\ntrain_token_ids = texts_to_token_ids(train_tokenized, vocabulary)\ntest_token_ids = texts_to_token_ids(test_tokenized, vocabulary)\n\nprint('\\n'.join(' '.join(str(t) for t in sent)\n                for sent in train_token_ids[5:7]))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.686258Z","start_time":"2019-10-29T19:19:32.327711Z"},"executionInfo":{"status":"ok","timestamp":1721216999056,"user_tz":-180,"elapsed":2761,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"3423f89a-ef18-4ade-8c36-1f2f935ee67e","id":"bNz4DdelV2b7","execution":{"iopub.status.busy":"2024-07-18T10:35:49.965035Z","iopub.execute_input":"2024-07-18T10:35:49.965941Z","iopub.status.idle":"2024-07-18T10:35:53.149919Z","shell.execute_reply.started":"2024-07-18T10:35:49.965909Z","shell.execute_reply":"2024-07-18T10:35:53.148980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist([len(s) for s in train_token_ids], bins=20);\nplt.title('Гистограмма длин текстов');","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.967989Z","start_time":"2019-10-29T19:19:32.688319Z"},"executionInfo":{"status":"ok","timestamp":1721217002167,"user_tz":-180,"elapsed":746,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"d0f8e090-7a58-47ed-dc06-094935bf0dea","id":"jor5gRVqV2b7","execution":{"iopub.status.busy":"2024-07-18T10:35:55.931612Z","iopub.execute_input":"2024-07-18T10:35:55.932520Z","iopub.status.idle":"2024-07-18T10:35:56.500153Z","shell.execute_reply.started":"2024-07-18T10:35:55.932486Z","shell.execute_reply":"2024-07-18T10:35:56.499119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_TEXT_LEN = 1250\n# Представляем корупс текстов в виже прямоугольной матрицы текстов,\n# выравниваем длину предложений фиктивным словом\ntrain_dataset = PaddedSequenceDataset(train_token_ids,\n                                      np.zeros(len(train_token_ids)),\n                                      out_len=MAX_TEXT_LEN, pad_value=vocabulary[PAD_WORD])\ntest_dataset = PaddedSequenceDataset(test_token_ids,\n                                     np.zeros(len(test_token_ids)),\n                                     out_len=MAX_TEXT_LEN, pad_value=vocabulary[PAD_WORD])\nprint(train_dataset[0])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.001487Z","start_time":"2019-10-29T19:19:32.970153Z"},"executionInfo":{"status":"ok","timestamp":1721217011658,"user_tz":-180,"elapsed":352,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"10800838-595b-49da-9c87-440f8d2dfc63","id":"-_MuVkOaWzjQ","execution":{"iopub.status.busy":"2024-07-18T10:36:02.749578Z","iopub.execute_input":"2024-07-18T10:36:02.749964Z","iopub.status.idle":"2024-07-18T10:36:02.853856Z","shell.execute_reply.started":"2024-07-18T10:36:02.749935Z","shell.execute_reply":"2024-07-18T10:36:02.852892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SkipGramNegativeSamplingTrainer(len(vocabulary), 100, MAX_TEXT_LEN,\n                                          radius=5, negative_samples_n=25)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.130307Z","start_time":"2019-10-29T19:19:33.103036Z"},"id":"LG2WJJ7GXd-9","execution":{"iopub.status.busy":"2024-07-18T10:36:07.180681Z","iopub.execute_input":"2024-07-18T10:36:07.181522Z","iopub.status.idle":"2024-07-18T10:36:07.365320Z","shell.execute_reply.started":"2024-07-18T10:36:07.181478Z","shell.execute_reply":"2024-07-18T10:36:07.364279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss, best_model = train_eval_loop(trainer,\n                                            train_dataset,\n                                            test_dataset,\n                                            no_loss,\n                                            lr=1e-2,\n                                            epoch_n=10,\n                                            batch_size=8,\n                                            device='cuda',\n                                            early_stopping_patience=10,\n                                            max_batches_per_epoch_train=2000,\n                                            max_batches_per_epoch_val=len(test_dataset),\n                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=1, verbose=True))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.830221Z","start_time":"2019-10-29T19:19:33.132062Z"},"executionInfo":{"status":"ok","timestamp":1721217419082,"user_tz":-180,"elapsed":400112,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"c8f0d588-e52c-486b-f403-8c821478f6ad","id":"pfgKStFrXd-9","execution":{"iopub.status.busy":"2024-07-18T10:36:20.265428Z","iopub.execute_input":"2024-07-18T10:36:20.266096Z","iopub.status.idle":"2024-07-18T10:40:33.237161Z","shell.execute_reply.started":"2024-07-18T10:36:20.266057Z","shell.execute_reply":"2024-07-18T10:40:33.236099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\ntorch.save(trainer.state_dict(), 'models/task2_word_embeddings/imdb_sgns_word_emb_baseline.pth')","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.862018Z","start_time":"2019-10-29T19:20:12.832046Z"},"id":"MTkSy3sVXd-9","execution":{"iopub.status.busy":"2024-07-18T10:40:38.332835Z","iopub.execute_input":"2024-07-18T10:40:38.333717Z","iopub.status.idle":"2024-07-18T10:40:38.439475Z","shell.execute_reply.started":"2024-07-18T10:40:38.333682Z","shell.execute_reply":"2024-07-18T10:40:38.438458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git add models","metadata":{"execution":{"iopub.status.busy":"2024-07-18T10:40:48.225188Z","iopub.execute_input":"2024-07-18T10:40:48.225579Z","iopub.status.idle":"2024-07-18T10:40:50.805616Z","shell.execute_reply.started":"2024-07-18T10:40:48.225548Z","shell.execute_reply":"2024-07-18T10:40:50.804334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git status","metadata":{"execution":{"iopub.status.busy":"2024-07-18T10:40:58.183945Z","iopub.execute_input":"2024-07-18T10:40:58.184332Z","iopub.status.idle":"2024-07-18T10:40:59.902673Z","shell.execute_reply.started":"2024-07-18T10:40:58.184305Z","shell.execute_reply":"2024-07-18T10:40:59.901516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git commit -m \"task2_word_emb_baseline added\"","metadata":{"execution":{"iopub.status.busy":"2024-07-18T10:41:40.516708Z","iopub.execute_input":"2024-07-18T10:41:40.517769Z","iopub.status.idle":"2024-07-18T10:41:41.655006Z","shell.execute_reply.started":"2024-07-18T10:41:40.517729Z","shell.execute_reply":"2024-07-18T10:41:41.653998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" !git push --set-upstream origin main","metadata":{"execution":{"iopub.status.busy":"2024-07-18T10:44:01.590322Z","iopub.execute_input":"2024-07-18T10:44:01.590991Z","iopub.status.idle":"2024-07-18T10:44:07.189112Z","shell.execute_reply.started":"2024-07-18T10:44:01.590956Z","shell.execute_reply":"2024-07-18T10:44:07.187800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  !unzip models.zip","metadata":{"executionInfo":{"status":"ok","timestamp":1720873059871,"user_tz":-180,"elapsed":272,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"58dc889c-a727-4dc1-f4ad-93d9cbc9fe2a","id":"3SiCgVoEXd-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\ntrainer.load_state_dict(torch.load('models/task2_word_embeddings/imdb_sgns_word_emb_baseline.pth'))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.888270Z","start_time":"2019-10-29T19:20:12.864706Z"},"executionInfo":{"status":"ok","timestamp":1721217465436,"user_tz":-180,"elapsed":360,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"0681f8f2-af0f-4cd4-e5cb-2ca9f3df7c39","id":"8k6GCWzbXd--","execution":{"iopub.status.busy":"2024-07-18T10:47:28.537611Z","iopub.execute_input":"2024-07-18T10:47:28.537991Z","iopub.status.idle":"2024-07-18T10:47:28.620805Z","shell.execute_reply.started":"2024-07-18T10:47:28.537962Z","shell.execute_reply":"2024-07-18T10:47:28.619879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  !zip -r models.zip models/","metadata":{"executionInfo":{"status":"ok","timestamp":1720790446082,"user_tz":-180,"elapsed":406,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"ada0588a-c3b1-4557-98b5-4ef2cba3eb78","id":"Lqd1K-9FXd--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[topic for (topic, _) in google_analogies.items()]","metadata":{"id":"v8LKy9XurHcD","executionInfo":{"status":"ok","timestamp":1721219592151,"user_tz":-180,"elapsed":380,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"a94f5406-9a01-4102-9877-0f1c1688683f","execution":{"iopub.status.busy":"2024-07-18T10:45:07.040584Z","iopub.execute_input":"2024-07-18T10:45:07.041305Z","iopub.status.idle":"2024-07-18T10:45:07.105732Z","shell.execute_reply.started":"2024-07-18T10:45:07.041272Z","shell.execute_reply":"2024-07-18T10:45:07.104720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = Embeddings(trainer.center_emb.weight.detach().cpu().numpy(), vocabulary)","metadata":{"id":"sBn6-pd0jk20","execution":{"iopub.status.busy":"2024-07-18T10:45:09.310016Z","iopub.execute_input":"2024-07-18T10:45:09.310676Z","iopub.status.idle":"2024-07-18T10:45:09.459859Z","shell.execute_reply.started":"2024-07-18T10:45:09.310636Z","shell.execute_reply":"2024-07-18T10:45:09.458653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_embeddings_analogies(embeddings, df_analogies, sample_size=20):\n  assert df_analogies.columns.tolist() == ['1st_a', '1st_b', '2nd_a', '2nd_b']\n  df_sampled = df_analogies.sample(sample_size)\n\n  analogy=[]\n  for first_a, first_b, second_a in zip(df_sampled['1st_a'].values, df_sampled['1st_b'].values, df_sampled['2nd_a'].values):\n    analogy.append(embeddings.analogy(first_a, first_b, second_a, topk=5))\n\n  # print(analogy[0])\n\n  analogy_result = pd.DataFrame(analogy, columns=[f'{i+1}th_word {i+1}th_ranking' for i, (_, _) in enumerate(analogy[0])])\n  analogy_result.index = df_sampled.index\n\n  return pd.concat([df_sampled, analogy_result], axis=1).reset_index(drop=True)\n","metadata":{"id":"2aon5MNckZgN","execution":{"iopub.status.busy":"2024-07-21T15:58:09.032285Z","iopub.execute_input":"2024-07-21T15:58:09.032668Z","iopub.status.idle":"2024-07-21T15:58:09.093236Z","shell.execute_reply.started":"2024-07-21T15:58:09.032636Z","shell.execute_reply":"2024-07-21T15:58:09.092255Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"google_analogies['gram1-adjective-to-adverb']","metadata":{"id":"AAQdfZ3LkNom","executionInfo":{"status":"ok","timestamp":1721219158201,"user_tz":-180,"elapsed":497,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"7035184a-8271-43da-db15-876189952b9a","execution":{"iopub.status.busy":"2024-07-18T10:45:12.834450Z","iopub.execute_input":"2024-07-18T10:45:12.835115Z","iopub.status.idle":"2024-07-18T10:45:12.906156Z","shell.execute_reply.started":"2024-07-18T10:45:12.835082Z","shell.execute_reply":"2024-07-18T10:45:12.905172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_embeddings_analogies(embeddings, google_analogies['gram1-adjective-to-adverb'], sample_size=20)","metadata":{"id":"h5UWKYkmmLz5","executionInfo":{"status":"ok","timestamp":1721219357783,"user_tz":-180,"elapsed":387,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"26feea71-29f8-4408-f6cf-6838cab9cc12","execution":{"iopub.status.busy":"2024-07-18T10:46:03.689586Z","iopub.execute_input":"2024-07-18T10:46:03.689966Z","iopub.status.idle":"2024-07-18T10:46:03.878695Z","shell.execute_reply.started":"2024-07-18T10:46:03.689934Z","shell.execute_reply":"2024-07-18T10:46:03.877771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_embeddings_analogies(embeddings, google_analogies['gram7-past-tense'], sample_size=3)","metadata":{"id":"o3bdvUZOnoAz","executionInfo":{"status":"ok","timestamp":1721219733356,"user_tz":-180,"elapsed":370,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"07e76285-1273-4090-c269-5a5b54bfd69d","execution":{"iopub.status.busy":"2024-07-18T10:46:31.848733Z","iopub.execute_input":"2024-07-18T10:46:31.849170Z","iopub.status.idle":"2024-07-18T10:46:31.953571Z","shell.execute_reply.started":"2024-07-18T10:46:31.849135Z","shell.execute_reply":"2024-07-18T10:46:31.952514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Короже, аналогии на уровне частей речи наша модель не видит вообще :( <br>\nПридется сделать морфемную токенизацию","metadata":{"id":"bJUBAoUasOrK"}},{"cell_type":"code","source":"import random","metadata":{"execution":{"iopub.status.busy":"2024-07-18T10:48:02.884362Z","iopub.execute_input":"2024-07-18T10:48:02.884783Z","iopub.status.idle":"2024-07-18T10:48:02.947614Z","shell.execute_reply.started":"2024-07-18T10:48:02.884752Z","shell.execute_reply":"2024-07-18T10:48:02.946606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_words = ['lullaby', 'hospital', 'wedding', 'fortune', 'horrifying', 'slaughter', 'depression', 'divorce', 'travel', 'abandoned', 'sex', 'betrayal', 'space', 'aircraft']","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:59:01.880093Z","iopub.execute_input":"2024-07-21T15:59:01.880769Z","iopub.status.idle":"2024-07-21T15:59:01.938962Z","shell.execute_reply.started":"2024-07-21T15:59:01.880735Z","shell.execute_reply":"2024-07-21T15:59:01.937953Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"assert set(test_words) <= vocabulary.keys()\ntest_vectors = embeddings.get_vectors(*test_words)\nfig, ax = plt.subplots()\nfig.set_size_inches((10, 10))\nplot_vectors(test_vectors, test_words, how='svd', ax=ax)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T11:00:03.426782Z","iopub.execute_input":"2024-07-18T11:00:03.427500Z","iopub.status.idle":"2024-07-18T11:00:03.763251Z","shell.execute_reply.started":"2024-07-18T11:00:03.427467Z","shell.execute_reply":"2024-07-18T11:00:03.762350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Увеличим радиус при обучении и число отрицательных примеров","metadata":{}},{"cell_type":"code","source":"trainer = SkipGramNegativeSamplingTrainer(len(vocabulary), 100, MAX_TEXT_LEN,\n                                          radius=20, negative_samples_n=50)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.130307Z","start_time":"2019-10-29T19:19:33.103036Z"},"id":"LG2WJJ7GXd-9","execution":{"iopub.status.busy":"2024-07-18T11:00:21.621103Z","iopub.execute_input":"2024-07-18T11:00:21.621961Z","iopub.status.idle":"2024-07-18T11:00:21.806141Z","shell.execute_reply.started":"2024-07-18T11:00:21.621922Z","shell.execute_reply":"2024-07-18T11:00:21.805159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss, best_model = train_eval_loop(trainer,\n                                            train_dataset,\n                                            test_dataset,\n                                            no_loss,\n                                            lr=1e-2,\n                                            epoch_n=10,\n                                            batch_size=8,\n                                            device='cuda',\n                                            early_stopping_patience=10,\n                                            max_batches_per_epoch_train=2000,\n                                            max_batches_per_epoch_val=len(test_dataset),\n                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=1, verbose=True))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.830221Z","start_time":"2019-10-29T19:19:33.132062Z"},"executionInfo":{"status":"ok","timestamp":1721217419082,"user_tz":-180,"elapsed":400112,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"c8f0d588-e52c-486b-f403-8c821478f6ad","id":"pfgKStFrXd-9","execution":{"iopub.status.busy":"2024-07-18T11:00:23.324662Z","iopub.execute_input":"2024-07-18T11:00:23.325344Z","iopub.status.idle":"2024-07-18T11:04:38.002896Z","shell.execute_reply.started":"2024-07-18T11:00:23.325312Z","shell.execute_reply":"2024-07-18T11:04:38.001915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = Embeddings(trainer.center_emb.weight.detach().cpu().numpy(), vocabulary)","metadata":{"id":"sBn6-pd0jk20","execution":{"iopub.status.busy":"2024-07-18T11:05:19.353956Z","iopub.execute_input":"2024-07-18T11:05:19.354986Z","iopub.status.idle":"2024-07-18T11:05:19.439735Z","shell.execute_reply.started":"2024-07-18T11:05:19.354948Z","shell.execute_reply":"2024-07-18T11:05:19.438733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_embeddings_analogies(embeddings, google_analogies['gram1-adjective-to-adverb'], sample_size=20)","metadata":{"id":"h5UWKYkmmLz5","executionInfo":{"status":"ok","timestamp":1721219357783,"user_tz":-180,"elapsed":387,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"26feea71-29f8-4408-f6cf-6838cab9cc12","execution":{"iopub.status.busy":"2024-07-18T11:05:21.608964Z","iopub.execute_input":"2024-07-18T11:05:21.609672Z","iopub.status.idle":"2024-07-18T11:05:21.798920Z","shell.execute_reply.started":"2024-07-18T11:05:21.609638Z","shell.execute_reply":"2024-07-18T11:05:21.798001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_embeddings_analogies(embeddings, google_analogies['gram7-past-tense'], sample_size=10)","metadata":{"id":"o3bdvUZOnoAz","executionInfo":{"status":"ok","timestamp":1721219733356,"user_tz":-180,"elapsed":370,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"07e76285-1273-4090-c269-5a5b54bfd69d","execution":{"iopub.status.busy":"2024-07-18T11:05:33.165234Z","iopub.execute_input":"2024-07-18T11:05:33.166121Z","iopub.status.idle":"2024-07-18T11:05:33.298256Z","shell.execute_reply.started":"2024-07-18T11:05:33.166086Z","shell.execute_reply":"2024-07-18T11:05:33.297256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors = embeddings.get_vectors(*test_words)\nprint(test_vectors.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T11:20:18.495660Z","iopub.execute_input":"2024-07-18T11:20:18.496101Z","iopub.status.idle":"2024-07-18T11:20:18.559864Z","shell.execute_reply.started":"2024-07-18T11:20:18.496068Z","shell.execute_reply":"2024-07-18T11:20:18.558788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches((10, 10))\nplot_vectors(test_vectors, test_words, how='svd', ax=ax)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:13.318676Z","start_time":"2019-10-29T19:20:12.996595Z"},"id":"-jWsJxiLQFhs","executionInfo":{"status":"ok","timestamp":1721214277635,"user_tz":-180,"elapsed":873,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"4f6f11ca-74d1-4bd6-f3db-e6d056cb9c05","execution":{"iopub.status.busy":"2024-07-18T11:20:21.504911Z","iopub.execute_input":"2024-07-18T11:20:21.505300Z","iopub.status.idle":"2024-07-18T11:20:21.908215Z","shell.execute_reply.started":"2024-07-18T11:20:21.505268Z","shell.execute_reply":"2024-07-18T11:20:21.907237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Семантическую связь модель стала ощущать лучше","metadata":{}},{"cell_type":"markdown","source":"## 2. Изменим токенизацию - применим библиотеку spaCy","metadata":{}},{"cell_type":"code","source":"import spacy\n\n# English pipelines include a rule-based lemmatizer\nnlp = spacy.load(\"en_core_web_sm\")\nlemmatizer = nlp.get_pipe(\"lemmatizer\")\nprint(lemmatizer.mode)  # 'rule'\n\ndoc = nlp(\"I was reading the paper.\")\nprint([token.lemma_ for token in doc])","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:25:49.289838Z","iopub.execute_input":"2024-07-21T15:25:49.290827Z","iopub.status.idle":"2024-07-21T15:25:50.391353Z","shell.execute_reply.started":"2024-07-21T15:25:49.290784Z","shell.execute_reply":"2024-07-21T15:25:50.390416Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"rule\n['I', 'be', 'read', 'the', 'paper', '.']\n","output_type":"stream"}]},{"cell_type":"code","source":"full_dataset = list(pd.read_csv('datasets/IMDB Dataset.csv')['review'].dropna())\nrandom.shuffle(full_dataset)\n\nTRAIN_VAL_SPLIT = int(len(full_dataset) * 0.7)\ntrain_source = full_dataset[:TRAIN_VAL_SPLIT]\ntest_source = full_dataset[TRAIN_VAL_SPLIT:]\nprint(\"Обучающая выборка\", len(train_source))\nprint(\"Тестовая выборка\", len(test_source))","metadata":{"id":"6O-FbGNpTk2d","executionInfo":{"status":"ok","timestamp":1721216954873,"user_tz":-180,"elapsed":2006,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"4026275d-7af2-4c1a-cca1-94e5fc59015f","execution":{"iopub.status.busy":"2024-07-21T15:19:14.920187Z","iopub.execute_input":"2024-07-21T15:19:14.921174Z","iopub.status.idle":"2024-07-21T15:19:15.627198Z","shell.execute_reply.started":"2024-07-21T15:19:14.921138Z","shell.execute_reply":"2024-07-21T15:19:15.626230Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Обучающая выборка 35000\nТестовая выборка 15000\n","output_type":"stream"}]},{"cell_type":"code","source":"print(''.join(train_source[9]))","metadata":{"id":"IhXQsPTaU8WB","executionInfo":{"status":"ok","timestamp":1721216960862,"user_tz":-180,"elapsed":356,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"01f0a8e2-015e-48ef-91d4-9fc9b4b51e60","execution":{"iopub.status.busy":"2024-07-18T10:29:10.055239Z","iopub.execute_input":"2024-07-18T10:29:10.055631Z","iopub.status.idle":"2024-07-18T10:29:10.119206Z","shell.execute_reply.started":"2024-07-18T10:29:10.055600Z","shell.execute_reply":"2024-07-18T10:29:10.118118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_source[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:35:16.823026Z","iopub.execute_input":"2024-07-21T15:35:16.823410Z","iopub.status.idle":"2024-07-21T15:35:16.890910Z","shell.execute_reply.started":"2024-07-21T15:35:16.823378Z","shell.execute_reply":"2024-07-21T15:35:16.890098Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'...But not this one! I always wanted to know \"what happened\" next. We will never know for sure what happened because GWTW was Margaret\\'s baby. I am a lifelong fan of Gone With the Wind and I could not have been more repulsed by the movie. I did compare \"Scarlett\" to the original GWTW because any film worth following GWTW needed to be on the same quality level as the first. Rhett was cast beautifully, although NO ONE will ever compare to Mr. Gable. I am also a strict Vivien Leigh fan!! She WAS Scarlett. She fit the bill. Not another actress in this lifetime or another will ever fit the same shoes but with \"Scarlett\" the job could have been done better. Not enough thought went into finding the proper Scarlett, that was evident.<br /><br />Overall, something to look to but if you want to know the what happened to Scarlett and Rhett, I suggest writing it yourself or finding fan fiction. This movie is not worth the time.'"},"metadata":{}}]},{"cell_type":"code","source":"import re\ndef tokenize_text(txt, nlp=nlp):\n    utf8_string = txt.encode('utf-8')\n    \n    txt = txt.lower()\n    \n    pattern = re.compile(r'<[^>]+>?')\n    # Replace all matched HTML tags with an empty string\n    cleaned_text = pattern.sub('', txt)\n    \n    pattern = re.compile(\"\\w+\")\n    return [token.lemma_ for token in nlp(txt) if pattern.match(token.lemma_)]","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:37:36.010975Z","iopub.execute_input":"2024-07-21T15:37:36.011733Z","iopub.status.idle":"2024-07-21T15:37:36.067596Z","shell.execute_reply.started":"2024-07-21T15:37:36.011701Z","shell.execute_reply":"2024-07-21T15:37:36.066582Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"len(train_source)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:41:56.767176Z","iopub.execute_input":"2024-07-21T15:41:56.767864Z","iopub.status.idle":"2024-07-21T15:41:56.822843Z","shell.execute_reply.started":"2024-07-21T15:41:56.767829Z","shell.execute_reply":"2024-07-21T15:41:56.821939Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"35000"},"metadata":{}}]},{"cell_type":"markdown","source":"Лемматизация долгая, поэтому будем использовать не все данные(","metadata":{}},{"cell_type":"code","source":"# %%time\n# train_tokenized = tokenize_corpus(train_source[:1000], tokenize_text)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:47:13.975320Z","iopub.execute_input":"2024-07-21T15:47:13.976023Z","iopub.status.idle":"2024-07-21T15:47:53.205054Z","shell.execute_reply.started":"2024-07-21T15:47:13.975993Z","shell.execute_reply":"2024-07-21T15:47:53.204002Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"CPU times: user 39.2 s, sys: 7.94 ms, total: 39.2 s\nWall time: 39.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"# токенизируем\ntrain_tokenized = tokenize_corpus(train_source[:7000], tokenize_text)\ntest_tokenized = tokenize_corpus(test_source[:3000], tokenize_text)\nprint('\\n'.join(' '.join(sent) for sent in train_tokenized[:5]))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.137838Z","start_time":"2019-10-29T19:19:31.272363Z"},"executionInfo":{"status":"ok","timestamp":1721216974508,"user_tz":-180,"elapsed":8375,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"79d7f0bd-aa6d-431c-e267-0ac937d22ed1","id":"o6KjW7FuV2b0","execution":{"iopub.status.busy":"2024-07-21T15:49:14.336065Z","iopub.execute_input":"2024-07-21T15:49:14.336595Z","iopub.status.idle":"2024-07-21T15:55:58.647893Z","shell.execute_reply.started":"2024-07-21T15:49:14.336560Z","shell.execute_reply":"2024-07-21T15:55:58.646964Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"but not this one I always want to know what happen next we will never know for sure what happen because gwtw be margaret baby I be a lifelong fan of go with the wind and I could not have be more repulse by the movie I do compare scarlett to the original gwtw because any film worth follow gwtw need to be on the same quality level as the first rhett be cast beautifully although no one will ever compare to mr gable I be also a strict vivien leigh fan she be scarlett she fit the bill not another actress in this lifetime or another will ever fit the same shoe but with scarlett the job could have be do well not enough thought go into find the proper scarlett that be evident.<br something to look to but if you want to know the what happen to scarlett and rhett I suggest write it yourself or find fan fiction this movie be not worth the time\nthis be a great movie but it have the bad end I think I have ever see the actor be great and display wonderful talent the entire story be twisted and unexpecting which be what make it entertaining as good as the movie be the entire film be judge by the ending which be terrible maybe a sequel could eliminate this bad ending\nI love julian sand and will at least attempt to watch anything he be in but this movie nearly do I in I be hard press to remember when I find any other movie to move so slow ly zzzzzzzzzzzz br it in the vcr when you have run out of sleep pill\nin 1895 in a small village in japan the wife of the litter carrier gisaburo takahiro tamura seki kazuko yoshiyuki have an affair with a man twenty six year young toyiji tatsuya fuji toyiji become jealous of gisaburo and plot with seki to kill he they strangle gisaburo and dump his body inside a well in the wood and seki tell the local that gisaburo move to tokyo to work three year later the local gossip about the fate of gisaburo and seki be haunt by his ghost the situation become unbearable to seki and toyiji when a police authority come to the village to investigate the disappearance of gisaburo.<br no borei be a surreal and supernatural love story the remorse and the guilty complex of seki make she see the ghost of her murder husband spoil the perfect plot of her lover the cinematography be jeopardize by the quality of the vhs release in brazil but there be very beautiful scene inclusive ringu and the american remake the ring use the view of the well from inside in the same angle the performance and direction be excellent make ai no borei a great movie my vote be eight.<br brazil o império da paixão the empire of passion\nscoop be also the name of a late thirty evelyn waugh novel and woody allen new movie though set today have a nostalgic charm and simplicity it have not the depth of characterization intense performance suspense or shocking final frisson of allen penultimate effort match point argue by many include this reviewer to be a strong return to form but scoop do closely resemble allen last outing in its focus on english aristocrat posh london flat murder and detection this time woody leave behind the arriviste murder mystery genre and return to comedy and be himself back on the screen as an amiable vaudevillian a magician call sid waterman stage moniker the great splendini who counter some snob probe with I use to be of the hebrew persuasion but as I get old I convert to narcissism follow a revelation in the midst of splendini standard dematerialize act with scarlett johansson as sondra pransky the audience volunteer the mismatch pair get draw into a dead ace english journalist post mortem attempt to score one last top news story on the edge of the styx joe strombel ian mcshane have just meet the shade of one lord lyman son secretary who say she be poison and she be tell he the charming aristocratic bounder son peter lyman hugh jackman be the tarot card murderer a london serial killer sondra and sid immediately become a pair of amateur sleuth with sid deadpan wit and sondra bumptious beauty they cut a quick swath through to the cream of the london aristocracy.<br be not paw his young heroine muse as in match point johansson again as in the past this time moreover scarlett not an ambitious sexpot and would be movie star she be morph surprisingly into a klutzy bespectacle but still pretty coe sid and sondra have no flirtation which be a great relief they simply team up more or less politely to carry out strombel wish by befriend lyman and watch he for clue to his guilt with only minimal protest sid consent to appear as sondra dad sondra who be captivate peter by pretend to drown in his club pool re christen herself jade spence mr spence i.e. woody keep break cover by do card trick but he amuse dowager with these and beat their husband at poker spew non stop one liner and all the while maintain apparently with success that he be in oil and precious metal just as jade have tell he to say.<br be about all there be to it or all that can be tell without spoil the story by reveal its outcome at first allen decision to make johansson a gauche naively plainspoken and badly dress college girl seem not just unkind but an all around bad decision but johansson who have pluck and panache as an actress miraculously manage to carry it off help by jackman an actor who know how to make any actress appear desirable if he desire she the film actually create a sense of relationship to make up for it limited range of character sid and sondra spar in a friendly way and peter and sondra have a believable attraction even though it be artificial and tainted she be after all go to bed with a suspect homicidal maniac).<br pall a bit be allen again drool over english wealth and class thing his brooklyn background seem to have leave he despite all his celebrity with a irresistible hankering for jackman be an impressive fellow glamorous and dash his parent be english but could this athletic musical comedy star raise in australia x man wolverine really pass as an aristocrat only in the movie perhaps here and in kate and leopold\").<br be not as strong a film as match point but to say it be a loser as some viewer have be quite wrong it have no more depth than a half hour radio drama or a tv show but woody joke be far funny and more original than you will get in any such medium affair and sometimes they show a return to the old wit and cleverness it do not matter if a movie be silly or slapdash when it be divert summer entertainment on a hot day you do not want a heavy meal the whole thing deliciously evoke a time when movie comedy be really light escapist entertainment without crude joke or bombastic effect without vince vaughan or owen wilson critic be eager to tell you this be a return to the allen decline that precede match point do not believe they he do not try too hard why should he he may be 70 but verbally he be still light on his foot and his body move pretty fast too\n","output_type":"stream"}]},{"cell_type":"code","source":"# строим словарь\n# Вводим фиктивный токен паддинга для того, чтобы в дальнейшем можно было объединить предложения разной длины в один прямоугольный тензор\nPAD_WORD = '<PAD>'\nvocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=0.9, min_count=5, pad_word=PAD_WORD)\nprint(\"Размер словаря\", len(vocabulary))\nprint(list(vocabulary.items())[:10])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.325205Z","start_time":"2019-10-29T19:19:32.140837Z"},"executionInfo":{"status":"ok","timestamp":1721216993247,"user_tz":-180,"elapsed":1747,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"692f1a44-fe64-448d-c4f1-4f865ad769d1","id":"MEJspdm_V2b7","execution":{"iopub.status.busy":"2024-07-21T15:55:58.649939Z","iopub.execute_input":"2024-07-21T15:55:58.650320Z","iopub.status.idle":"2024-07-21T15:55:59.051365Z","shell.execute_reply.started":"2024-07-21T15:55:58.650286Z","shell.execute_reply":"2024-07-21T15:55:59.050341Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Размер словаря 11511\n[('<PAD>', 0), ('this', 1), ('it', 2), ('in', 3), ('not', 4), ('that', 5), ('have', 6), ('I', 7), ('but', 8), ('for', 9)]\n","output_type":"stream"}]},{"cell_type":"code","source":"# отображаем в номера токенов\ntrain_token_ids = texts_to_token_ids(train_tokenized, vocabulary)\ntest_token_ids = texts_to_token_ids(test_tokenized, vocabulary)\n\nprint('\\n'.join(' '.join(str(t) for t in sent)\n                for sent in train_token_ids[5:7]))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.686258Z","start_time":"2019-10-29T19:19:32.327711Z"},"executionInfo":{"status":"ok","timestamp":1721216999056,"user_tz":-180,"elapsed":2761,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"3423f89a-ef18-4ade-8c36-1f2f935ee67e","id":"bNz4DdelV2b7","execution":{"iopub.status.busy":"2024-07-21T15:55:59.052463Z","iopub.execute_input":"2024-07-21T15:55:59.052834Z","iopub.status.idle":"2024-07-21T15:55:59.523112Z","shell.execute_reply.started":"2024-07-21T15:55:59.052807Z","shell.execute_reply":"2024-07-21T15:55:59.522092Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"144 2935 2998 12 5 107 1114 554 1350 5238 434 226 1275 9 150 1432 205 68 4266 221 30 6 110 830 40 3 554 1252 41 18 80 1 15 3975 2878 170 3840 19 344 233 19 5023 1366 337 2554 1098 38 817 1407 3507 2650 10 57 288 20 71 2058 469 6 112 478 136 102 123 150 2466 6557 2077 1378 26 10157 19 469 13 8285 814 57 16 69 9 222 130 43 7045 1035 62 4620 13 1328 6558 1 4 162 388 4 238 7 69 2402 3312 10158 9075 7045 10 43 165 528 94 1350 6 3404 78 336 19 22 12 23 1 50 4 1789 260\n3976 988 472 7046 6560 5241 10159 30 288 567 6559 13 514 3226 3 95 81 88 1164 10 95 1526 4449 6142 2936 93 27 988 138 108 667 577 5242 15 440 2059 8 1525 661 75 86 51 665 329 26 131 30 7047 5242 3718 1394 251 1039 2467 142 26 988 30 74 412 5239 184 552 2608 8 10160 910 5242 899 3616 456 3 211 455 13 28 72 772 329 4621 31 1963 20 988 61 183 25 422 5240 65 509 469 1 324 10 5826 822 212 308 290 64 2651 13 42 8287 1904 190 320 1158 3 624 255 1843 529 1379 275 16 1157 75 47 988 211 3 274 271 2771 1123 661 20 1124 126 349 334 8286 555 235 2508 95 7618 48 823 437 44 6 541 1878 52 10161 5242 1823 65 124 304 180 25 2107 509 13 2 289 39 9 71 125 25 6141 348 6140\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.hist([len(s) for s in train_token_ids], bins=20);\nplt.title('Гистограмма длин текстов');","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:32.967989Z","start_time":"2019-10-29T19:19:32.688319Z"},"executionInfo":{"status":"ok","timestamp":1721217002167,"user_tz":-180,"elapsed":746,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"d0f8e090-7a58-47ed-dc06-094935bf0dea","id":"jor5gRVqV2b7","execution":{"iopub.status.busy":"2024-07-21T15:55:59.524979Z","iopub.execute_input":"2024-07-21T15:55:59.525271Z","iopub.status.idle":"2024-07-21T15:55:59.960482Z","shell.execute_reply.started":"2024-07-21T15:55:59.525247Z","shell.execute_reply":"2024-07-21T15:55:59.959611Z"},"trusted":true},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"MAX_TEXT_LEN = 1250\n# Представляем корупс текстов в виже прямоугольной матрицы текстов,\n# выравниваем длину предложений фиктивным словом\ntrain_dataset = PaddedSequenceDataset(train_token_ids,\n                                      np.zeros(len(train_token_ids)),\n                                      out_len=MAX_TEXT_LEN, pad_value=vocabulary[PAD_WORD])\ntest_dataset = PaddedSequenceDataset(test_token_ids,\n                                     np.zeros(len(test_token_ids)),\n                                     out_len=MAX_TEXT_LEN, pad_value=vocabulary[PAD_WORD])\nprint(train_dataset[0])","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.001487Z","start_time":"2019-10-29T19:19:32.970153Z"},"executionInfo":{"status":"ok","timestamp":1721217011658,"user_tz":-180,"elapsed":352,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"10800838-595b-49da-9c87-440f8d2dfc63","id":"-_MuVkOaWzjQ","execution":{"iopub.status.busy":"2024-07-21T15:56:13.150031Z","iopub.execute_input":"2024-07-21T15:56:13.150394Z","iopub.status.idle":"2024-07-21T15:56:13.207214Z","shell.execute_reply.started":"2024-07-21T15:56:13.150365Z","shell.execute_reply":"2024-07-21T15:56:13.206122Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"(tensor([8, 4, 1,  ..., 0, 0, 0]), tensor(0))\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = SkipGramNegativeSamplingTrainer(len(vocabulary), 100, MAX_TEXT_LEN,\n                                          radius=5, negative_samples_n=25)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:19:33.130307Z","start_time":"2019-10-29T19:19:33.103036Z"},"id":"LG2WJJ7GXd-9","execution":{"iopub.status.busy":"2024-07-21T15:56:15.051420Z","iopub.execute_input":"2024-07-21T15:56:15.051807Z","iopub.status.idle":"2024-07-21T15:56:15.153951Z","shell.execute_reply.started":"2024-07-21T15:56:15.051778Z","shell.execute_reply":"2024-07-21T15:56:15.152954Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"best_val_loss, best_model = train_eval_loop(trainer,\n                                            train_dataset,\n                                            test_dataset,\n                                            no_loss,\n                                            lr=1e-2,\n                                            epoch_n=10,\n                                            batch_size=8,\n                                            device='cuda',\n                                            early_stopping_patience=10,\n                                            max_batches_per_epoch_train=2000,\n                                            max_batches_per_epoch_val=len(test_dataset),\n                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=1, verbose=True))","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:12.830221Z","start_time":"2019-10-29T19:19:33.132062Z"},"executionInfo":{"status":"ok","timestamp":1721217419082,"user_tz":-180,"elapsed":400112,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"c8f0d588-e52c-486b-f403-8c821478f6ad","id":"pfgKStFrXd-9","execution":{"iopub.status.busy":"2024-07-21T15:56:16.952240Z","iopub.execute_input":"2024-07-21T15:56:16.952861Z","iopub.status.idle":"2024-07-21T15:57:43.313218Z","shell.execute_reply.started":"2024-07-21T15:56:16.952830Z","shell.execute_reply":"2024-07-21T15:57:43.312048Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Эпоха 0\nЭпоха: 875 итераций, 7.27 сек\nСреднее значение функции потерь на обучении 0.6233063478469849\nСреднее значение функции потерь на валидации 0.6062196950912475\nНовая лучшая модель!\n\nЭпоха 1\nЭпоха: 875 итераций, 6.76 сек\nСреднее значение функции потерь на обучении 0.6053292680467878\nСреднее значение функции потерь на валидации 0.6060514939626058\nНовая лучшая модель!\n\nЭпоха 2\nЭпоха: 875 итераций, 6.78 сек\nСреднее значение функции потерь на обучении 0.6052793827397482\nСреднее значение функции потерь на валидации 0.6060635798772176\n\nЭпоха 3\nЭпоха: 875 итераций, 6.80 сек\nСреднее значение функции потерь на обучении 0.60525280720847\nСреднее значение функции потерь на валидации 0.6059052815437317\nНовая лучшая модель!\n\nЭпоха 4\nЭпоха: 875 итераций, 6.80 сек\nСреднее значение функции потерь на обучении 0.6051537870679583\nСреднее значение функции потерь на валидации 0.6059467549324036\n\nЭпоха 5\nЭпоха: 875 итераций, 6.78 сек\nСреднее значение функции потерь на обучении 0.6051596865313393\nСреднее значение функции потерь на валидации 0.6058117500940958\nНовая лучшая модель!\n\nЭпоха 6\nЭпоха: 875 итераций, 6.78 сек\nСреднее значение функции потерь на обучении 0.605127878018788\nСреднее значение функции потерь на валидации 0.605778348604838\nНовая лучшая модель!\n\nЭпоха 7\nЭпоха: 875 итераций, 6.79 сек\nСреднее значение функции потерь на обучении 0.6051092319488526\nСреднее значение функции потерь на валидации 0.605841113726298\nEpoch 00008: reducing learning rate of group 0 to 1.0000e-03.\n\nЭпоха 8\nЭпоха: 875 итераций, 6.80 сек\nСреднее значение функции потерь на обучении 0.6049163893972125\nСреднее значение функции потерь на валидации 0.6055884998639425\nНовая лучшая модель!\n\nЭпоха 9\nЭпоха: 875 итераций, 6.91 сек\nСреднее значение функции потерь на обучении 0.6047877843039376\nСреднее значение функции потерь на валидации 0.6055276651382446\nНовая лучшая модель!\n\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings = Embeddings(trainer.center_emb.weight.detach().cpu().numpy(), vocabulary)","metadata":{"id":"sBn6-pd0jk20","execution":{"iopub.status.busy":"2024-07-21T15:57:54.535462Z","iopub.execute_input":"2024-07-21T15:57:54.536076Z","iopub.status.idle":"2024-07-21T15:57:54.601820Z","shell.execute_reply.started":"2024-07-21T15:57:54.536044Z","shell.execute_reply":"2024-07-21T15:57:54.600855Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"check_embeddings_analogies(embeddings, google_analogies['gram1-adjective-to-adverb'], sample_size=20)","metadata":{"id":"h5UWKYkmmLz5","executionInfo":{"status":"ok","timestamp":1721219357783,"user_tz":-180,"elapsed":387,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"26feea71-29f8-4408-f6cf-6838cab9cc12","execution":{"iopub.status.busy":"2024-07-21T15:58:34.056488Z","iopub.execute_input":"2024-07-21T15:58:34.057388Z","iopub.status.idle":"2024-07-21T15:58:34.194403Z","shell.execute_reply.started":"2024-07-21T15:58:34.057356Z","shell.execute_reply":"2024-07-21T15:58:34.193187Z"},"trusted":true},"execution_count":68,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcheck_embeddings_analogies\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoogle_analogies\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgram1-adjective-to-adverb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[62], line 7\u001b[0m, in \u001b[0;36mcheck_embeddings_analogies\u001b[0;34m(embeddings, df_analogies, sample_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m analogy\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m first_a, first_b, second_a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df_sampled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1st_a\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, df_sampled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1st_b\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, df_sampled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2nd_a\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m----> 7\u001b[0m   analogy\u001b[38;5;241m.\u001b[39mappend(\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalogy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(analogy[0])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m analogy_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(analogy, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mth_word \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mth_ranking\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (_, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(analogy[\u001b[38;5;241m0\u001b[39m])])\n","File \u001b[0;32m/kaggle/working/stepik-dl-nlp/dlnlputils/data/embeddings.py:17\u001b[0m, in \u001b[0;36mEmbeddings.analogy\u001b[0;34m(self, a1, b1, a2, topk)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalogy\u001b[39m(\u001b[38;5;28mself\u001b[39m, a1, b1, a2, topk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     16\u001b[0m     a1_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(a1)\n\u001b[0;32m---> 17\u001b[0m     b1_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     a2_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(a2)\n\u001b[1;32m     19\u001b[0m     query \u001b[38;5;241m=\u001b[39m b1_v \u001b[38;5;241m-\u001b[39m a1_v \u001b[38;5;241m+\u001b[39m a2_v\n","File \u001b[0;32m/kaggle/working/stepik-dl-nlp/dlnlputils/data/embeddings.py:31\u001b[0m, in \u001b[0;36mEmbeddings.get_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, word):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2id:\n\u001b[0;32m---> 31\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mНеизвестное слово \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(word))\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2id[word]]\n","\u001b[0;31mValueError\u001b[0m: Неизвестное слово \"cheerfully\""],"ename":"ValueError","evalue":"Неизвестное слово \"cheerfully\"","output_type":"error"}]},{"cell_type":"code","source":"check_embeddings_analogies(embeddings, google_analogies['gram7-past-tense'], sample_size=10)","metadata":{"id":"o3bdvUZOnoAz","executionInfo":{"status":"ok","timestamp":1721219733356,"user_tz":-180,"elapsed":370,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"07e76285-1273-4090-c269-5a5b54bfd69d","execution":{"iopub.status.busy":"2024-07-18T11:05:33.165234Z","iopub.execute_input":"2024-07-18T11:05:33.166121Z","iopub.status.idle":"2024-07-18T11:05:33.298256Z","shell.execute_reply.started":"2024-07-18T11:05:33.166086Z","shell.execute_reply":"2024-07-18T11:05:33.297256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors = embeddings.get_vectors(*test_words)\nprint(test_vectors.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T15:59:13.971889Z","iopub.execute_input":"2024-07-21T15:59:13.972760Z","iopub.status.idle":"2024-07-21T15:59:14.077632Z","shell.execute_reply.started":"2024-07-21T15:59:13.972728Z","shell.execute_reply":"2024-07-21T15:59:14.076429Z"},"trusted":true},"execution_count":74,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_vectors \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtest_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_vectors\u001b[38;5;241m.\u001b[39mshape)\n","File \u001b[0;32m/kaggle/working/stepik-dl-nlp/dlnlputils/data/embeddings.py:35\u001b[0m, in \u001b[0;36mEmbeddings.get_vectors\u001b[0;34m(self, *words)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vectors\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mwords):\n\u001b[0;32m---> 35\u001b[0m     word_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2id[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[1;32m     36\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m word_ids], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectors\n","File \u001b[0;32m/kaggle/working/stepik-dl-nlp/dlnlputils/data/embeddings.py:35\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vectors\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mwords):\n\u001b[0;32m---> 35\u001b[0m     word_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2id\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[1;32m     36\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m word_ids], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectors\n","\u001b[0;31mKeyError\u001b[0m: 'lullaby'"],"ename":"KeyError","evalue":"'lullaby'","output_type":"error"}]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches((10, 10))\nplot_vectors(test_vectors, test_words, how='svd', ax=ax)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:13.318676Z","start_time":"2019-10-29T19:20:12.996595Z"},"id":"-jWsJxiLQFhs","executionInfo":{"status":"ok","timestamp":1721214277635,"user_tz":-180,"elapsed":873,"user":{"displayName":"Кирилл Демёхин","userId":"13741693148885415936"}},"outputId":"4f6f11ca-74d1-4bd6-f3db-e6d056cb9c05","execution":{"iopub.status.busy":"2024-07-18T11:20:21.504911Z","iopub.execute_input":"2024-07-18T11:20:21.505300Z","iopub.status.idle":"2024-07-18T11:20:21.908215Z","shell.execute_reply.started":"2024-07-18T11:20:21.505268Z","shell.execute_reply":"2024-07-18T11:20:21.907237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -U gensim\n# import gensim","metadata":{"id":"fuvmBfGQZAIw","execution":{"iopub.status.busy":"2024-07-18T11:36:17.243014Z","iopub.execute_input":"2024-07-18T11:36:17.243399Z","iopub.status.idle":"2024-07-18T11:36:31.385640Z","shell.execute_reply.started":"2024-07-18T11:36:17.243369Z","shell.execute_reply":"2024-07-18T11:36:31.384406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word2vec = gensim.models.Word2Vec(sentences=train_tokenized, vector_size=100,\n#                                   window=5, min_count=5, workers=4,\n#                                   sg=1, epochs=10)","metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:20:17.075005Z","start_time":"2019-10-29T19:20:13.615729Z"},"id":"UCx267leQFhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}