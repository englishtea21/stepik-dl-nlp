{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Генерация текста с помощью RNN\n","metadata":{}},{"cell_type":"markdown","source":"(по мотивам [семинара](https://github.com/neychev/harbour_dlia2019/blob/master/day02_Simple_RNN/Day_2_Simple_RNN_pytorch.ipynb)\n [курса \"Deep Learning in Applications\"](https://in.harbour.space/data-science/deep-learning-in-applications-radoslav-neychev-anastasia-ianina/))","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/englishtea21/stepik-dl-nlp.git\n# !pip install -r stepik-dl-nlp/requirements.txt\nimport sys;","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-11T08:32:13.564962Z","iopub.execute_input":"2024-08-11T08:32:13.565296Z","iopub.status.idle":"2024-08-11T08:32:29.037997Z","shell.execute_reply.started":"2024-08-11T08:32:13.565268Z","shell.execute_reply":"2024-08-11T08:32:29.036898Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'stepik-dl-nlp'...\nremote: Enumerating objects: 480, done.\u001b[K\nremote: Counting objects: 100% (186/186), done.\u001b[K\nremote: Compressing objects: 100% (81/81), done.\u001b[K\nremote: Total 480 (delta 109), reused 180 (delta 104), pack-reused 294\u001b[K\nReceiving objects: 100% (480/480), 208.96 MiB | 35.32 MiB/s, done.\nResolving deltas: 100% (243/243), done.\nUpdating files: 100% (72/72), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/stepik-dl-nlp","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:29.040310Z","iopub.execute_input":"2024-08-11T08:32:29.040662Z","iopub.status.idle":"2024-08-11T08:32:29.048059Z","shell.execute_reply.started":"2024-08-11T08:32:29.040629Z","shell.execute_reply":"2024-08-11T08:32:29.047017Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/stepik-dl-nlp\n","output_type":"stream"}]},{"cell_type":"code","source":"# from google.colab import userdata\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:29.049360Z","iopub.execute_input":"2024-08-11T08:32:29.049695Z","iopub.status.idle":"2024-08-11T08:32:29.070398Z","shell.execute_reply.started":"2024-08-11T08:32:29.049657Z","shell.execute_reply":"2024-08-11T08:32:29.069649Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!git remote remove origin\n!git remote add origin https://englishtea21:{user_secrets.get_secret('stepik-samsung-nlp-github-token')}@github.com/englishtea21/stepik-dl-nlp.git","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:29.073976Z","iopub.execute_input":"2024-08-11T08:32:29.074223Z","iopub.status.idle":"2024-08-11T08:32:31.240493Z","shell.execute_reply.started":"2024-08-11T08:32:29.074201Z","shell.execute_reply":"2024-08-11T08:32:31.239258Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!git config --global user.email \"englishtea21@mail.ru\"\n!git config --global user.name \"englishtea21\"","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:31.242083Z","iopub.execute_input":"2024-08-11T08:32:31.242459Z","iopub.status.idle":"2024-08-11T08:32:33.251597Z","shell.execute_reply.started":"2024-08-11T08:32:31.242422Z","shell.execute_reply":"2024-08-11T08:32:33.250347Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:20:34.854793Z","start_time":"2019-11-05T18:20:34.372865Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.253065Z","iopub.execute_input":"2024-08-11T08:32:33.253376Z","iopub.status.idle":"2024-08-11T08:32:33.260676Z","shell.execute_reply.started":"2024-08-11T08:32:33.253348Z","shell.execute_reply":"2024-08-11T08:32:33.259807Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Данные\nДатасет содержит ~9k имен, все написаны латиницей.","metadata":{}},{"cell_type":"code","source":"# # Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n# with open('datasets/russian_names.txt') as input_file:\n#     names = input_file.read()[:-1].split('\\n')","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:03.509714Z","start_time":"2019-11-05T18:21:03.491489Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.263713Z","iopub.execute_input":"2024-08-11T08:32:33.263998Z","iopub.status.idle":"2024-08-11T08:32:33.272823Z","shell.execute_reply.started":"2024-08-11T08:32:33.263975Z","shell.execute_reply":"2024-08-11T08:32:33.272053Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# names[:5]","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:03.946758Z","start_time":"2019-11-05T18:21:03.938432Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.273910Z","iopub.execute_input":"2024-08-11T08:32:33.274155Z","iopub.status.idle":"2024-08-11T08:32:33.284754Z","shell.execute_reply.started":"2024-08-11T08:32:33.274128Z","shell.execute_reply":"2024-08-11T08:32:33.283944Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на распределение длин имен:","metadata":{}},{"cell_type":"markdown","source":"# Препроцессинг","metadata":{}},{"cell_type":"code","source":"# len(list(filter(str.isalpha, names))), len(names)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.285999Z","iopub.execute_input":"2024-08-11T08:32:33.286750Z","iopub.status.idle":"2024-08-11T08:32:33.295801Z","shell.execute_reply.started":"2024-08-11T08:32:33.286719Z","shell.execute_reply":"2024-08-11T08:32:33.294955Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# import re\n# only_latin_letters=re.compile(r'[A-Za-z]+')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.300075Z","iopub.execute_input":"2024-08-11T08:32:33.300319Z","iopub.status.idle":"2024-08-11T08:32:33.306615Z","shell.execute_reply.started":"2024-08-11T08:32:33.300298Z","shell.execute_reply":"2024-08-11T08:32:33.305889Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# names_tmp = list(filter(only_latin_letters.fullmatch, names))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.307619Z","iopub.execute_input":"2024-08-11T08:32:33.307898Z","iopub.status.idle":"2024-08-11T08:32:33.317468Z","shell.execute_reply.started":"2024-08-11T08:32:33.307873Z","shell.execute_reply":"2024-08-11T08:32:33.316797Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# len(names_tmp)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.318492Z","iopub.execute_input":"2024-08-11T08:32:33.318749Z","iopub.status.idle":"2024-08-11T08:32:33.327518Z","shell.execute_reply.started":"2024-08-11T08:32:33.318728Z","shell.execute_reply":"2024-08-11T08:32:33.326891Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# names=names_tmp\n# del names_tmp","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.328425Z","iopub.execute_input":"2024-08-11T08:32:33.328652Z","iopub.status.idle":"2024-08-11T08:32:33.340556Z","shell.execute_reply.started":"2024-08-11T08:32:33.328632Z","shell.execute_reply":"2024-08-11T08:32:33.339882Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# plt.title('Name length distribution')\n# plt.hist(list(map(len, names)), bins=25);","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:05.420060Z","start_time":"2019-11-05T18:21:05.179513Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.341547Z","iopub.execute_input":"2024-08-11T08:32:33.341775Z","iopub.status.idle":"2024-08-11T08:32:33.351270Z","shell.execute_reply.started":"2024-08-11T08:32:33.341755Z","shell.execute_reply":"2024-08-11T08:32:33.350545Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# names = [' ' + line for line in names]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.352252Z","iopub.execute_input":"2024-08-11T08:32:33.352516Z","iopub.status.idle":"2024-08-11T08:32:33.363074Z","shell.execute_reply.started":"2024-08-11T08:32:33.352494Z","shell.execute_reply":"2024-08-11T08:32:33.362391Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# #all unique characters go here\n# tokens = list(set(''.join(names)))\n\n# num_tokens = len(tokens)\n# print ('num_tokens = ', num_tokens)","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:07.335188Z","start_time":"2019-11-05T18:21:07.320148Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.364000Z","iopub.execute_input":"2024-08-11T08:32:33.364342Z","iopub.status.idle":"2024-08-11T08:32:33.374142Z","shell.execute_reply.started":"2024-08-11T08:32:33.364309Z","shell.execute_reply":"2024-08-11T08:32:33.373450Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# tokens","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.375136Z","iopub.execute_input":"2024-08-11T08:32:33.375401Z","iopub.status.idle":"2024-08-11T08:32:33.386305Z","shell.execute_reply.started":"2024-08-11T08:32:33.375378Z","shell.execute_reply":"2024-08-11T08:32:33.385590Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Мы специально добавляем пробел к нашим именам в тренировочных данных. Зачем? <br>\nEсли не будет специального символа, с которого начинается генерация, то мы лишим нашу модель способности выбирать первый символ последовательности","metadata":{}},{"cell_type":"markdown","source":"После того, как мы обучим нашу нейронную сеть, мы сможем генерировать имена, которые соответствуют некоторым условиям — например, имена, которые начинаются на букву \"a\" или на буквы \"abc\", или какие-либо другие условия. Если же мы захотим генерировать любые имена, начинающиеся с любой буквы, мы просто передадим нашей функции пробел в качестве первого символа. Таким образом, сможем сгенерировать имена, начинающиеся на любую букву. Отлично! С этой небольшой хитростью в коде разобрались.","metadata":{}},{"cell_type":"markdown","source":"### Символы -> id\n\nСоздадим словарь < символ > -> < id >","metadata":{}},{"cell_type":"code","source":"# token_to_id = {token: idx for idx, token in enumerate(tokens)}","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:07.674548Z","start_time":"2019-11-05T18:21:07.671129Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.387271Z","iopub.execute_input":"2024-08-11T08:32:33.387524Z","iopub.status.idle":"2024-08-11T08:32:33.397379Z","shell.execute_reply.started":"2024-08-11T08:32:33.387503Z","shell.execute_reply":"2024-08-11T08:32:33.396543Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# token_to_id.keys()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.398618Z","iopub.execute_input":"2024-08-11T08:32:33.398922Z","iopub.status.idle":"2024-08-11T08:32:33.409835Z","shell.execute_reply.started":"2024-08-11T08:32:33.398899Z","shell.execute_reply":"2024-08-11T08:32:33.409137Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n\n# for i in range(num_tokens):\n#     assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n\n# print(\"Seems alright!\")","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:07.838814Z","start_time":"2019-11-05T18:21:07.833611Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.410879Z","iopub.execute_input":"2024-08-11T08:32:33.411108Z","iopub.status.idle":"2024-08-11T08:32:33.421810Z","shell.execute_reply.started":"2024-08-11T08:32:33.411087Z","shell.execute_reply":"2024-08-11T08:32:33.421051Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Отлично! И теперь мы хотим преобразовать наши входные данные, а именно — наши 9 с небольшим хвостиком тысяч имён в некоторое численное представление, то есть вместо имени мы хотим получить численный вектор. Сделать это мы можем с помощью функций \"to_matrix\", которая будет преобразовывать наше имя из буквенного, человеко-читаемого формата в формат \"вектор с числами\".","metadata":{}},{"cell_type":"code","source":"# def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first = True):\n#     \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n    \n#     max_len = max_len or max(map(len, data))\n#     data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n\n#     for i in range(len(data)):\n#         line_ix = [token_to_id[c] for c in data[i]]\n#         data_ix[i, :len(line_ix)] = line_ix\n        \n#     if not batch_first: # convert [batch, time] into [time, batch]\n#         data_ix = np.transpose(data_ix)\n\n#     return data_ix","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:07.988093Z","start_time":"2019-11-05T18:21:07.977722Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.422875Z","iopub.execute_input":"2024-08-11T08:32:33.423136Z","iopub.status.idle":"2024-08-11T08:32:33.435052Z","shell.execute_reply.started":"2024-08-11T08:32:33.423114Z","shell.execute_reply":"2024-08-11T08:32:33.434257Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# #Example: cast 4 names to matrices, pad with zeros\n# print('\\n'.join(names[::2000]))\n# print(to_matrix(names[::2000], token_to_id))","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:08.136936Z","start_time":"2019-11-05T18:21:08.131609Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.436014Z","iopub.execute_input":"2024-08-11T08:32:33.436256Z","iopub.status.idle":"2024-08-11T08:32:33.450792Z","shell.execute_reply.started":"2024-08-11T08:32:33.436234Z","shell.execute_reply":"2024-08-11T08:32:33.450147Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"22 - id пробела, этот токен встречается вначале (по умолчанию как знак начала), так и может быть в конце - паддинг до равной длины строк в матрице","metadata":{}},{"cell_type":"markdown","source":"# Рекуррентные нейронные сети\n\n<img src=\"img/rnn.png\" width=480>","metadata":{}},{"cell_type":"code","source":"# import torch, torch.nn as nn\n# import torch.nn.functional as F\n# # from torch.autograd import Variable","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:10.739438Z","start_time":"2019-11-05T18:21:09.661222Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.451918Z","iopub.execute_input":"2024-08-11T08:32:33.452495Z","iopub.status.idle":"2024-08-11T08:32:33.463060Z","shell.execute_reply.started":"2024-08-11T08:32:33.452464Z","shell.execute_reply":"2024-08-11T08:32:33.462412Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# class CharRNNCell(nn.Module):\n#     \"\"\"\n#     Implement the scheme above as torch module\n#     \"\"\"\n#     def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n#         super(self.__class__,self).__init__()\n#         self.num_units = rnn_num_units\n        \n#         self.embedding = nn.Embedding(num_tokens, embedding_size)\n#         self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n#         self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n        \n#     def forward(self, x, h_prev):\n#         \"\"\"\n#         This method computes h_next(x, h_prev) and log P(x_next | h_next)\n#         We'll call it repeatedly to produce the whole sequence.\n        \n#         :param x: batch of character ids, variable containing vector of int64\n#         :param h_prev: previous rnn hidden states, variable containing matrix [batch, rnn_num_units] of float32\n#         \"\"\"\n#         # get vector embedding of x\n#         x_emb = self.embedding(x)\n        \n#         # compute next hidden state using self.rnn_update\n#         x_and_h = torch.cat([x_emb, h_prev], dim=1) #YOUR CODE HERE\n#         h_next = self.rnn_update(x_and_h) #YOUR CODE HERE\n        \n#         h_next = F.tanh(h_next)\n        \n#         assert h_next.size() == h_prev.size()\n        \n#         #compute logits for next character probs\n#         logits = self.rnn_to_logits(h_next)\n        \n#         return h_next, F.log_softmax(logits, -1)\n    \n#     def initial_state(self, batch_size):\n#         \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n#         return torch.zeros(batch_size, self.num_units)","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:10.751862Z","start_time":"2019-11-05T18:21:10.741772Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.464166Z","iopub.execute_input":"2024-08-11T08:32:33.464487Z","iopub.status.idle":"2024-08-11T08:32:33.474525Z","shell.execute_reply.started":"2024-08-11T08:32:33.464455Z","shell.execute_reply":"2024-08-11T08:32:33.473745Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# char_rnn = CharRNNCell()","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:11.071002Z","start_time":"2019-11-05T18:21:11.052377Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.475651Z","iopub.execute_input":"2024-08-11T08:32:33.475948Z","iopub.status.idle":"2024-08-11T08:32:33.493136Z","shell.execute_reply.started":"2024-08-11T08:32:33.475925Z","shell.execute_reply":"2024-08-11T08:32:33.492378Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Тренировка сети, RNN loop","metadata":{}},{"cell_type":"code","source":"# def rnn_loop(rnn, batch_index):\n#     \"\"\"\n#     Computes log P(next_character) for all time-steps in names_ix\n#     :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n#     \"\"\"\n#     batch_size, max_length = batch_index.size()\n#     hid_state = rnn.initial_state(batch_size)\n#     logprobs = []\n\n#     for x_t in batch_index.transpose(0,1):\n#         hid_state, logp_next = rnn(x_t, hid_state)  \n#         logprobs.append(logp_next)\n        \n#     return torch.stack(logprobs, dim=1)","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:11.521078Z","start_time":"2019-11-05T18:21:11.510175Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.494016Z","iopub.execute_input":"2024-08-11T08:32:33.494256Z","iopub.status.idle":"2024-08-11T08:32:33.503469Z","shell.execute_reply.started":"2024-08-11T08:32:33.494235Z","shell.execute_reply":"2024-08-11T08:32:33.502788Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Тренировка сети","metadata":{}},{"cell_type":"code","source":"# from IPython.display import clear_output\n# from random import sample\n\n# char_rnn = CharRNNCell()\n# opt = torch.optim.Adam(char_rnn.parameters())\n# criterion = nn.NLLLoss()\n# history = []","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:12.120106Z","start_time":"2019-11-05T18:21:12.109585Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.504402Z","iopub.execute_input":"2024-08-11T08:32:33.504703Z","iopub.status.idle":"2024-08-11T08:32:33.521405Z","shell.execute_reply.started":"2024-08-11T08:32:33.504679Z","shell.execute_reply":"2024-08-11T08:32:33.520646Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# MAX_LENGTH = max(map(len, names))\n\n# for i in range(1000):\n\n#     batch_ix = to_matrix(sample(names, 32), token_to_id, max_len=MAX_LENGTH)\n#     batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n    \n#     logp_seq = rnn_loop(char_rnn, batch_ix)\n    \n#     # compute loss\n#     predictions_logp = logp_seq[:, :-1]\n#     actual_next_tokens = batch_ix[:, 1:]\n\n#     loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n    \n#     # train with backprop\n#     loss.backward()\n#     opt.step()\n#     opt.zero_grad()\n    \n#     # visualizing training process\n#     history.append(loss.data.numpy())\n#     if (i + 1) % 100 == 0:\n#         clear_output(True)\n#         plt.plot(history,label='loss')\n#         plt.legend()\n#         plt.show()\n\n# assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\"","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.521061Z","start_time":"2019-11-05T18:21:12.302892Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.529194Z","iopub.execute_input":"2024-08-11T08:32:33.529493Z","iopub.status.idle":"2024-08-11T08:32:33.536266Z","shell.execute_reply.started":"2024-08-11T08:32:33.529470Z","shell.execute_reply":"2024-08-11T08:32:33.535407Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### RNN: генерация имен","metadata":{}},{"cell_type":"code","source":"# def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n#     '''\n#     The function generates text given a phrase of length at least SEQ_LENGTH.\n#     :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n#     :param max_length: maximum output length, including seed_phrase\n#     :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n#                         smaller temperature converges to the single most likely output\n#     '''\n    \n#     x_sequence = [token_to_id[token] for token in seed_phrase]\n#     x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n#     hid_state = char_rnn.initial_state(batch_size=1)\n    \n#     #feed the seed phrase, if any\n#     for i in range(len(seed_phrase) - 1):\n#         hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n    \n#     #start generating\n#     for _ in range(max_length - len(seed_phrase)):\n#         hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n#         p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n        \n#         # sample next token and push it back into x_sequence\n#         next_ix = np.random.choice(len(tokens), p=p_next)\n#         next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n#         x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n        \n#     return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.540765Z","start_time":"2019-11-05T18:21:23.524503Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.537391Z","iopub.execute_input":"2024-08-11T08:32:33.537644Z","iopub.status.idle":"2024-08-11T08:32:33.549411Z","shell.execute_reply.started":"2024-08-11T08:32:33.537623Z","shell.execute_reply":"2024-08-11T08:32:33.548727Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# sampled=[]\n# for _ in range(10):\n#     sampled.append(generate_sample(char_rnn))","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.625562Z","start_time":"2019-11-05T18:21:23.544968Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.550250Z","iopub.execute_input":"2024-08-11T08:32:33.550557Z","iopub.status.idle":"2024-08-11T08:32:33.566832Z","shell.execute_reply.started":"2024-08-11T08:32:33.550534Z","shell.execute_reply":"2024-08-11T08:32:33.566141Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# sampled","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.568022Z","iopub.execute_input":"2024-08-11T08:32:33.568351Z","iopub.status.idle":"2024-08-11T08:32:33.581314Z","shell.execute_reply.started":"2024-08-11T08:32:33.568318Z","shell.execute_reply":"2024-08-11T08:32:33.580613Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# names_stripped = [name.strip() for name in names]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.582238Z","iopub.execute_input":"2024-08-11T08:32:33.582491Z","iopub.status.idle":"2024-08-11T08:32:33.593032Z","shell.execute_reply.started":"2024-08-11T08:32:33.582469Z","shell.execute_reply":"2024-08-11T08:32:33.592309Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# names_stripped[::2000]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.594203Z","iopub.execute_input":"2024-08-11T08:32:33.594961Z","iopub.status.idle":"2024-08-11T08:32:33.605033Z","shell.execute_reply.started":"2024-08-11T08:32:33.594929Z","shell.execute_reply":"2024-08-11T08:32:33.604333Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# [matched for el in sampled if el.strip() in names_stripped]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.606221Z","iopub.execute_input":"2024-08-11T08:32:33.606807Z","iopub.status.idle":"2024-08-11T08:32:33.615212Z","shell.execute_reply.started":"2024-08-11T08:32:33.606775Z","shell.execute_reply":"2024-08-11T08:32:33.614475Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# sampled=[]\n# for _ in range(10):\n#     sampled.append(generate_sample(char_rnn, seed_phrase=' Ar'))","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.702249Z","start_time":"2019-11-05T18:21:23.629226Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.616207Z","iopub.execute_input":"2024-08-11T08:32:33.616470Z","iopub.status.idle":"2024-08-11T08:32:33.627340Z","shell.execute_reply.started":"2024-08-11T08:32:33.616449Z","shell.execute_reply":"2024-08-11T08:32:33.626635Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# sampled","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.628335Z","iopub.execute_input":"2024-08-11T08:32:33.628583Z","iopub.status.idle":"2024-08-11T08:32:33.637552Z","shell.execute_reply.started":"2024-08-11T08:32:33.628562Z","shell.execute_reply":"2024-08-11T08:32:33.636887Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# [matched for el in sampled if el.strip() in names_stripped]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.638547Z","iopub.execute_input":"2024-08-11T08:32:33.638869Z","iopub.status.idle":"2024-08-11T08:32:33.650147Z","shell.execute_reply.started":"2024-08-11T08:32:33.638818Z","shell.execute_reply":"2024-08-11T08:32:33.649402Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Как видно, наша модель именно генерирует новые имена, а не вспоминает запоменнные","metadata":{}},{"cell_type":"code","source":"# sampled=[]\n# for _ in range(10):\n#     sampled.append(generate_sample(char_rnn, seed_phrase=' Koval'))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.651302Z","iopub.execute_input":"2024-08-11T08:32:33.651829Z","iopub.status.idle":"2024-08-11T08:32:33.661439Z","shell.execute_reply.started":"2024-08-11T08:32:33.651804Z","shell.execute_reply":"2024-08-11T08:32:33.660773Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# sampled","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.662402Z","iopub.execute_input":"2024-08-11T08:32:33.662954Z","iopub.status.idle":"2024-08-11T08:32:33.674339Z","shell.execute_reply.started":"2024-08-11T08:32:33.662929Z","shell.execute_reply":"2024-08-11T08:32:33.673662Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"При маленькой температуре сеть генерирует фамилии, в которых она наиболее уверена <br>\nПри большой - очень разнообразные фамилии","metadata":{}},{"cell_type":"code","source":"# sampled=[]\n# for _ in range(10):\n#     sampled.append(generate_sample(char_rnn, seed_phrase=' Podo', temperature=1.2))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.675205Z","iopub.execute_input":"2024-08-11T08:32:33.675520Z","iopub.status.idle":"2024-08-11T08:32:33.686101Z","shell.execute_reply.started":"2024-08-11T08:32:33.675496Z","shell.execute_reply":"2024-08-11T08:32:33.685347Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# sampled","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.688724Z","iopub.execute_input":"2024-08-11T08:32:33.689388Z","iopub.status.idle":"2024-08-11T08:32:33.703891Z","shell.execute_reply.started":"2024-08-11T08:32:33.689362Z","shell.execute_reply":"2024-08-11T08:32:33.703101Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Более простое решение\n\n* `nn.RNNCell(emb_size, rnn_num_units)` - шаг RNN. Алгоритм: concat-linear-tanh\n* `nn.RNN(emb_size, rnn_num_units` - весь rnn_loop.\n\nКроме того, в PyTorch есть `nn.LSTMCell`, `nn.LSTM`, `nn.GRUCell`, `nn.GRU`, etc. etc.\n\nПерепишем наш пример с генерацией имен с помощью средств PyTorch.","metadata":{}},{"cell_type":"code","source":"# class CharRNNLoop(nn.Module):\n#     def __init__(self, num_tokens=num_tokens, emb_size=32, rnn_num_units=64):\n#         super(self.__class__, self).__init__()\n#         self.num_units = rnn_num_units\n#         self.emb = nn.Embedding(num_tokens, emb_size)\n#         self.rnn = nn.RNN(emb_size, rnn_num_units, batch_first=True)\n#         self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n        \n#     def forward_logits(self, x, hidden_state=None):\n#         if hidden_state is None:\n#             hidden_state=self.initial_state(x.shape[0])\n        \n#         h_seq, hidden_state = self.rnn(self.emb(x), hidden_state)\n#         next_logits = self.hid_to_logits(h_seq)\n#         return next_logits, hidden_state\n        \n#     def forward_hidden(self, x, hidden_state=None):\n#         next_logits, hidden_state = self.forward_logits(x, hidden_state)\n#         next_logp = F.log_softmax(next_logits, dim=-1)\n#         return next_logp, hidden_state\n    \n#     def forward(self, x):\n#         next_logits, _ = self.forward_logits(x)\n#         next_logp = F.log_softmax(next_logits, dim=-1)\n#         return next_logp\n    \n#     def initial_state(self, batch_size):\n#         \"\"\"Return RNN state before it processes the first input (aka h0)\"\"\"\n#         return torch.zeros(1, batch_size, self.num_units) \n    \n# model = CharRNNLoop()\n# opt = torch.optim.Adam(model.parameters())\n# criterion = nn.NLLLoss()\n# history = []","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.713285Z","start_time":"2019-11-05T18:21:23.704755Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.705099Z","iopub.execute_input":"2024-08-11T08:32:33.705434Z","iopub.status.idle":"2024-08-11T08:32:33.718442Z","shell.execute_reply.started":"2024-08-11T08:32:33.705404Z","shell.execute_reply":"2024-08-11T08:32:33.717793Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# model=model.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.719464Z","iopub.execute_input":"2024-08-11T08:32:33.719756Z","iopub.status.idle":"2024-08-11T08:32:33.730664Z","shell.execute_reply.started":"2024-08-11T08:32:33.719722Z","shell.execute_reply":"2024-08-11T08:32:33.729847Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# # the model applies over the whole sequence\n# batch_ix = to_matrix(sample(names, 32), token_to_id, max_len=MAX_LENGTH)\n# # batch_ix = torch.LongTensor(batch_ix).to('cuda')\n# batch_ix = torch.LongTensor(batch_ix)\n\n# logp_seq = model(batch_ix)\n\n# # compute loss\n# loss = F.nll_loss(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n#                   batch_ix[:, :-1].contiguous().view(-1))\n\n# loss.backward()","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.790047Z","start_time":"2019-11-05T18:21:23.715167Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.731915Z","iopub.execute_input":"2024-08-11T08:32:33.732248Z","iopub.status.idle":"2024-08-11T08:32:33.744735Z","shell.execute_reply.started":"2024-08-11T08:32:33.732219Z","shell.execute_reply":"2024-08-11T08:32:33.744072Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# MAX_LENGTH = max(map(len, names))\n\n\n# for i in range(1000):\n#     batch_ix = to_matrix(sample(names, 32), token_to_id, max_len=MAX_LENGTH)\n# #     batch_ix = torch.tensor(batch_ix, dtype=torch.int64).to('cuda')\n#     batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n    \n#     logp_seq = model(batch_ix)\n    \n#     # compute loss\n#     predictions_logp = logp_seq[:, :-1]\n#     actual_next_tokens = batch_ix[:, 1:]\n\n#     loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n    \n#     # train with backprop\n#     loss.backward()\n#     opt.step()\n#     opt.zero_grad()\n    \n#     history.append(loss.data.cpu().numpy())\n#     if (i + 1) % 100 == 0:\n#         clear_output(True)\n#         plt.plot(history, label='loss')\n#         plt.legend()\n#         plt.show()\n\n# assert np.mean(history[:25]) > np.mean(history[-25:]), \"RNN didn't converge.\"","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.468107Z","start_time":"2019-11-05T18:21:23.792092Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.745950Z","iopub.execute_input":"2024-08-11T08:32:33.746508Z","iopub.status.idle":"2024-08-11T08:32:33.757113Z","shell.execute_reply.started":"2024-08-11T08:32:33.746477Z","shell.execute_reply":"2024-08-11T08:32:33.756398Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# def generate_sample(char_torch_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n#     '''\n#     The function generates text given a phrase of length at least SEQ_LENGTH.\n#     :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n#     :param max_length: maximum output length, including seed_phrase\n#     :param temperature: coefficient for sampling. Higher temperature produces more chaotic outputs,\n#                         smaller temperature converges to the single most likely output\n#     '''\n    \n#     # Convert the seed phrase to a sequence of indices\n#     x_sequence = [token_to_id[token] for token in seed_phrase]\n#     x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n    \n#     # Initialize the hidden state\n#     hid_state = char_torch_rnn.initial_state(batch_size=1)\n    \n#     if seed_phrase!=' ':\n#         _, hid_state = char_torch_rnn.forward_hidden(x_sequence[:, len(seed_phrase)-2].unsqueeze(0))\n    \n#     # Start generating text\n#     generated_sequence = list(seed_phrase)  # Initialize with the seed phrase\n\n#     for _ in range(max_length - len(seed_phrase)):\n#         # Get the logits for the next character\n#         next_logits, _ = char_torch_rnn.forward_logits(x_sequence[:, -1].unsqueeze(0), hid_state)\n        \n#         # Apply temperature to logits\n#         next_logits = next_logits / temperature\n        \n#         # Calculate probabilities using softmax\n#         p_next = F.softmax(next_logits, dim=-1).data.cpu().numpy().flatten()\n#         # Sample the next character index from the probability distribution\n#         next_ix = np.random.choice(len(tokens), p=p_next)\n        \n#         # Append the sampled character to the generated sequence\n#         generated_sequence.append(tokens[next_ix])\n        \n#         # Update the input sequence with the new character\n#         next_ix_tensor = torch.tensor([[next_ix]], dtype=torch.int64)\n#         x_sequence = torch.cat([x_sequence, next_ix_tensor], dim=1)\n\n#         # Update hidden state for the next character\n#         _, hid_state = char_torch_rnn.forward_hidden(next_ix_tensor, hid_state)\n    \n#     return ''.join(generated_sequence)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.758267Z","iopub.execute_input":"2024-08-11T08:32:33.758521Z","iopub.status.idle":"2024-08-11T08:32:33.777267Z","shell.execute_reply.started":"2024-08-11T08:32:33.758499Z","shell.execute_reply":"2024-08-11T08:32:33.776485Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# # model=model.cpu()\n# for _ in range(10):\n#     print(generate_sample(model,seed_phrase='Stryk', temperature=1))","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.526436Z","start_time":"2019-11-05T18:21:31.469965Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.778460Z","iopub.execute_input":"2024-08-11T08:32:33.779049Z","iopub.status.idle":"2024-08-11T08:32:33.794232Z","shell.execute_reply.started":"2024-08-11T08:32:33.779018Z","shell.execute_reply":"2024-08-11T08:32:33.793442Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"### Домашнее задание: мотивационные лозунги","metadata":{}},{"cell_type":"markdown","source":"Возможно стоит учить эмбеддинги n-грамм","metadata":{}},{"cell_type":"code","source":"# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\nwith open('datasets/author_quotes.txt') as input_file:\n    quotes = input_file.read()[:-1].split('\\n')\n    quotes = [' ' + line for line in quotes]","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.570320Z","start_time":"2019-11-05T18:21:31.528673Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.795425Z","iopub.execute_input":"2024-08-11T08:32:33.795750Z","iopub.status.idle":"2024-08-11T08:32:33.844063Z","shell.execute_reply.started":"2024-08-11T08:32:33.795723Z","shell.execute_reply":"2024-08-11T08:32:33.843367Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"quotes[:5]","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.575286Z","start_time":"2019-11-05T18:21:31.571798Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.845144Z","iopub.execute_input":"2024-08-11T08:32:33.845687Z","iopub.status.idle":"2024-08-11T08:32:33.852877Z","shell.execute_reply.started":"2024-08-11T08:32:33.845654Z","shell.execute_reply":"2024-08-11T08:32:33.852014Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"[' If you live to be a hundred, I want to live to be a hundred minus one day so I never have to live without you.',\n \" Promise me you'll always remember: You're braver than you believe, and stronger than you seem, and smarter than you think.\",\n ' Did you ever stop to think, and forget to start again?',\n ' Organizing is what you do before you do something, so that when you do it, it is not all mixed up.',\n ' Weeds are flowers too, once you get to know them.']"},"metadata":{}}]},{"cell_type":"code","source":"# tokens = list(set(''.join(quotes)))\n# token_to_id = {token: idx for idx, token in enumerate(tokens)}\n# num_tokens = len(tokens)","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.653673Z","start_time":"2019-11-05T18:21:31.578424Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:33.854063Z","iopub.execute_input":"2024-08-11T08:32:33.854633Z","iopub.status.idle":"2024-08-11T08:32:33.863608Z","shell.execute_reply.started":"2024-08-11T08:32:33.854601Z","shell.execute_reply":"2024-08-11T08:32:33.862825Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# MAX_LENGTH = max(map(len, quotes))\n# MAX_LENGTH","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.864808Z","iopub.execute_input":"2024-08-11T08:32:33.865125Z","iopub.status.idle":"2024-08-11T08:32:33.873915Z","shell.execute_reply.started":"2024-08-11T08:32:33.865094Z","shell.execute_reply":"2024-08-11T08:32:33.873244Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# # tokens, \n# num_tokens","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.874897Z","iopub.execute_input":"2024-08-11T08:32:33.875170Z","iopub.status.idle":"2024-08-11T08:32:33.886836Z","shell.execute_reply.started":"2024-08-11T08:32:33.875147Z","shell.execute_reply":"2024-08-11T08:32:33.886166Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.887864Z","iopub.execute_input":"2024-08-11T08:32:33.888359Z","iopub.status.idle":"2024-08-11T08:32:33.897373Z","shell.execute_reply.started":"2024-08-11T08:32:33.888328Z","shell.execute_reply":"2024-08-11T08:32:33.896730Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# class CharRNNLoop(nn.Module):\n#     def __init__(self, device=device, num_tokens=num_tokens, emb_size=64, hidden_size=64, num_layers=1):\n#         super(self.__class__, self).__init__()\n#         self.device=device\n#         self.num_layers=num_layers\n#         self.hidden_size = hidden_size\n#         self.emb = nn.Embedding(num_tokens, emb_size)\n#         self.rnn = nn.RNN(emb_size, hidden_size, num_layers, batch_first=True)\n#         self.hid_to_logits = nn.Linear(hidden_size, num_tokens)\n        \n#     def forward_logits(self, x, hidden_state=None):\n#         if hidden_state is None:\n#             hidden_state=self.initial_state(x.shape[0])\n        \n#         h_seq, hidden_state = self.rnn(self.emb(x), hidden_state)\n#         next_logits = self.hid_to_logits(h_seq)\n#         return next_logits, hidden_state\n        \n#     def forward_hidden(self, x, hidden_state=None):\n#         next_logits, hidden_state = self.forward_logits(x, hidden_state)\n#         next_logp = F.log_softmax(next_logits, dim=-1)\n#         return next_logp, hidden_state\n    \n#     def forward(self, x):\n#         next_logits, _ = self.forward_logits(x)\n#         next_logp = F.log_softmax(next_logits, dim=-1)\n#         return next_logp\n    \n#     def initial_state(self, batch_size):\n#         \"\"\"Return RNN state before it processes the first input (aka h0)\"\"\"\n# #         return torch.zeros(1, batch_size, self.hidden_size, device=self.device) \n#         return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n    \n# quotes_baseline_model = CharRNNLoop(num_layers=4)\n# opt = torch.optim.Adam(quotes_baseline_model.parameters(), lr=1e-4)\n# sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.7, patience=1)\n# criterion = nn.CrossEntropyLoss()\n\n# history=[]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.898502Z","iopub.execute_input":"2024-08-11T08:32:33.898928Z","iopub.status.idle":"2024-08-11T08:32:33.911574Z","shell.execute_reply.started":"2024-08-11T08:32:33.898898Z","shell.execute_reply":"2024-08-11T08:32:33.910876Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# # Move model to the first GPU device\n# quotes_baseline_model = quotes_baseline_model.to(device)\n\n# # Use DataParallel to utilize multiple GPUs\n# if torch.cuda.device_count() > 1:\n#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n#     quotes_baseline_model = nn.DataParallel(quotes_baseline_model)\n    \n# quotes_baseline_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.912578Z","iopub.execute_input":"2024-08-11T08:32:33.913177Z","iopub.status.idle":"2024-08-11T08:32:33.930090Z","shell.execute_reply.started":"2024-08-11T08:32:33.913146Z","shell.execute_reply":"2024-08-11T08:32:33.929266Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# from torch.utils.data import Dataset, DataLoader\n# import copy","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.931152Z","iopub.execute_input":"2024-08-11T08:32:33.931400Z","iopub.status.idle":"2024-08-11T08:32:33.949117Z","shell.execute_reply.started":"2024-08-11T08:32:33.931378Z","shell.execute_reply":"2024-08-11T08:32:33.948455Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first = True):\n#     \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n    \n#     max_len = max_len or max(map(len, data))\n#     data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n\n#     for i in range(len(data)):\n#         line_ix = [token_to_id[c] for c in data[i]]\n#         data_ix[i, :len(line_ix)] = line_ix\n        \n#     if not batch_first: # convert [batch, time] into [time, batch]\n#         data_ix = np.transpose(data_ix)\n\n#     return data_ix","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.951411Z","iopub.execute_input":"2024-08-11T08:32:33.951987Z","iopub.status.idle":"2024-08-11T08:32:33.962054Z","shell.execute_reply.started":"2024-08-11T08:32:33.951963Z","shell.execute_reply":"2024-08-11T08:32:33.961221Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# class QuotesDataset(Dataset):\n#     def __init__(self, quotes_list: list[str], token_to_id: dict, max_len: int):\n#         self.quotes_list=copy.deepcopy(quotes_list)\n#         self.token_to_id=copy.deepcopy(token_to_id)\n#         self.max_len=max_len\n#         self.quotes_tensors=torch.LongTensor(to_matrix(self.quotes_list, self.token_to_id, self.max_len)) \n\n#     def __len__(self):\n#         return len(self.quotes_list)\n\n#     def __getitem__(self, idx):\n#         return self.quotes_tensors[idx, :]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.963037Z","iopub.execute_input":"2024-08-11T08:32:33.963453Z","iopub.status.idle":"2024-08-11T08:32:33.977280Z","shell.execute_reply.started":"2024-08-11T08:32:33.963430Z","shell.execute_reply":"2024-08-11T08:32:33.976498Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# quotes_train = QuotesDataset(quotes, token_to_id, MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.978465Z","iopub.execute_input":"2024-08-11T08:32:33.979044Z","iopub.status.idle":"2024-08-11T08:32:33.989252Z","shell.execute_reply.started":"2024-08-11T08:32:33.979013Z","shell.execute_reply":"2024-08-11T08:32:33.988390Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# len(quotes)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:33.990384Z","iopub.execute_input":"2024-08-11T08:32:33.990640Z","iopub.status.idle":"2024-08-11T08:32:34.003876Z","shell.execute_reply.started":"2024-08-11T08:32:33.990618Z","shell.execute_reply":"2024-08-11T08:32:34.002983Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# num_gpus = torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.004985Z","iopub.execute_input":"2024-08-11T08:32:34.005768Z","iopub.status.idle":"2024-08-11T08:32:34.016785Z","shell.execute_reply.started":"2024-08-11T08:32:34.005738Z","shell.execute_reply":"2024-08-11T08:32:34.016121Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# quotes_train_dataloader = DataLoader(\n#     quotes_train, \n#     batch_size=128, \n#     shuffle=True, \n#     num_workers=2 * num_gpus,  # 2 workers per GPU (adjust based on performance)\n#     pin_memory=True\n# )","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.018024Z","iopub.execute_input":"2024-08-11T08:32:34.018793Z","iopub.status.idle":"2024-08-11T08:32:34.029557Z","shell.execute_reply.started":"2024-08-11T08:32:34.018766Z","shell.execute_reply":"2024-08-11T08:32:34.028877Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# batch_ix = next(iter(quotes_train_dataloader))","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.790047Z","start_time":"2019-11-05T18:21:23.715167Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:34.030584Z","iopub.execute_input":"2024-08-11T08:32:34.030832Z","iopub.status.idle":"2024-08-11T08:32:34.044950Z","shell.execute_reply.started":"2024-08-11T08:32:34.030810Z","shell.execute_reply":"2024-08-11T08:32:34.044169Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# batch_ix.device","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.045970Z","iopub.execute_input":"2024-08-11T08:32:34.046228Z","iopub.status.idle":"2024-08-11T08:32:34.058762Z","shell.execute_reply.started":"2024-08-11T08:32:34.046207Z","shell.execute_reply":"2024-08-11T08:32:34.058104Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# batch_ix=batch_ix.to(device)\n# logp_seq = quotes_baseline_model(batch_ix)\n\n# # compute loss\n# loss = F.nll_loss(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n#                   batch_ix[:, :-1].contiguous().view(-1))\n\n# loss.backward()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.059744Z","iopub.execute_input":"2024-08-11T08:32:34.060000Z","iopub.status.idle":"2024-08-11T08:32:34.073640Z","shell.execute_reply.started":"2024-08-11T08:32:34.059978Z","shell.execute_reply":"2024-08-11T08:32:34.072966Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.074751Z","iopub.execute_input":"2024-08-11T08:32:34.075392Z","iopub.status.idle":"2024-08-11T08:32:34.093922Z","shell.execute_reply.started":"2024-08-11T08:32:34.075359Z","shell.execute_reply":"2024-08-11T08:32:34.093249Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.095031Z","iopub.execute_input":"2024-08-11T08:32:34.095835Z","iopub.status.idle":"2024-08-11T08:32:34.107649Z","shell.execute_reply.started":"2024-08-11T08:32:34.095802Z","shell.execute_reply":"2024-08-11T08:32:34.106883Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# num_epochs=20\n# for epoch in range(num_epochs):\n#     quotes_baseline_model.train()\n#     total_batches = len(quotes_train_dataloader)\n\n#     # Wrap DataLoader iterator with tqdm\n#     for i, batch_ix in enumerate(tqdm(quotes_train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", total=total_batches)):\n\n# #         batch_ix = to_matrix(sample(quotes, 32), token_to_id, max_len=MAX_LENGTH)\n# #         batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n#         curr_batch=batch_ix.to(device)\n\n#         logp_seq = quotes_baseline_model(curr_batch)\n\n#         # compute loss\n#         predictions_logp = logp_seq[:, :-1]\n#         actual_next_tokens = curr_batch[:, 1:]\n\n#         loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n\n#         # train with backprop\n#         loss.backward()\n#         opt.step()\n#         opt.zero_grad()\n\n#         # visualizing training process\n#         history.append(loss.cpu().data.numpy())\n#         if (i + 1) % 25 == 0:\n#             clear_output(True)\n#             plt.plot(history,label='loss')\n#             plt.legend()\n#             plt.show()\n\n#      # Validate the model and calculate the metric\n#     quotes_baseline_model.eval()\n#     val_loss = 0.0\n#     with torch.no_grad():\n#         for batch in quotes_train_dataloader:\n#             curr_batch=batch_ix.to(device)\n\n#             logp_seq = quotes_baseline_model(curr_batch)\n\n#             # compute loss\n#             predictions_logp = logp_seq[:, :-1]\n#             actual_next_tokens = curr_batch[:, 1:]\n\n#             loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n#             val_loss += loss.item()\n\n#     val_loss /= len(quotes_train_dataloader)\n#     print(f'Val loss: {val_loss}')\n    \n#     # Step the scheduler\n#     sched.step(val_loss)\n    \n#     assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\"","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.468107Z","start_time":"2019-11-05T18:21:23.792092Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:34.108920Z","iopub.execute_input":"2024-08-11T08:32:34.109164Z","iopub.status.idle":"2024-08-11T08:32:34.123404Z","shell.execute_reply.started":"2024-08-11T08:32:34.109143Z","shell.execute_reply":"2024-08-11T08:32:34.122603Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# # Assume your trained model is wrapped in DataParallel\n# trained_model = quotes_baseline_model\n\n# # Check if the model is wrapped with DataParallel\n# if isinstance(trained_model, nn.DataParallel):\n#     # Extract the original model\n#     trained_model = trained_model.module","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.124367Z","iopub.execute_input":"2024-08-11T08:32:34.124613Z","iopub.status.idle":"2024-08-11T08:32:34.143492Z","shell.execute_reply.started":"2024-08-11T08:32:34.124592Z","shell.execute_reply":"2024-08-11T08:32:34.142789Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# trained_model_cpu=trained_model.cpu()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.144578Z","iopub.execute_input":"2024-08-11T08:32:34.144837Z","iopub.status.idle":"2024-08-11T08:32:34.165984Z","shell.execute_reply.started":"2024-08-11T08:32:34.144816Z","shell.execute_reply":"2024-08-11T08:32:34.165134Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# trained_model_cpu.device=torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.167137Z","iopub.execute_input":"2024-08-11T08:32:34.167402Z","iopub.status.idle":"2024-08-11T08:32:34.180566Z","shell.execute_reply.started":"2024-08-11T08:32:34.167381Z","shell.execute_reply":"2024-08-11T08:32:34.179729Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# def generate_sample(char_torch_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n#     '''\n#     The function generates text given a phrase of length at least SEQ_LENGTH.\n#     :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n#     :param max_length: maximum output length, including seed_phrase\n#     :param temperature: coefficient for sampling. Higher temperature produces more chaotic outputs,\n#                         smaller temperature converges to the single most likely output\n#     '''\n    \n#     # Convert the seed phrase to a sequence of indices\n#     x_sequence = [token_to_id[token] for token in seed_phrase]\n#     x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n    \n#     # Initialize the hidden state\n#     hid_state = char_torch_rnn.initial_state(batch_size=1)\n    \n#     if seed_phrase!=' ':\n#         _, hid_state = char_torch_rnn.forward_hidden(x_sequence[:, len(seed_phrase)-2].unsqueeze(0))\n    \n#     # Start generating text\n#     generated_sequence = list(seed_phrase)  # Initialize with the seed phrase\n\n#     for _ in range(max_length - len(seed_phrase)):\n#         # Get the logits for the next character\n#         next_logits, _ = char_torch_rnn.forward_logits(x_sequence[:, -1].unsqueeze(0), hid_state)\n        \n#         # Apply temperature to logits\n#         next_logits = next_logits / temperature\n        \n#         # Calculate probabilities using softmax\n#         p_next = F.softmax(next_logits, dim=-1).data.cpu().numpy().flatten()\n#         # Sample the next character index from the probability distribution\n#         next_ix = np.random.choice(len(tokens), p=p_next)\n        \n#         # Append the sampled character to the generated sequence\n#         generated_sequence.append(tokens[next_ix])\n        \n#         # Update the input sequence with the new character\n#         next_ix_tensor = torch.tensor([[next_ix]], dtype=torch.int64)\n#         x_sequence = torch.cat([x_sequence, next_ix_tensor], dim=1)\n\n#         # Update hidden state for the next character\n#         _, hid_state = char_torch_rnn.forward_hidden(next_ix_tensor, hid_state)\n    \n#     return ''.join(generated_sequence)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.181828Z","iopub.execute_input":"2024-08-11T08:32:34.182101Z","iopub.status.idle":"2024-08-11T08:32:34.192888Z","shell.execute_reply.started":"2024-08-11T08:32:34.182079Z","shell.execute_reply":"2024-08-11T08:32:34.192190Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# quotes","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.194175Z","iopub.execute_input":"2024-08-11T08:32:34.194601Z","iopub.status.idle":"2024-08-11T08:32:34.210605Z","shell.execute_reply.started":"2024-08-11T08:32:34.194570Z","shell.execute_reply":"2024-08-11T08:32:34.209939Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# generate_sample(trained_model, seed_phrase='Life is ', temperature=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.211589Z","iopub.execute_input":"2024-08-11T08:32:34.211814Z","iopub.status.idle":"2024-08-11T08:32:34.225300Z","shell.execute_reply.started":"2024-08-11T08:32:34.211795Z","shell.execute_reply":"2024-08-11T08:32:34.224451Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"Наша посимвольная модель страдает фигней... <br>\nПопробуем вместо эмбеддинга символов использовать эмбеддинги FastText <br>\nТакже вместо rnn воспользуемся lstm или gru","metadata":{}},{"cell_type":"markdown","source":"## LSTM-based посимвольная модель","metadata":{}},{"cell_type":"code","source":"# class CharLSTMLoop(nn.Module):\n#     def __init__(self, device=device, num_tokens=num_tokens, emb_size=64, hidden_size=64, num_layers=1):\n#         super(self.__class__, self).__init__()\n#         self.device=device\n#         self.num_layers=num_layers\n#         self.hidden_size = hidden_size\n#         self.emb = nn.Embedding(num_tokens, emb_size)\n#         self.rnn = nn.LSTM(input_size=emb_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n#         self.hid_to_logits = nn.Linear(hidden_size, num_tokens)\n        \n#     def forward_logits(self, x, hidden_state=None):\n#         if hidden_state is None:\n#             hidden_state=self.initial_state(x.shape[0])\n        \n#         h_seq, hidden_state = self.rnn(self.emb(x), hidden_state)\n#         next_logits = self.hid_to_logits(h_seq)\n#         return next_logits, hidden_state\n        \n#     def forward_hidden(self, x, hidden_state=None):\n#         next_logits, hidden_state = self.forward_logits(x, hidden_state)\n#         next_logp = F.log_softmax(next_logits, dim=-1)\n#         return next_logp, hidden_state\n    \n#     def forward(self, x):\n#         next_logits, _ = self.forward_logits(x)\n#         return next_logits\n    \n#     def initial_state(self, batch_size):\n#         \"\"\"Return RNN state before it processes the first input (aka h0)\"\"\"\n#         # Initialize both hidden state (h_0) and cell state (c_0)\n#         h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n#         c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n#         return (h_0, c_0)\n    \n# quotes_char_lstm_model = CharLSTMLoop(emb_size=128, hidden_size=128, num_layers=2)\n# opt = torch.optim.Adam(quotes_char_lstm_model.parameters(), lr=1e-4)\n# sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.7, patience=2)\n# criterion = nn.CrossEntropyLoss()\n\n# history=[]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.226567Z","iopub.execute_input":"2024-08-11T08:32:34.226905Z","iopub.status.idle":"2024-08-11T08:32:34.238560Z","shell.execute_reply.started":"2024-08-11T08:32:34.226875Z","shell.execute_reply":"2024-08-11T08:32:34.237815Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# # Move model to the first GPU device\n# quotes_char_lstm_model = quotes_char_lstm_model.to(device)\n\n# # Use DataParallel to utilize multiple GPUs\n# if torch.cuda.device_count() > 1:\n#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n#     quotes_char_lstm_model = nn.DataParallel(quotes_char_lstm_model)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.239516Z","iopub.execute_input":"2024-08-11T08:32:34.239775Z","iopub.status.idle":"2024-08-11T08:32:34.254706Z","shell.execute_reply.started":"2024-08-11T08:32:34.239748Z","shell.execute_reply":"2024-08-11T08:32:34.253882Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# quotes_train_dataloader = DataLoader(\n#     quotes_train, \n#     batch_size=256, \n#     shuffle=True, \n#     num_workers=2 * num_gpus,  # 2 workers per GPU (adjust based on performance)\n#     pin_memory=True\n# )","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.255831Z","iopub.execute_input":"2024-08-11T08:32:34.256141Z","iopub.status.idle":"2024-08-11T08:32:34.272129Z","shell.execute_reply.started":"2024-08-11T08:32:34.256118Z","shell.execute_reply":"2024-08-11T08:32:34.271255Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# batch_ix = next(iter(quotes_train_dataloader))","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.790047Z","start_time":"2019-11-05T18:21:23.715167Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:34.273235Z","iopub.execute_input":"2024-08-11T08:32:34.273501Z","iopub.status.idle":"2024-08-11T08:32:34.284591Z","shell.execute_reply.started":"2024-08-11T08:32:34.273471Z","shell.execute_reply":"2024-08-11T08:32:34.283852Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# batch_ix.device","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.285710Z","iopub.execute_input":"2024-08-11T08:32:34.286019Z","iopub.status.idle":"2024-08-11T08:32:34.295567Z","shell.execute_reply.started":"2024-08-11T08:32:34.285993Z","shell.execute_reply":"2024-08-11T08:32:34.294666Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# batch_ix=batch_ix.to(device)\n# logp_seq = quotes_char_lstm_model(batch_ix)\n\n# # compute loss\n# loss = criterion(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n#                   batch_ix[:, :-1].contiguous().view(-1))\n\n# loss.backward()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.296933Z","iopub.execute_input":"2024-08-11T08:32:34.297512Z","iopub.status.idle":"2024-08-11T08:32:34.307413Z","shell.execute_reply.started":"2024-08-11T08:32:34.297487Z","shell.execute_reply":"2024-08-11T08:32:34.306609Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.308497Z","iopub.execute_input":"2024-08-11T08:32:34.308816Z","iopub.status.idle":"2024-08-11T08:32:34.317579Z","shell.execute_reply.started":"2024-08-11T08:32:34.308786Z","shell.execute_reply":"2024-08-11T08:32:34.316945Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.331966Z","iopub.execute_input":"2024-08-11T08:32:34.332240Z","iopub.status.idle":"2024-08-11T08:32:34.336973Z","shell.execute_reply.started":"2024-08-11T08:32:34.332216Z","shell.execute_reply":"2024-08-11T08:32:34.336152Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# num_epochs=100\n# best_model=None\n# best_loss=float('inf')\n# for epoch in range(num_epochs):\n#     quotes_char_lstm_model.train()\n#     total_batches = len(quotes_train_dataloader)\n\n#     # Wrap DataLoader iterator with tqdm\n#     for i, batch_ix in enumerate(tqdm(quotes_train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", total=total_batches)):\n\n# #         batch_ix = to_matrix(sample(quotes, 32), token_to_id, max_len=MAX_LENGTH)\n# #         batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n#         curr_batch=batch_ix.to(device)\n\n#         logp_seq = quotes_char_lstm_model(curr_batch)\n\n#         # compute loss\n#         predictions_logp = logp_seq[:, :-1]\n#         actual_next_tokens = curr_batch[:, 1:]\n\n#         loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n\n#         # train with backprop\n#         loss.backward()\n#         opt.step()\n#         opt.zero_grad()\n\n#         # visualizing training process\n#         history.append(loss.cpu().data.numpy())\n#         if (i + 1) % 25 == 0:\n#             clear_output(True)\n#             plt.plot(history,label='loss')\n#             plt.legend()\n#             plt.show()\n    \n#     # Validate the model and calculate the metric\n#     quotes_char_lstm_model.eval()\n#     val_loss = 0.0\n#     with torch.no_grad():\n#         for batch in quotes_train_dataloader:\n#             curr_batch=batch.to(device)\n\n#             logp_seq = quotes_char_lstm_model(curr_batch)\n\n#             # compute loss\n#             predictions_logp = logp_seq[:, :-1]\n#             actual_next_tokens = curr_batch[:, 1:]\n\n#             loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n#             val_loss += loss.item()\n\n#     val_loss /= len(quotes_train_dataloader)\n    \n#     if val_loss<best_loss:\n#         print(f'Новый лучший лосс: {val_loss}')\n#         best_loss=val_loss\n#         best_model=copy.deepcopy(quotes_char_lstm_model)\n    \n#     print(f'Текущий loss: {val_loss}')\n    \n#     # Step the scheduler\n#     sched.step(val_loss)\n\n#     assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\"","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.468107Z","start_time":"2019-11-05T18:21:23.792092Z"},"execution":{"iopub.status.busy":"2024-08-11T08:32:34.338298Z","iopub.execute_input":"2024-08-11T08:32:34.338936Z","iopub.status.idle":"2024-08-11T08:32:34.346832Z","shell.execute_reply.started":"2024-08-11T08:32:34.338905Z","shell.execute_reply":"2024-08-11T08:32:34.346178Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# # Assume your trained model is wrapped in DataParallel\n# trained_model = best_model\n# # train_model = quotes_char_lstm_model\n\n# # Check if the model is wrapped with DataParallel\n# if isinstance(trained_model, nn.DataParallel):\n#     # Extract the original model\n#     trained_model = trained_model.module","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.347907Z","iopub.execute_input":"2024-08-11T08:32:34.348159Z","iopub.status.idle":"2024-08-11T08:32:34.363210Z","shell.execute_reply.started":"2024-08-11T08:32:34.348137Z","shell.execute_reply":"2024-08-11T08:32:34.362523Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# trained_model_cpu=trained_model.cpu()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.364273Z","iopub.execute_input":"2024-08-11T08:32:34.364604Z","iopub.status.idle":"2024-08-11T08:32:34.376416Z","shell.execute_reply.started":"2024-08-11T08:32:34.364572Z","shell.execute_reply":"2024-08-11T08:32:34.375660Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# trained_model_cpu.device=torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.377282Z","iopub.execute_input":"2024-08-11T08:32:34.377528Z","iopub.status.idle":"2024-08-11T08:32:34.387989Z","shell.execute_reply.started":"2024-08-11T08:32:34.377507Z","shell.execute_reply":"2024-08-11T08:32:34.387042Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# def generate_sample(char_torch_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n#     '''\n#     The function generates text given a phrase of length at least SEQ_LENGTH.\n#     :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n#     :param max_length: maximum output length, including seed_phrase\n#     :param temperature: coefficient for sampling. Higher temperature produces more chaotic outputs,\n#                         smaller temperature converges to the single most likely output\n#     '''\n    \n#     # Convert the seed phrase to a sequence of indices\n#     x_sequence = [token_to_id.get(token, 0) for token in seed_phrase]  # Default to 0 if token not found\n#     x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(char_torch_rnn.device)\n    \n#     # Initialize the hidden state\n#     hid_state = char_torch_rnn.initial_state(batch_size=1)\n    \n#     # If seed_phrase is not just a space, update hidden state based on the seed_phrase\n#     if seed_phrase.strip() != '':\n#         _, hid_state = char_torch_rnn.forward_hidden(x_sequence, hid_state)\n    \n#     # Start generating text\n#     generated_sequence = list(seed_phrase)  # Initialize with the seed phrase\n\n#     for _ in range(max_length - len(seed_phrase)):\n#         # Get the logits for the next character\n#         next_logits, hid_state = char_torch_rnn.forward_logits(x_sequence[:, -1].unsqueeze(1), hid_state)\n        \n#         # Apply temperature to logits\n#         next_logits = next_logits / temperature\n        \n#         # Calculate probabilities using softmax\n#         p_next = F.softmax(next_logits.squeeze(1), dim=-1).data.cpu().numpy().flatten()\n        \n#         # Sample the next character index from the probability distribution\n#         next_ix = np.random.choice(len(token_to_id), p=p_next)\n        \n#         # Append the sampled character to the generated sequence\n#         generated_sequence.append(tokens[next_ix])\n        \n#         # Update the input sequence with the new character\n#         next_ix_tensor = torch.tensor([[next_ix]], dtype=torch.int64).to(char_torch_rnn.device)\n#         x_sequence = torch.cat([x_sequence, next_ix_tensor], dim=1)\n\n#         # Update hidden state for the next character\n#         _, hid_state = char_torch_rnn.forward_hidden(next_ix_tensor, hid_state)\n    \n#     return ''.join(generated_sequence)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.388897Z","iopub.execute_input":"2024-08-11T08:32:34.389142Z","iopub.status.idle":"2024-08-11T08:32:34.402953Z","shell.execute_reply.started":"2024-08-11T08:32:34.389122Z","shell.execute_reply":"2024-08-11T08:32:34.402219Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# quotes","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.403835Z","iopub.execute_input":"2024-08-11T08:32:34.404151Z","iopub.status.idle":"2024-08-11T08:32:34.420549Z","shell.execute_reply.started":"2024-08-11T08:32:34.404119Z","shell.execute_reply":"2024-08-11T08:32:34.419883Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# for t in np.linspace(1, 1.5, 10):\n#     print(generate_sample(trained_model, seed_phrase='Life ', temperature=t))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.421530Z","iopub.execute_input":"2024-08-11T08:32:34.421785Z","iopub.status.idle":"2024-08-11T08:32:34.432948Z","shell.execute_reply.started":"2024-08-11T08:32:34.421762Z","shell.execute_reply":"2024-08-11T08:32:34.432272Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"## Получается туфта, возьмем эмбеддинги fasttext","metadata":{}},{"cell_type":"markdown","source":"### Здесь подход следующий: на вход принимаем n-граммы, предсказываем следующий символ\nСходится, но генерируется туфта","metadata":{}},{"cell_type":"code","source":"# import fasttext\n# import fasttext.util\n\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# import gc","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:34.433982Z","iopub.execute_input":"2024-08-11T08:32:34.434265Z","iopub.status.idle":"2024-08-11T08:32:36.220294Z","shell.execute_reply.started":"2024-08-11T08:32:34.434234Z","shell.execute_reply":"2024-08-11T08:32:36.219504Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:36.221343Z","iopub.execute_input":"2024-08-11T08:32:36.221714Z","iopub.status.idle":"2024-08-11T08:32:52.771416Z","shell.execute_reply.started":"2024-08-11T08:32:36.221688Z","shell.execute_reply":"2024-08-11T08:32:52.770448Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"--2024-08-11 08:32:37--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.162.163.11, 3.162.163.34, 3.162.163.19, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.162.163.11|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4503593528 (4.2G) [application/octet-stream]\nSaving to: 'cc.en.300.bin.gz'\n\ncc.en.300.bin.gz    100%[===================>]   4.19G   252MB/s    in 15s     \n\n2024-08-11 08:32:52 (280 MB/s) - 'cc.en.300.bin.gz' saved [4503593528/4503593528]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# !gunzip cc.en.300.bin.gz","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:52.772956Z","iopub.execute_input":"2024-08-11T08:32:52.773311Z","iopub.status.idle":"2024-08-11T08:33:51.775918Z","shell.execute_reply.started":"2024-08-11T08:32:52.773280Z","shell.execute_reply":"2024-08-11T08:33:51.774657Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"# ft = fasttext.load_model('cc.en.300.bin') \n# ft.get_dimension()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:33:51.777531Z","iopub.execute_input":"2024-08-11T08:33:51.777861Z","iopub.status.idle":"2024-08-11T08:33:58.082910Z","shell.execute_reply.started":"2024-08-11T08:33:51.777821Z","shell.execute_reply":"2024-08-11T08:33:58.081789Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"300"},"metadata":{}}]},{"cell_type":"markdown","source":"Понизим размерность","metadata":{}},{"cell_type":"code","source":"# EMB_SIZE=100","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:33:58.084270Z","iopub.execute_input":"2024-08-11T08:33:58.084709Z","iopub.status.idle":"2024-08-11T08:33:58.094611Z","shell.execute_reply.started":"2024-08-11T08:33:58.084671Z","shell.execute_reply":"2024-08-11T08:33:58.093792Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# fasttext.util.reduce_model(ft, EMB_SIZE)\n# ft.get_dimension()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:33:58.095744Z","iopub.execute_input":"2024-08-11T08:33:58.096091Z","iopub.status.idle":"2024-08-11T08:34:14.381429Z","shell.execute_reply.started":"2024-08-11T08:33:58.096057Z","shell.execute_reply":"2024-08-11T08:34:14.380523Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}]},{"cell_type":"markdown","source":"Будем нашей моделью предсказывать следующий символ на основе n-грамм fasttext каждого слова","metadata":{}},{"cell_type":"markdown","source":"Весь текст токенизируем на слова и пунктуацию","metadata":{}},{"cell_type":"code","source":"# from nltk.tokenize import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:14.382727Z","iopub.execute_input":"2024-08-11T08:34:14.383121Z","iopub.status.idle":"2024-08-11T08:34:16.783932Z","shell.execute_reply.started":"2024-08-11T08:34:14.383085Z","shell.execute_reply":"2024-08-11T08:34:16.782903Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# quotes_tokenized = [word_tokenize(quote) for quote in quotes]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:16.785254Z","iopub.execute_input":"2024-08-11T08:34:16.785567Z","iopub.status.idle":"2024-08-11T08:34:29.111961Z","shell.execute_reply.started":"2024-08-11T08:34:16.785530Z","shell.execute_reply":"2024-08-11T08:34:29.111190Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# quotes_tokenized[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:29.113020Z","iopub.execute_input":"2024-08-11T08:34:29.113285Z","iopub.status.idle":"2024-08-11T08:34:29.120071Z","shell.execute_reply.started":"2024-08-11T08:34:29.113263Z","shell.execute_reply":"2024-08-11T08:34:29.119042Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"['If',\n 'you',\n 'live',\n 'to',\n 'be',\n 'a',\n 'hundred',\n ',',\n 'I',\n 'want',\n 'to',\n 'live',\n 'to',\n 'be',\n 'a',\n 'hundred',\n 'minus',\n 'one',\n 'day',\n 'so',\n 'I',\n 'never',\n 'have',\n 'to',\n 'live',\n 'without',\n 'you',\n '.']"},"metadata":{}}]},{"cell_type":"markdown","source":"Будем использовать n-граммы различных размеров","metadata":{}},{"cell_type":"code","source":"# import random\n# from typing import List, Dict\n\n# utils_tokens={'<PAD>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3}\n\n# def extract_ngrams_for_vocab(word, n):\n#     # Function to extract n-grams from text\n    \n#     # артикли и пунктуацию добавляем как есть\n#     if len(word)==1:\n#         return [word]\n#     ngrams = [word[i:i+n] for i in range(len(word) - n + 1)]\n#     return ngrams\n\n# def build_ngram_vocab(texts_tokenized, ns: List[int], utils_tokens=utils_tokens):\n#     ngram_to_index = utils_tokens.copy()\n#     ngram_to_index[' '] = len(ngram_to_index)\n#     index = len(ngram_to_index)\n#     for n in ns:\n#         for text in texts_tokenized:\n#             for word in text:\n#                 ngrams = extract_ngrams_for_vocab(word, n)\n#                 for ngram in ngrams:\n#                     if ngram not in ngram_to_index:\n#                         ngram_to_index[ngram] = index\n#                         index += 1\n#     return ngram_to_index\n\n# def build_char_vocab(texts, utils_tokens=utils_tokens):\n#     char_vocab=utils_tokens.copy()\n#     index = 0\n#     for text in texts:\n#         for ch in text:\n#             if ch not in char_vocab:\n#                 char_vocab[ch] = index\n#                 index += 1\n#     return char_vocab","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:16.401834Z","iopub.execute_input":"2024-08-11T09:08:16.402513Z","iopub.status.idle":"2024-08-11T09:08:16.411984Z","shell.execute_reply.started":"2024-08-11T09:08:16.402464Z","shell.execute_reply":"2024-08-11T09:08:16.411134Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"# CHAR_VOCAB = build_char_vocab(quotes)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:18.243585Z","iopub.execute_input":"2024-08-11T09:08:18.244440Z","iopub.status.idle":"2024-08-11T09:08:18.535020Z","shell.execute_reply.started":"2024-08-11T09:08:18.244407Z","shell.execute_reply":"2024-08-11T09:08:18.534042Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"# NUM_CHARS=len(CHAR_VOCAB)\n# NUM_CHARS","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:19.287534Z","iopub.execute_input":"2024-08-11T09:08:19.288332Z","iopub.status.idle":"2024-08-11T09:08:19.294174Z","shell.execute_reply.started":"2024-08-11T09:08:19.288286Z","shell.execute_reply":"2024-08-11T09:08:19.293332Z"},"trusted":true},"execution_count":191,"outputs":[{"execution_count":191,"output_type":"execute_result","data":{"text/plain":"89"},"metadata":{}}]},{"cell_type":"code","source":"# '<PAD>' in CHAR_VOCAB","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:20.183194Z","iopub.execute_input":"2024-08-11T09:08:20.183541Z","iopub.status.idle":"2024-08-11T09:08:20.190044Z","shell.execute_reply.started":"2024-08-11T09:08:20.183515Z","shell.execute_reply":"2024-08-11T09:08:20.189081Z"},"trusted":true},"execution_count":192,"outputs":[{"execution_count":192,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# import pickle","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:21.124362Z","iopub.execute_input":"2024-08-11T09:08:21.124716Z","iopub.status.idle":"2024-08-11T09:08:21.128768Z","shell.execute_reply.started":"2024-08-11T09:08:21.124687Z","shell.execute_reply":"2024-08-11T09:08:21.127897Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"# CHAR_VOCAB={}\n# with open('models/task4_RNN_name_generator/char_vocab_dict.pkl', 'rb') as f:\n#     CHAR_VOCAB=pickle.load(f)\n\n# NUM_CHARS = len(CHAR_VOCAB)\n# NUM_CHARS","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:21.919814Z","iopub.execute_input":"2024-08-11T09:08:21.920528Z","iopub.status.idle":"2024-08-11T09:08:21.924468Z","shell.execute_reply.started":"2024-08-11T09:08:21.920496Z","shell.execute_reply":"2024-08-11T09:08:21.923476Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"# # Sample text data\n# # texts = [\"sample sentence for n-gram extraction\", \"another example sentence\"]\n\n# # Build vocabulary for bigrams (2-grams)\n# NGRAMS=[1, 2, 3, 4]\n# NGRAM_VOCAB = build_ngram_vocab(quotes_tokenized, NGRAMS)\n\n# # NGRAM_VOCAB={}\n# # with open('models/task4_RNN_name_generator/ngram_vocab_dict.pkl', 'rb') as f:\n# #     NGRAM_VOCAB=pickle.load(f)\n\n# NUM_NGRAMS = len(NGRAM_VOCAB)\n# NUM_NGRAMS","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:22.763191Z","iopub.execute_input":"2024-08-11T09:08:22.763909Z","iopub.status.idle":"2024-08-11T09:08:30.437292Z","shell.execute_reply.started":"2024-08-11T09:08:22.763875Z","shell.execute_reply":"2024-08-11T09:08:30.436325Z"},"trusted":true},"execution_count":195,"outputs":[{"execution_count":195,"output_type":"execute_result","data":{"text/plain":"39160"},"metadata":{}}]},{"cell_type":"code","source":"# # Create an embedding matrix for n-grams\n# def create_ngram_embedding_matrix(ngram_vocab, ft):\n#     emb_size = ft.get_dimension()\n#     embedding_matrix = torch.zeros((len(ngram_vocab), emb_size))\n#     for ngram, idx in ngram_vocab.items():\n#         embedding_matrix[idx] = torch.tensor(ft.get_word_vector(ngram))\n#     return embedding_matrix\n\n# # Generate embedding matrix\n# EMBEDDING_MATRIX = create_ngram_embedding_matrix(NGRAM_VOCAB, ft)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:33.522988Z","iopub.execute_input":"2024-08-11T09:08:33.523808Z","iopub.status.idle":"2024-08-11T09:08:34.474668Z","shell.execute_reply.started":"2024-08-11T09:08:33.523776Z","shell.execute_reply":"2024-08-11T09:08:34.473896Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"# EMBEDDING_MATRIX.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:34.750048Z","iopub.execute_input":"2024-08-11T09:08:34.750384Z","iopub.status.idle":"2024-08-11T09:08:34.755971Z","shell.execute_reply.started":"2024-08-11T09:08:34.750359Z","shell.execute_reply":"2024-08-11T09:08:34.755084Z"},"trusted":true},"execution_count":197,"outputs":[{"execution_count":197,"output_type":"execute_result","data":{"text/plain":"torch.Size([39160, 100])"},"metadata":{}}]},{"cell_type":"markdown","source":"Каждое предложение представляется всеми возможными n-граммами - новый слой - новый тип n-грам <br>\nВажно заметить, что n-граммы не пересекаются","metadata":{}},{"cell_type":"code","source":"# def extract_ngrams(word: str, n: int) -> List[str]:\n#     ngrams = []\n    \n#     # Iterate over possible start position of n-grams in the text\n#     for start in range(0, len(word), n):\n#         # Ensure the size does not exceed the remaining length of the text\n#         if start + n <= len(word):\n#             ngram = word[start:start + n]\n#             ngrams.append(ngram)\n    \n#     return ngrams","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:49.748418Z","iopub.execute_input":"2024-08-11T09:08:49.748797Z","iopub.status.idle":"2024-08-11T09:08:49.754530Z","shell.execute_reply.started":"2024-08-11T09:08:49.748765Z","shell.execute_reply":"2024-08-11T09:08:49.753632Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"markdown","source":"Напишим класс датасета","metadata":{}},{"cell_type":"code","source":"# from torch.utils.data import Dataset, DataLoader\n# import re","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:51.599131Z","iopub.execute_input":"2024-08-11T09:08:51.599522Z","iopub.status.idle":"2024-08-11T09:08:51.603886Z","shell.execute_reply.started":"2024-08-11T09:08:51.599493Z","shell.execute_reply":"2024-08-11T09:08:51.602969Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"markdown","source":"Вычислим максимальную длину предложения в символах:","metadata":{}},{"cell_type":"code","source":"# MAX_LEN = 0\n# for quote_tokenized in quotes_tokenized:\n#     curr_len=len(utils_tokens)\n#     for word in quote_tokenized:\n#         curr_len+=len(word)\n#         curr_len+=1\n#     if curr_len>MAX_LEN:\n# #         print(quote)\n#         MAX_LEN=curr_len","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:34:44.185114Z","iopub.execute_input":"2024-08-11T09:34:44.185925Z","iopub.status.idle":"2024-08-11T09:34:44.540612Z","shell.execute_reply.started":"2024-08-11T09:34:44.185869Z","shell.execute_reply":"2024-08-11T09:34:44.539848Z"},"trusted":true},"execution_count":291,"outputs":[]},{"cell_type":"code","source":"# MAX_LEN","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:34:46.329691Z","iopub.execute_input":"2024-08-11T09:34:46.330068Z","iopub.status.idle":"2024-08-11T09:34:46.335889Z","shell.execute_reply.started":"2024-08-11T09:34:46.330039Z","shell.execute_reply":"2024-08-11T09:34:46.334896Z"},"trusted":true},"execution_count":292,"outputs":[{"execution_count":292,"output_type":"execute_result","data":{"text/plain":"423"},"metadata":{}}]},{"cell_type":"code","source":"# import torch\n# from torch.utils.data import Dataset\n\n# class NGramDataset(Dataset):\n#     def __init__(self, sentences, ngram_vocab=NGRAM_VOCAB, ns=NGRAMS, char_vocab=CHAR_VOCAB, utils_tokens=utils_tokens, max_len=MAX_LEN):\n#         \"\"\"\n#         Args:\n#             sentences (list of str): List of sentences (each sentence is a string).\n#             ngram_vocab (dict): Dictionary mapping n-grams to indices.\n#             n (int): Size of the n-grams (e.g., 2 for bigrams).\n#         \"\"\"\n#         self.sentences = sentences\n#         self.utils_tokens=utils_tokens.copy()\n#         self.char_vocab = char_vocab.copy()\n#         self.ngram_vocab = ngram_vocab.copy()\n        \n#         self.id_to_token = {val:key for key,val in ngram_vocab.items()}\n        \n#         self.ns = ns\n        \n#         self.max_len=max_len\n\n#     def __len__(self):\n#         return len(self.sentences)\n\n#     def __getitem__(self, idx):\n#         sentence = self.sentences[idx]\n        \n#         # Convert sentence to n-grams and character IDs\n#         ngram_tensor = self.sent_to_ngrams(sentence)\n#         char_tensor = self.sent_to_char_ids(sentence)\n\n#         # Assert to ensure dimensions match\n#         assert ngram_tensor.shape[1] == char_tensor.shape[0], \\\n#             f\"Dimension mismatch: ngram_tensor shape: {ngram_tensor.shape}, char_tensor shape: {char_tensor.shape} \\n {sentence}\"\n\n#         return ngram_tensor, char_tensor\n    \n#     def sent_to_ngrams(self, sentence_tokenized):\n#         \"\"\"Prepare a sentence as embeddings with padding.\"\"\"\n#         ngrams = []\n\n#         for n in self.ns:\n#             new_ngrams = [self.utils_tokens['<BEGIN>']]\n#             for word in sentence_tokenized:\n#                 new_ngrams.extend(extract_ngrams(word, n))\n#                 new_ngrams.append(' ')\n#             new_ngrams.pop()  # Удаляем последний пробел\n#             new_ngrams.append(self.utils_tokens['<END>'])\n\n#             ngrams.append(new_ngrams)\n\n#         indices = []\n#         pad_index = self.utils_tokens.get('<PAD>')\n\n#         for ngram_list in ngrams:\n#             # Преобразуем n-граммы в индексы\n#             layer_indices = [self.ngram_vocab.get(ngram, self.utils_tokens.get('<UNK>')) for ngram in ngram_list]\n\n#             # Добавляем паддинг до максимальной длины в символах\n#             layer_indices.extend([pad_index] * (self.max_len - len(layer_indices)))\n\n#             indices.append(layer_indices)\n\n#         # Преобразуем список в тензор с размерностью [количество n-грамм, максимальная длина последовательности]\n#         return torch.LongTensor(indices)\n    \n#     def sent_to_char_ids(self, sentence_tokenized):\n#         char_ids=[self.utils_tokens['<BEGIN>']]\n#         for word in sentence_tokenized:\n#             word_ids = [self.char_vocab.get(char, self.utils_tokens.get('<UNK>')) for char in word]\n#             char_ids.extend(word_ids)\n#             char_ids.append(self.char_vocab[' '])\n#         char_ids.pop()\n#         char_ids.append(self.utils_tokens['<END>'])\n        \n#         pad_index = self.utils_tokens.get('<PAD>')\n\n#         # Добавляем паддинг до максимальной длины в символах\n#         char_ids.extend([pad_index] * (self.max_len - len(char_ids)))\n        \n#         return torch.LongTensor(char_ids)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:46:48.876126Z","iopub.execute_input":"2024-08-11T09:46:48.876554Z","iopub.status.idle":"2024-08-11T09:46:48.893824Z","shell.execute_reply.started":"2024-08-11T09:46:48.876521Z","shell.execute_reply":"2024-08-11T09:46:48.892907Z"},"trusted":true},"execution_count":340,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:34:48.029092Z","iopub.execute_input":"2024-08-11T09:34:48.029460Z","iopub.status.idle":"2024-08-11T09:34:48.033826Z","shell.execute_reply.started":"2024-08-11T09:34:48.029431Z","shell.execute_reply":"2024-08-11T09:34:48.032924Z"},"trusted":true},"execution_count":294,"outputs":[]},{"cell_type":"code","source":"# X_train, X_test = train_test_split(quotes_tokenized, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:34:48.654862Z","iopub.execute_input":"2024-08-11T09:34:48.655203Z","iopub.status.idle":"2024-08-11T09:34:48.673357Z","shell.execute_reply.started":"2024-08-11T09:34:48.655177Z","shell.execute_reply":"2024-08-11T09:34:48.672366Z"},"trusted":true},"execution_count":295,"outputs":[]},{"cell_type":"code","source":"# quotes_train_dataset = NGramDataset(X_train, NGRAM_VOCAB, NGRAMS, CHAR_VOCAB, utils_tokens, MAX_LEN)\n# quotes_val_dataset = NGramDataset(X_test, NGRAM_VOCAB, NGRAMS, CHAR_VOCAB, utils_tokens, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:34:49.206494Z","iopub.execute_input":"2024-08-11T09:34:49.206808Z","iopub.status.idle":"2024-08-11T09:34:49.224814Z","shell.execute_reply.started":"2024-08-11T09:34:49.206784Z","shell.execute_reply":"2024-08-11T09:34:49.223781Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:34:49.804582Z","iopub.execute_input":"2024-08-11T09:34:49.804970Z","iopub.status.idle":"2024-08-11T09:34:49.809799Z","shell.execute_reply.started":"2024-08-11T09:34:49.804937Z","shell.execute_reply":"2024-08-11T09:34:49.808899Z"},"trusted":true},"execution_count":297,"outputs":[]},{"cell_type":"code","source":"# NUM_NGRAMS","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:34:50.347084Z","iopub.execute_input":"2024-08-11T09:34:50.347424Z","iopub.status.idle":"2024-08-11T09:34:50.353472Z","shell.execute_reply.started":"2024-08-11T09:34:50.347395Z","shell.execute_reply":"2024-08-11T09:34:50.352512Z"},"trusted":true},"execution_count":298,"outputs":[{"execution_count":298,"output_type":"execute_result","data":{"text/plain":"39160"},"metadata":{}}]},{"cell_type":"code","source":"# class FastTextEmbLSTMLoop(nn.Module):\n#     def __init__(self, device='cpu', num_tokens=NUM_CHARS, num_embs=NUM_NGRAMS, emb_size=EMB_SIZE, hidden_size=128, num_layers=2, embedding_matrix=None):\n#         super(FastTextEmbLSTMLoop, self).__init__()\n#         self.device = device\n#         self.num_embs = num_embs\n#         self.num_tokens = num_tokens\n#         self.num_layers = num_layers\n#         self.hidden_size = hidden_size\n        \n#         # Initialize n-gram embedding layer\n#         self.emb = nn.Embedding(num_embs, emb_size)\n#         if embedding_matrix is not None:\n#             assert emb_size == embedding_matrix.shape[1]\n#             self.emb.weight.data.copy_(embedding_matrix)\n#             self.emb.weight.requires_grad = True  # Optional: set to True if you want to fine-tune embeddings\n        \n#         # RNN and Linear layers\n#         self.rnn = nn.LSTM(input_size=emb_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=0.5)\n        \n#         self.to_logits = nn.Sequential(\n#             nn.Linear(self.hidden_size, self.hidden_size),  # First hidden layer\n#             nn.ReLU(),  # Activation function\n#             nn.Dropout(0.5),  # Dropout for regularization\n#             nn.Linear(self.hidden_size, self.num_tokens),  # Second hidden layer\n#         )\n        \n#     def forward(self, ngram_tensor):\n#         combined_logits, hidden_state = self.forward_hidden(ngram_tensor)\n#         return combined_logits\n    \n#     def forward_hidden(self, ngram_tensor, hidden_state=None):\n#         \"\"\"\n#         Process a 3D tensor of n-grams of different sizes and return logits for the next symbol.\n        \n#         :param ngram_tensor: A 3D tensor with shape [batch_size, num_ngram_types, seq_len].\n#         :param hidden_state: Tuple (h_0, c_0) containing the hidden state of the LSTM.\n#         :return: Logits for the next symbol and updated hidden state.\n#         \"\"\"\n#         batch_size, num_ngram_types, seq_len = ngram_tensor.size()\n        \n#         # Initialize hidden state for the batch if not provided\n#         if hidden_state is None:\n#             hidden_state = self.initial_state(batch_size)\n        \n#         # List to collect logits for each n-gram size\n#         all_logits = []\n#         all_hidden_h = []\n#         all_hidden_c = []\n        \n#         for i in range(num_ngram_types):\n#             tensor = ngram_tensor[:, i, :]  # Select n-grams of the i-th type\n            \n#             # Apply embedding layer\n#             x_embedded = self.emb(tensor)\n            \n#             # Use forward_hidden_util to get logits and update hidden state\n#             curr_logits, curr_hidden_state = self.forward_hidden_util(x_embedded, hidden_state)\n            \n#             # Collect logits\n#             all_logits.append(curr_logits)\n            \n#             all_hidden_h.append(curr_hidden_state[0])\n#             all_hidden_c.append(curr_hidden_state[1])\n        \n#         # Stack logits from different n-gram sizes\n#         all_logits = torch.stack(all_logits, dim=1)  # Shape: [batch_size, num_ngram_types, seq_len, num_tokens]\n        \n#         all_hidden_h = torch.stack(all_hidden_h, dim=1)\n#         all_hidden_c = torch.stack(all_hidden_c, dim=1)\n        \n#         # Combine logits from different n-gram sizes\n# #         combined_logits = all_logits.mean(dim=1)  # Aggregate over different n-gram sizes\n        \n#         return all_logits.mean(dim=1), (all_hidden_h.mean(dim=1), all_hidden_c.mean(dim=1))\n\n#     def forward_hidden_util(self, x_embedded, hidden_state=None):\n#         \"\"\"\n#         Process a batch of sequences and update the hidden state.\n        \n#         :param x: A tensor containing the sequences.\n#         :param hidden_state: Tuple (h_0, c_0) containing the hidden state of the LSTM.\n#         :return: next_logp (log probabilities of the next token), hidden_state (updated hidden state).\n#         \"\"\"\n#         if hidden_state is None:\n#             hidden_state = self.initial_state(x_embedded.size(0))\n        \n#         # RNN forward pass\n#         h_seq, hidden_state = self.rnn(x_embedded, hidden_state)\n        \n#         # Compute logits from the last hidden state of each sequence\n#         next_logits = self.to_logits(h_seq)  # Use the sequence's hidden states\n        \n#         return next_logits, hidden_state\n\n#     def initial_state(self, batch_size):\n#         \"\"\"Return RNN state before it processes the first input (aka h0)\"\"\"\n#         h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n#         c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n#         return (h_0, c_0)\n\n#     def generate_sample(self, seed_phrase=' ', temperature=1.0, max_length=100, quotes_train_dataset=None):\n#         '''\n#         Generate text starting with a given seed phrase using the RNN model.\n\n#         :param seed_phrase: The initial phrase to start text generation.\n#         :param temperature: Coefficient to adjust the probability distribution. Higher temperature means more randomness.\n#         :param max_length: Maximum length of the generated text (including seed_phrase).\n#         :param quotes_train_dataset: The dataset containing token-to-id mappings and id-to-token mappings.\n#         :return: Generated text.\n#         '''\n#         with torch.no_grad():\n\n#             # Convert seed_phrase to token IDs and n-grams\n#             seed_phrase_tokenized = word_tokenize(seed_phrase)\n#             x_sequence = quotes_train_dataset.sent_to_ngrams(seed_phrase_tokenized).unsqueeze(0)\n\n#             # Initialize hidden state\n#             hid_state = self.initial_state(batch_size=1)\n\n#             # If seed_phrase is not just a space, update hidden state based on the seed_phrase\n#             if seed_phrase.strip() != '':\n#                 _, hid_state = self.forward_hidden(x_sequence, hid_state)\n\n#             # Start generating text\n#             generated_sequence = list(seed_phrase)\n\n#             char_vocab_reversed = {val: key for key, val in quotes_train_dataset.char_vocab.items()}\n\n#             # Convert the seed_phrase to its last token ID for the generation loop\n#             # Get the last n-gram slice from x_sequence\n#             current_ngram_tensor = x_sequence[:, -1, :].unsqueeze(1)  # Shape: [1, num_ngram_types, seq_len]\n\n#             for i in range(max_length - len(seed_phrase)):\n#                 # Get logits and update hidden state\n#                 next_logits, hid_state = self.forward_hidden(current_ngram_tensor, hid_state)\n# #                 print(next_logits.squeeze(0).shape)\n                \n#                 # Apply temperature to logits for scaling\n#                 next_logits = next_logits / temperature\n\n#                 # Convert logits to probabilities\n#                 p_next = F.softmax(next_logits.squeeze(0), dim=-1).cpu().numpy()\n# #                 print(p_next.shape)\n# #                 print(p_next.shape, len(quotes_train_dataset.char_vocab))\n\n#                 # Sample the next token index based on the probability distribution\n#                 next_ix = np.random.choice(len(quotes_train_dataset.char_vocab), p=p_next[i, :])\n\n#                 # Decode the next token ID to a character\n#                 next_char = char_vocab_reversed[next_ix]\n\n#                 # Append the new character to the generated sequence\n#                 generated_sequence.append(next_char)\n\n#                 # Update current_ngram_tensor with the new character\n#                 current_ngram_tensor = quotes_train_dataset.sent_to_ngrams(generated_sequence).unsqueeze(0)\n\n#             return ''.join(generated_sequence)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:39.962175Z","iopub.execute_input":"2024-08-11T09:41:39.962566Z","iopub.status.idle":"2024-08-11T09:41:39.991350Z","shell.execute_reply.started":"2024-08-11T09:41:39.962534Z","shell.execute_reply":"2024-08-11T09:41:39.990320Z"},"trusted":true},"execution_count":328,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:49.246481Z","iopub.execute_input":"2024-08-11T09:41:49.247563Z","iopub.status.idle":"2024-08-11T09:41:49.251626Z","shell.execute_reply.started":"2024-08-11T09:41:49.247526Z","shell.execute_reply":"2024-08-11T09:41:49.250645Z"},"trusted":true},"execution_count":329,"outputs":[]},{"cell_type":"code","source":"# num_gpus = torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:50.276250Z","iopub.execute_input":"2024-08-11T09:41:50.277226Z","iopub.status.idle":"2024-08-11T09:41:50.281341Z","shell.execute_reply.started":"2024-08-11T09:41:50.277192Z","shell.execute_reply":"2024-08-11T09:41:50.280416Z"},"trusted":true},"execution_count":330,"outputs":[]},{"cell_type":"code","source":"# quotes_train_dataloader = DataLoader(\n#     quotes_train_dataset, \n#     batch_size=128, \n#     shuffle=True, \n#     num_workers=2 * num_gpus,  # 2 workers per GPU (adjust based on performance)\n#     pin_memory=True\n# )\n\n# quotes_val_dataloader = DataLoader(\n#     quotes_val_dataset, \n#     batch_size=128, \n#     num_workers=2 * num_gpus,  # 2 workers per GPU (adjust based on performance)\n#     pin_memory=True\n# )","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:51.085572Z","iopub.execute_input":"2024-08-11T09:41:51.086194Z","iopub.status.idle":"2024-08-11T09:41:51.091610Z","shell.execute_reply.started":"2024-08-11T09:41:51.086161Z","shell.execute_reply":"2024-08-11T09:41:51.090662Z"},"trusted":true},"execution_count":331,"outputs":[]},{"cell_type":"code","source":"# EMBEDDING_MATRIX.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:52.470337Z","iopub.execute_input":"2024-08-11T09:41:52.470969Z","iopub.status.idle":"2024-08-11T09:41:52.476625Z","shell.execute_reply.started":"2024-08-11T09:41:52.470937Z","shell.execute_reply":"2024-08-11T09:41:52.475783Z"},"trusted":true},"execution_count":332,"outputs":[{"execution_count":332,"output_type":"execute_result","data":{"text/plain":"torch.Size([39160, 100])"},"metadata":{}}]},{"cell_type":"code","source":"# ft_emb_lstm_model = FastTextEmbLSTMLoop(device, num_tokens=NUM_CHARS, emb_size=EMB_SIZE, hidden_size=256, num_layers=4, embedding_matrix=EMBEDDING_MATRIX)\n\n# opt = torch.optim.Adam(ft_emb_lstm_model.parameters(), lr=1e-4)\n# sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.4, patience=2)\n# criterion = nn.CrossEntropyLoss()\n\n# history=[]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:53.372309Z","iopub.execute_input":"2024-08-11T09:41:53.372678Z","iopub.status.idle":"2024-08-11T09:41:53.443124Z","shell.execute_reply.started":"2024-08-11T09:41:53.372647Z","shell.execute_reply":"2024-08-11T09:41:53.442384Z"},"trusted":true},"execution_count":333,"outputs":[]},{"cell_type":"code","source":"# # Move model to the first GPU device\n# ft_emb_lstm_model = ft_emb_lstm_model.to(device)\n\n# # Use DataParallel to utilize multiple GPUs\n# if torch.cuda.device_count() > 1:\n#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n#     ft_emb_lstm_model = nn.DataParallel(ft_emb_lstm_model)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:57.354886Z","iopub.execute_input":"2024-08-11T09:41:57.355570Z","iopub.status.idle":"2024-08-11T09:41:57.362994Z","shell.execute_reply.started":"2024-08-11T09:41:57.355538Z","shell.execute_reply":"2024-08-11T09:41:57.362098Z"},"trusted":true},"execution_count":334,"outputs":[{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Теперь для подсчета лосса мне нужно разобрать каждое предложение на n-граммы","metadata":{}},{"cell_type":"code","source":"# batch_ix, batch_iy = next(iter(quotes_train_dataloader))","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.790047Z","start_time":"2019-11-05T18:21:23.715167Z"},"execution":{"iopub.status.busy":"2024-08-11T09:35:01.367675Z","iopub.execute_input":"2024-08-11T09:35:01.368451Z","iopub.status.idle":"2024-08-11T09:35:01.981579Z","shell.execute_reply.started":"2024-08-11T09:35:01.368418Z","shell.execute_reply":"2024-08-11T09:35:01.980209Z"},"trusted":true},"execution_count":306,"outputs":[]},{"cell_type":"code","source":"# batch_ix.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:02.478124Z","iopub.execute_input":"2024-08-11T09:35:02.478513Z","iopub.status.idle":"2024-08-11T09:35:02.485452Z","shell.execute_reply.started":"2024-08-11T09:35:02.478483Z","shell.execute_reply":"2024-08-11T09:35:02.484394Z"},"trusted":true},"execution_count":307,"outputs":[{"execution_count":307,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 4, 423])"},"metadata":{}}]},{"cell_type":"code","source":"# MAX_LEN","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:03.533988Z","iopub.execute_input":"2024-08-11T09:35:03.534761Z","iopub.status.idle":"2024-08-11T09:35:03.540493Z","shell.execute_reply.started":"2024-08-11T09:35:03.534731Z","shell.execute_reply":"2024-08-11T09:35:03.539565Z"},"trusted":true},"execution_count":308,"outputs":[{"execution_count":308,"output_type":"execute_result","data":{"text/plain":"423"},"metadata":{}}]},{"cell_type":"code","source":"# batch_iy.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:04.517424Z","iopub.execute_input":"2024-08-11T09:35:04.518108Z","iopub.status.idle":"2024-08-11T09:35:04.523819Z","shell.execute_reply.started":"2024-08-11T09:35:04.518075Z","shell.execute_reply":"2024-08-11T09:35:04.522806Z"},"trusted":true},"execution_count":309,"outputs":[{"execution_count":309,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 423])"},"metadata":{}}]},{"cell_type":"code","source":"# batch_ix.device","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:05.604588Z","iopub.execute_input":"2024-08-11T09:35:05.604965Z","iopub.status.idle":"2024-08-11T09:35:05.610864Z","shell.execute_reply.started":"2024-08-11T09:35:05.604935Z","shell.execute_reply":"2024-08-11T09:35:05.610006Z"},"trusted":true},"execution_count":310,"outputs":[{"execution_count":310,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"# curr_batch_ix=batch_ix.to(device)\n# curr_batch_iy=batch_iy.to(device)\n\n# logp_seq = ft_emb_lstm_model(curr_batch_ix)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:06.685003Z","iopub.execute_input":"2024-08-11T09:35:06.685929Z","iopub.status.idle":"2024-08-11T09:35:06.941646Z","shell.execute_reply.started":"2024-08-11T09:35:06.685882Z","shell.execute_reply":"2024-08-11T09:35:06.940858Z"},"trusted":true},"execution_count":311,"outputs":[]},{"cell_type":"code","source":"# logp_seq.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:07.944753Z","iopub.execute_input":"2024-08-11T09:35:07.945147Z","iopub.status.idle":"2024-08-11T09:35:07.951207Z","shell.execute_reply.started":"2024-08-11T09:35:07.945116Z","shell.execute_reply":"2024-08-11T09:35:07.950291Z"},"trusted":true},"execution_count":312,"outputs":[{"execution_count":312,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 423, 89])"},"metadata":{}}]},{"cell_type":"code","source":"# # compute loss\n# predictions_logp = logp_seq[:, :-1]\n# curr_batch_iy = curr_batch_iy[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:08.998540Z","iopub.execute_input":"2024-08-11T09:35:08.999262Z","iopub.status.idle":"2024-08-11T09:35:09.004921Z","shell.execute_reply.started":"2024-08-11T09:35:08.999211Z","shell.execute_reply":"2024-08-11T09:35:09.003795Z"},"trusted":true},"execution_count":313,"outputs":[]},{"cell_type":"code","source":"# predictions_logp.shape, curr_batch_iy.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:10.239290Z","iopub.execute_input":"2024-08-11T09:35:10.239987Z","iopub.status.idle":"2024-08-11T09:35:10.245831Z","shell.execute_reply.started":"2024-08-11T09:35:10.239955Z","shell.execute_reply":"2024-08-11T09:35:10.245001Z"},"trusted":true},"execution_count":314,"outputs":[{"execution_count":314,"output_type":"execute_result","data":{"text/plain":"(torch.Size([128, 422, 89]), torch.Size([128, 422]))"},"metadata":{}}]},{"cell_type":"code","source":"# loss = criterion(predictions_logp.permute(0,2,1), curr_batch_iy)\n\n# loss.backward()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:11.347241Z","iopub.execute_input":"2024-08-11T09:35:11.347628Z","iopub.status.idle":"2024-08-11T09:35:11.675048Z","shell.execute_reply.started":"2024-08-11T09:35:11.347598Z","shell.execute_reply":"2024-08-11T09:35:11.674066Z"},"trusted":true},"execution_count":315,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:14.603317Z","iopub.execute_input":"2024-08-11T09:35:14.603685Z","iopub.status.idle":"2024-08-11T09:35:14.608471Z","shell.execute_reply.started":"2024-08-11T09:35:14.603657Z","shell.execute_reply":"2024-08-11T09:35:14.607486Z"},"trusted":true},"execution_count":316,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:15.782739Z","iopub.execute_input":"2024-08-11T09:35:15.783598Z","iopub.status.idle":"2024-08-11T09:35:15.787659Z","shell.execute_reply.started":"2024-08-11T09:35:15.783564Z","shell.execute_reply":"2024-08-11T09:35:15.786559Z"},"trusted":true},"execution_count":317,"outputs":[]},{"cell_type":"code","source":"# import copy","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:16.977803Z","iopub.execute_input":"2024-08-11T09:35:16.978523Z","iopub.status.idle":"2024-08-11T09:35:16.983269Z","shell.execute_reply.started":"2024-08-11T09:35:16.978491Z","shell.execute_reply":"2024-08-11T09:35:16.982219Z"},"trusted":true},"execution_count":318,"outputs":[]},{"cell_type":"code","source":"# num_epochs=100\n# best_model=None\n# best_loss=float('inf')\n# for epoch in range(num_epochs):\n#     ft_emb_lstm_model.train()\n#     total_batches = len(quotes_train_dataloader)\n\n#     # Wrap DataLoader iterator with tqdm\n#     for i, (batch_ix, batch_iy) in enumerate(tqdm(quotes_train_dataloader, desc=f\"Train: Epoch {epoch+1}/{num_epochs}\", total=total_batches)):\n\n# #         batch_ix = to_matrix(sample(quotes, 32), token_to_id, max_len=MAX_LENGTH)\n# #         batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n#         curr_batch_ix=batch_ix.to(device)\n#         curr_batch_iy=batch_iy.to(device)\n\n#         logp_seq = ft_emb_lstm_model(curr_batch_ix)\n\n#         # compute loss\n#         predictions_logp = logp_seq[:, :-1]\n#         actual_next_tokens = curr_batch_iy[:, 1:]\n\n#         loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n\n#         # train with backprop\n#         opt.zero_grad()\n#         loss.backward()\n#         opt.step()\n\n#         # visualizing training process\n#         history.append(loss.cpu().data.numpy())\n#         if (i + 1) % 25 == 0:\n#             clear_output(True)\n#             plt.plot(history,label='loss')\n#             plt.legend()\n#             plt.show()\n    \n#     # Validate the model and calculate the metric\n#     ft_emb_lstm_model.eval()\n#     val_loss = 0.0\n#     with torch.no_grad():\n#         for (batch_ix, batch_iy) in tqdm(quotes_val_dataloader, desc=f\"Validation: Epoch {epoch+1}/{num_epochs}\", total=len(quotes_val_dataloader)):\n#             curr_batch_ix=batch_ix.to(device)\n#             curr_batch_iy=batch_iy.to(device)\n\n#             logp_seq = ft_emb_lstm_model(curr_batch_ix)\n\n#             # compute loss\n#             predictions_logp = logp_seq[:, :-1]\n#             actual_next_tokens = curr_batch_iy[:, 1:]\n\n#             loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n#             val_loss += loss.item()\n\n#     val_loss /= len(quotes_val_dataloader)\n    \n#     if val_loss<best_loss:\n#         print(f'Новый лучший val лосс: {val_loss}')\n#         best_loss=val_loss\n#         best_model=copy.deepcopy(ft_emb_lstm_model)\n    \n#     print(f'Текущий val loss: {val_loss}')\n    \n#     # Step the scheduler\n#     sched.step(val_loss)\n\n#     assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\"","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.468107Z","start_time":"2019-11-05T18:21:23.792092Z"},"execution":{"iopub.status.busy":"2024-08-11T09:35:18.316150Z","iopub.execute_input":"2024-08-11T09:35:18.316776Z","iopub.status.idle":"2024-08-11T09:38:04.183151Z","shell.execute_reply.started":"2024-08-11T09:35:18.316746Z","shell.execute_reply":"2024-08-11T09:38:04.181428Z"},"trusted":true},"execution_count":319,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stderr","text":"Train: Epoch 1/100: 100%|██████████| 255/255 [02:31<00:00,  1.68it/s]\nValidation: Epoch 1/100: 100%|██████████| 29/29 [00:06<00:00,  4.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Новый лучший val лосс: 1.1073151621325263\nТекущий val loss: 1.1073151621325263\n","output_type":"stream"},{"name":"stderr","text":"Train: Epoch 2/100:   4%|▍         | 11/255 [00:07<02:46,  1.47it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[319], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# train with backprop\u001b[39;00m\n\u001b[1;32m     25\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# visualizing training process\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# # Assume your trained model is wrapped in DataParallel\n# # trained_model = best_model\n# trained_model = ft_emb_lstm_model\n\n# # Check if the model is wrapped with DataParallel\n# if isinstance(trained_model, nn.DataParallel):\n#     # Extract the original model\n#     trained_model = trained_model.module","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:06.941695Z","iopub.execute_input":"2024-08-11T09:42:06.942064Z","iopub.status.idle":"2024-08-11T09:42:06.946749Z","shell.execute_reply.started":"2024-08-11T09:42:06.942036Z","shell.execute_reply":"2024-08-11T09:42:06.945837Z"},"trusted":true},"execution_count":335,"outputs":[]},{"cell_type":"code","source":"# trained_model_cpu=trained_model.cpu()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:07.950335Z","iopub.execute_input":"2024-08-11T09:42:07.950745Z","iopub.status.idle":"2024-08-11T09:42:07.956444Z","shell.execute_reply.started":"2024-08-11T09:42:07.950714Z","shell.execute_reply":"2024-08-11T09:42:07.955520Z"},"trusted":true},"execution_count":336,"outputs":[]},{"cell_type":"code","source":"# import os\n\n# newpath = 'models/task4_RNN_name_generator'\n# if not os.path.exists(newpath):\n#     os.makedirs(newpath)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.981093Z","iopub.status.idle":"2024-08-11T08:34:46.981481Z","shell.execute_reply.started":"2024-08-11T08:34:46.981271Z","shell.execute_reply":"2024-08-11T08:34:46.981285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle \n\n# with open('models/task4_RNN_name_generator/ngram_vocab_dict.pkl', 'wb+') as f:\n#     pickle.dump(NGRAM_VOCAB, f, protocol=pickle.HIGHEST_PROTOCOL)\n    \n# with open('models/task4_RNN_name_generator/char_vocab_dict.pkl', 'wb+') as f:\n#     pickle.dump(CHAR_VOCAB, f, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.982777Z","iopub.status.idle":"2024-08-11T08:34:46.983118Z","shell.execute_reply.started":"2024-08-11T08:34:46.982960Z","shell.execute_reply":"2024-08-11T08:34:46.982975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(trained_model_cpu.state_dict(), 'models/task4_RNN_name_generator/ft_emb_lstm_baseline.pth')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.984156Z","iopub.status.idle":"2024-08-11T08:34:46.984518Z","shell.execute_reply.started":"2024-08-11T08:34:46.984349Z","shell.execute_reply":"2024-08-11T08:34:46.984364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git add models/task4_RNN_name_generator","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.986743Z","iopub.status.idle":"2024-08-11T08:34:46.987104Z","shell.execute_reply.started":"2024-08-11T08:34:46.986933Z","shell.execute_reply":"2024-08-11T08:34:46.986947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git commit -m 'ft_emb_lstm_baseline'","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.988910Z","iopub.status.idle":"2024-08-11T08:34:46.989383Z","shell.execute_reply.started":"2024-08-11T08:34:46.989139Z","shell.execute_reply":"2024-08-11T08:34:46.989161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git push -u origin main","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.991091Z","iopub.status.idle":"2024-08-11T08:34:46.991521Z","shell.execute_reply.started":"2024-08-11T08:34:46.991297Z","shell.execute_reply":"2024-08-11T08:34:46.991315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:12.041080Z","iopub.execute_input":"2024-08-11T09:42:12.041718Z","iopub.status.idle":"2024-08-11T09:42:12.046097Z","shell.execute_reply.started":"2024-08-11T09:42:12.041685Z","shell.execute_reply":"2024-08-11T09:42:12.045081Z"},"trusted":true},"execution_count":337,"outputs":[]},{"cell_type":"code","source":"# model = trained_model_cpu\n# model.device=device\n# # model = FastTextEmbLSTMLoop(device, num_tokens=NUM_CHARS, emb_size=EMB_SIZE, hidden_size=256, num_layers=4)\n# # model.load_state_dict(torch.load('models/task4_RNN_name_generator/ft_emb_lstm_baseline.pth'))\n# model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:13.177812Z","iopub.execute_input":"2024-08-11T09:42:13.178204Z","iopub.status.idle":"2024-08-11T09:42:13.184827Z","shell.execute_reply.started":"2024-08-11T09:42:13.178177Z","shell.execute_reply":"2024-08-11T09:42:13.183909Z"},"trusted":true},"execution_count":338,"outputs":[{"execution_count":338,"output_type":"execute_result","data":{"text/plain":"FastTextEmbLSTMLoop(\n  (emb): Embedding(39160, 100)\n  (rnn): LSTM(100, 256, num_layers=4, batch_first=True, dropout=0.5)\n  (to_logits): Sequential(\n    (0): Linear(in_features=256, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=256, out_features=89, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# print(model.generate_sample(seed_phrase='Time passes ', temperature=1, quotes_train_dataset=quotes_train_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:14.648589Z","iopub.execute_input":"2024-08-11T09:42:14.649106Z","iopub.status.idle":"2024-08-11T09:42:14.774640Z","shell.execute_reply.started":"2024-08-11T09:42:14.649068Z","shell.execute_reply":"2024-08-11T09:42:14.773310Z"},"trusted":true},"execution_count":339,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[339], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_phrase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime passes \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquotes_train_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotes_train_dataset\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[328], line 115\u001b[0m, in \u001b[0;36mFastTextEmbLSTMLoop.generate_sample\u001b[0;34m(self, seed_phrase, temperature, max_length, quotes_train_dataset)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Convert seed_phrase to token IDs and n-grams\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     seed_phrase_tokenized \u001b[38;5;241m=\u001b[39m [quotes_train_dataset\u001b[38;5;241m.\u001b[39mutils_tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<BEGIN>\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m+\u001b[39mword_tokenize(seed_phrase)\n\u001b[0;32m--> 115\u001b[0m     x_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mquotes_train_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msent_to_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_phrase_tokenized\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Initialize hidden state\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     hid_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_state(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","Cell \u001b[0;32mIn[293], line 46\u001b[0m, in \u001b[0;36mNGramDataset.sent_to_ngrams\u001b[0;34m(self, sentence_tokenized)\u001b[0m\n\u001b[1;32m     44\u001b[0m new_ngrams \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutils_tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<BEGIN>\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence_tokenized:\n\u001b[0;32m---> 46\u001b[0m     new_ngrams\u001b[38;5;241m.\u001b[39mextend(\u001b[43mextract_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     47\u001b[0m     new_ngrams\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m new_ngrams\u001b[38;5;241m.\u001b[39mpop()  \u001b[38;5;66;03m# Удаляем последний пробел\u001b[39;00m\n","Cell \u001b[0;32mIn[198], line 5\u001b[0m, in \u001b[0;36mextract_ngrams\u001b[0;34m(word, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m ngrams \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate over possible start position of n-grams in the text\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m, n):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Ensure the size does not exceed the remaining length of the text\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m+\u001b[39m n \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(word):\n\u001b[1;32m      8\u001b[0m         ngram \u001b[38;5;241m=\u001b[39m word[start:start \u001b[38;5;241m+\u001b[39m n]\n","\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"],"ename":"TypeError","evalue":"object of type 'int' has no len()","output_type":"error"}]},{"cell_type":"markdown","source":"## Напишем генератор по словам и пунктуации","metadata":{}},{"cell_type":"code","source":"import fasttext\nimport fasttext.util\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport gc","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:51:14.154927Z","iopub.execute_input":"2024-08-11T09:51:14.155626Z","iopub.status.idle":"2024-08-11T09:51:14.160641Z","shell.execute_reply.started":"2024-08-11T09:51:14.155580Z","shell.execute_reply":"2024-08-11T09:51:14.159555Z"},"trusted":true},"execution_count":342,"outputs":[]},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:36.221343Z","iopub.execute_input":"2024-08-11T08:32:36.221714Z","iopub.status.idle":"2024-08-11T08:32:52.771416Z","shell.execute_reply.started":"2024-08-11T08:32:36.221688Z","shell.execute_reply":"2024-08-11T08:32:52.770448Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"--2024-08-11 08:32:37--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.162.163.11, 3.162.163.34, 3.162.163.19, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.162.163.11|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4503593528 (4.2G) [application/octet-stream]\nSaving to: 'cc.en.300.bin.gz'\n\ncc.en.300.bin.gz    100%[===================>]   4.19G   252MB/s    in 15s     \n\n2024-08-11 08:32:52 (280 MB/s) - 'cc.en.300.bin.gz' saved [4503593528/4503593528]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!gunzip cc.en.300.bin.gz","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:32:52.772956Z","iopub.execute_input":"2024-08-11T08:32:52.773311Z","iopub.status.idle":"2024-08-11T08:33:51.775918Z","shell.execute_reply.started":"2024-08-11T08:32:52.773280Z","shell.execute_reply":"2024-08-11T08:33:51.774657Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"ft = fasttext.load_model('cc.en.300.bin') \nft.get_dimension()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:21:25.559651Z","iopub.execute_input":"2024-08-11T10:21:25.560052Z","iopub.status.idle":"2024-08-11T10:21:59.525882Z","shell.execute_reply.started":"2024-08-11T10:21:25.560020Z","shell.execute_reply":"2024-08-11T10:21:59.524864Z"},"trusted":true},"execution_count":380,"outputs":[{"execution_count":380,"output_type":"execute_result","data":{"text/plain":"300"},"metadata":{}}]},{"cell_type":"markdown","source":"Понизим размерность","metadata":{}},{"cell_type":"code","source":"EMB_SIZE=128","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:21:59.527542Z","iopub.execute_input":"2024-08-11T10:21:59.527881Z","iopub.status.idle":"2024-08-11T10:21:59.547826Z","shell.execute_reply.started":"2024-08-11T10:21:59.527852Z","shell.execute_reply":"2024-08-11T10:21:59.546944Z"},"trusted":true},"execution_count":381,"outputs":[]},{"cell_type":"code","source":"fasttext.util.reduce_model(ft, EMB_SIZE)\nft.get_dimension()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:22:02.210420Z","iopub.execute_input":"2024-08-11T10:22:02.211345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Будем нашей моделью предсказывать следующее слова на основе предыдущих используя fasttext эмбеддинги","metadata":{}},{"cell_type":"markdown","source":"Весь текст токенизируем на слова и пунктуацию","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:52:07.520884Z","iopub.execute_input":"2024-08-11T09:52:07.521283Z","iopub.status.idle":"2024-08-11T09:52:07.525758Z","shell.execute_reply.started":"2024-08-11T09:52:07.521251Z","shell.execute_reply":"2024-08-11T09:52:07.524886Z"},"trusted":true},"execution_count":344,"outputs":[]},{"cell_type":"code","source":"quotes_tokenized = [word_tokenize(quote) for quote in quotes]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:52:08.577714Z","iopub.execute_input":"2024-08-11T09:52:08.578657Z","iopub.status.idle":"2024-08-11T09:52:20.655390Z","shell.execute_reply.started":"2024-08-11T09:52:08.578622Z","shell.execute_reply":"2024-08-11T09:52:20.654562Z"},"trusted":true},"execution_count":345,"outputs":[]},{"cell_type":"code","source":"quotes_tokenized[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:52:20.656751Z","iopub.execute_input":"2024-08-11T09:52:20.657114Z","iopub.status.idle":"2024-08-11T09:52:20.663179Z","shell.execute_reply.started":"2024-08-11T09:52:20.657088Z","shell.execute_reply":"2024-08-11T09:52:20.662198Z"},"trusted":true},"execution_count":346,"outputs":[{"execution_count":346,"output_type":"execute_result","data":{"text/plain":"['If',\n 'you',\n 'live',\n 'to',\n 'be',\n 'a',\n 'hundred',\n ',',\n 'I',\n 'want',\n 'to',\n 'live',\n 'to',\n 'be',\n 'a',\n 'hundred',\n 'minus',\n 'one',\n 'day',\n 'so',\n 'I',\n 'never',\n 'have',\n 'to',\n 'live',\n 'without',\n 'you',\n '.']"},"metadata":{}}]},{"cell_type":"markdown","source":"Будем использовать n-граммы различных размеров","metadata":{}},{"cell_type":"code","source":"import random\nfrom typing import List, Dict\n\nutils_tokens={'<PAD>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3}\n\ndef build_word_vocab(texts_tokenized):\n    \"\"\"\n    Строит словарь из списка списков токенов и вычисляет максимальную длину предложения.\n    \n    :param texts_tokenized: Список списков слов (токенов), где каждый внутренний список представляет собой токенизированный текст.\n    :return: Словарь, в котором каждому слову сопоставлен уникальный идентификатор, \n             обратный словарь для декодирования и максимальная длина предложения.\n    \"\"\"\n    # Создаем пустой словарь для хранения слов и их идентификаторов\n    word_to_id = {}\n    id_to_word = {}\n    \n    # Уникальный идентификатор для каждого слова\n    current_id = 0\n    \n    # Переменная для отслеживания максимальной длины предложения\n    max_sentence_length = 0\n    \n    # Перебираем каждый текст в списке\n    for text in texts_tokenized:\n        # Обновляем максимальную длину предложения\n        max_sentence_length = max(max_sentence_length, len(text))\n        \n        for word in text:\n            # Если слово еще не добавлено в словарь, добавляем его\n            if word not in word_to_id:\n                word_to_id[word] = current_id\n                id_to_word[current_id] = word\n                current_id += 1\n    \n    return word_to_id, id_to_word, max_sentence_length\n\nword_to_id, id_to_word, max_length = build_word_vocab(quotes_tokenized)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:54:05.330911Z","iopub.execute_input":"2024-08-11T09:54:05.331849Z","iopub.status.idle":"2024-08-11T09:54:05.490087Z","shell.execute_reply.started":"2024-08-11T09:54:05.331795Z","shell.execute_reply":"2024-08-11T09:54:05.489310Z"},"trusted":true},"execution_count":347,"outputs":[]},{"cell_type":"code","source":"len(word_to_id)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:54:27.263624Z","iopub.execute_input":"2024-08-11T09:54:27.264327Z","iopub.status.idle":"2024-08-11T09:54:27.270037Z","shell.execute_reply.started":"2024-08-11T09:54:27.264292Z","shell.execute_reply":"2024-08-11T09:54:27.269136Z"},"trusted":true},"execution_count":348,"outputs":[{"execution_count":348,"output_type":"execute_result","data":{"text/plain":"33435"},"metadata":{}}]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:54:47.376303Z","iopub.execute_input":"2024-08-11T09:54:47.377120Z","iopub.status.idle":"2024-08-11T09:54:47.381081Z","shell.execute_reply.started":"2024-08-11T09:54:47.377087Z","shell.execute_reply":"2024-08-11T09:54:47.380066Z"},"trusted":true},"execution_count":349,"outputs":[]},{"cell_type":"code","source":"# word_to_id={}\n# with open('models/task4_RNN_name_generator/word_to_id_dict.pkl', 'rb') as f:\n#     word_to_id=pickle.load(f)\n\n# NUM_CHARS = len(CHAR_VOCAB)\n# NUM_CHARS","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:08:21.919814Z","iopub.execute_input":"2024-08-11T09:08:21.920528Z","iopub.status.idle":"2024-08-11T09:08:21.924468Z","shell.execute_reply.started":"2024-08-11T09:08:21.920496Z","shell.execute_reply":"2024-08-11T09:08:21.923476Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"# Create an embedding matrix for words\ndef create_word_embedding_matrix(word_to_id, ft):\n    emb_size = ft.get_dimension()\n    embedding_matrix = torch.zeros((len(word_to_id), emb_size))\n    for word, idx in word_to_id.items():\n        embedding_matrix[idx] = torch.tensor(ft.get_word_vector(word))\n    return embedding_matrix\n\n# Generate embedding matrix\nEMBEDDING_MATRIX = create_word_embedding_matrix(word_to_id, ft)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:58:00.412889Z","iopub.execute_input":"2024-08-11T09:58:00.413261Z","iopub.status.idle":"2024-08-11T09:58:01.434556Z","shell.execute_reply.started":"2024-08-11T09:58:00.413225Z","shell.execute_reply":"2024-08-11T09:58:01.433518Z"},"trusted":true},"execution_count":351,"outputs":[]},{"cell_type":"code","source":"EMBEDDING_MATRIX.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:58:06.443029Z","iopub.execute_input":"2024-08-11T09:58:06.446194Z","iopub.status.idle":"2024-08-11T09:58:06.455211Z","shell.execute_reply.started":"2024-08-11T09:58:06.446149Z","shell.execute_reply":"2024-08-11T09:58:06.453998Z"},"trusted":true},"execution_count":352,"outputs":[{"execution_count":352,"output_type":"execute_result","data":{"text/plain":"torch.Size([33435, 300])"},"metadata":{}}]},{"cell_type":"markdown","source":"Напишим класс датасета","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:58:43.027281Z","iopub.execute_input":"2024-08-11T09:58:43.027668Z","iopub.status.idle":"2024-08-11T09:58:43.031979Z","shell.execute_reply.started":"2024-08-11T09:58:43.027636Z","shell.execute_reply":"2024-08-11T09:58:43.031072Z"},"trusted":true},"execution_count":353,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass WordsDataset(Dataset):\n    def __init__(self, tokenized_texts, word_to_id, max_len, utils_tokens):\n        \"\"\"\n        Args:\n            tokenized_texts (list of list of str): Список списков слов, представляющих тексты.\n            word_to_id (dict): Словарь, сопоставляющий слова с их индексами.\n        \"\"\"\n        self.tokenized_texts = tokenized_texts.copy()\n        self.word_to_id = word_to_id.copy()\n        self.id_to_word = {val: key for key, val in self.word_to_id.items()}\n        self.max_len = max_len\n        self.utils_tokens = utils_tokens.copy()\n\n    def __len__(self):\n        return len(self.tokenized_texts)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Args:\n            idx (int): Индекс выборки.\n        \n        Returns:\n            dict: Словарь с ключами 'input' и 'length', где 'input' - это тензор с закодированным предложением,\n                  а 'length' - длина предложения.\n        \"\"\"\n        return transform_text(self.tokenized_texts[idx])\n    \n    def transform_text(self, sentence):\n        encoded_sentence = [self.utils_tokens.get('<BEGIN>')]+[self.word_to_id.get(word, self.utils_tokens.get('<UNK>')) for word in sentence]+[self.utils_tokens.get('<END>')]\n        \n        # Создание тензора с индексами слов и дополнение до max_len\n        padded_sentence = encoded_sentence + [self.utils_tokens.get('<PAD>')] * (self.max_len - len(encoded_sentence))\n        return torch.tensor(padded_sentence, dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:19:40.668456Z","iopub.execute_input":"2024-08-11T10:19:40.668856Z","iopub.status.idle":"2024-08-11T10:19:40.679668Z","shell.execute_reply.started":"2024-08-11T10:19:40.668814Z","shell.execute_reply":"2024-08-11T10:19:40.678832Z"},"trusted":true},"execution_count":374,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:10:15.003928Z","iopub.execute_input":"2024-08-11T10:10:15.004325Z","iopub.status.idle":"2024-08-11T10:10:15.008651Z","shell.execute_reply.started":"2024-08-11T10:10:15.004295Z","shell.execute_reply":"2024-08-11T10:10:15.007757Z"},"trusted":true},"execution_count":369,"outputs":[]},{"cell_type":"code","source":"X_train, X_test = train_test_split(quotes_tokenized, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:10:15.644083Z","iopub.execute_input":"2024-08-11T10:10:15.645085Z","iopub.status.idle":"2024-08-11T10:10:15.661522Z","shell.execute_reply.started":"2024-08-11T10:10:15.645047Z","shell.execute_reply":"2024-08-11T10:10:15.660555Z"},"trusted":true},"execution_count":370,"outputs":[]},{"cell_type":"code","source":"quotes_train_dataset = WordsDataset(X_train, word_to_id, max_length, utils_tokens)\nquotes_val_dataset = WordsDataset(X_train, word_to_id, max_length, utils_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:10:16.232381Z","iopub.execute_input":"2024-08-11T10:10:16.232741Z","iopub.status.idle":"2024-08-11T10:10:16.253852Z","shell.execute_reply.started":"2024-08-11T10:10:16.232709Z","shell.execute_reply":"2024-08-11T10:10:16.252894Z"},"trusted":true},"execution_count":371,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:10:16.884006Z","iopub.execute_input":"2024-08-11T10:10:16.884417Z","iopub.status.idle":"2024-08-11T10:10:16.889900Z","shell.execute_reply.started":"2024-08-11T10:10:16.884386Z","shell.execute_reply":"2024-08-11T10:10:16.888912Z"},"trusted":true},"execution_count":372,"outputs":[]},{"cell_type":"code","source":"num_words = len(word_to_id)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:10:17.659714Z","iopub.execute_input":"2024-08-11T10:10:17.660680Z","iopub.status.idle":"2024-08-11T10:10:17.665010Z","shell.execute_reply.started":"2024-08-11T10:10:17.660642Z","shell.execute_reply":"2024-08-11T10:10:17.663836Z"},"trusted":true},"execution_count":373,"outputs":[]},{"cell_type":"code","source":"class FastTextEmbLSTMLoop(nn.Module):\n    def __init__(self, device='cpu', num_tokens=num_words, num_embs=num_words, emb_size=EMB_SIZE, hidden_size=128, num_layers=2, embedding_matrix=None):\n        super(FastTextEmbLSTMLoop, self).__init__()\n        self.device = device\n        self.num_embs = num_embs\n        self.num_tokens = num_tokens\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        \n        # Initialize n-gram embedding layer\n        self.emb = nn.Embedding(num_embs, emb_size)\n        if embedding_matrix is not None:\n            assert emb_size == embedding_matrix.shape[1]\n            self.emb.weight.data.copy_(embedding_matrix)\n            self.emb.weight.requires_grad = True  # Optional: set to True if you want to fine-tune embeddings\n        \n        # RNN and Linear layers\n        self.rnn = nn.LSTM(input_size=emb_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=0.5)\n        \n        self.to_logits = nn.Sequential(\n            nn.Linear(self.hidden_size, self.hidden_size),  # First hidden layer\n            nn.ReLU(),  # Activation function\n            nn.Dropout(0.5),  # Dropout for regularization\n            nn.Linear(self.hidden_size, self.num_tokens),  # Second hidden layer\n        )\n        \n    def forward(self, tensor):\n        combined_logits, hidden_state = self.forward_hidden(tensor)\n        return combined_logits\n    \n    def forward_hidden(self, tensor, hidden_state=None):\n        batch_size, seq_len = ngram_tensor.size()\n        \n        # Initialize hidden state for the batch if not provided\n        if hidden_state is None:\n            hidden_state = self.initial_state(batch_size)\n        \n            \n        # Apply embedding layer\n        x_embedded = self.emb(tensor)\n            \n        # Use forward_hidden_util to get logits and update hidden state\n        curr_logits, curr_hidden_state = self.forward_hidden_util(x_embedded, hidden_state)\n        \n        return curr_logits, curr_hidden_state\n\n    def forward_hidden_util(self, x_embedded, hidden_state=None):\n        \"\"\"\n        Process a batch of sequences and update the hidden state.\n        \n        :param x: A tensor containing the sequences.\n        :param hidden_state: Tuple (h_0, c_0) containing the hidden state of the LSTM.\n        :return: next_logp (log probabilities of the next token), hidden_state (updated hidden state).\n        \"\"\"\n        if hidden_state is None:\n            hidden_state = self.initial_state(x_embedded.size(0))\n        \n        # RNN forward pass\n        h_seq, hidden_state = self.rnn(x_embedded, hidden_state)\n        \n        # Compute logits from the last hidden state of each sequence\n        next_logits = self.to_logits(h_seq)  # Use the sequence's hidden states\n        \n        return next_logits, hidden_state\n\n    def initial_state(self, batch_size):\n        \"\"\"Return RNN state before it processes the first input (aka h0)\"\"\"\n        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n        return (h_0, c_0)\n\n    def generate_sample(self, seed_phrase=' ', temperature=1.0, max_length=100, quotes_train_dataset=None):\n        '''\n        Generate text starting with a given seed phrase using the RNN model.\n\n        :param seed_phrase: The initial phrase to start text generation.\n        :param temperature: Coefficient to adjust the probability distribution. Higher temperature means more randomness.\n        :param max_length: Maximum length of the generated text (including seed_phrase).\n        :param quotes_train_dataset: The dataset containing token-to-id mappings and id-to-token mappings.\n        :return: Generated text.\n        '''\n        with torch.no_grad():\n\n            # Convert seed_phrase to token IDs and n-grams\n            seed_phrase_tokenized = word_tokenize(seed_phrase)\n            x_sequence = quotes_train_dataset.transform_text(seed_phrase_tokenized).unsqueeze(0)\n\n            # Initialize hidden state\n            hid_state = self.initial_state(batch_size=1)\n\n            # If seed_phrase is not just a space, update hidden state based on the seed_phrase\n            if seed_phrase.strip() != '':\n                _, hid_state = self.forward_hidden(x_sequence, hid_state)\n\n            # Start generating text\n            generated_sequence = list(seed_phrase)\n\n            # Convert the seed_phrase to its last token ID for the generation loop\n            # Get the last n-gram slice from x_sequence\n            current_ngram_tensor = x_sequence[:, -1, :].unsqueeze(1)  # Shape: [1, num_ngram_types, seq_len]\n\n            for i in range(max_length - len(seed_phrase)):\n                # Get logits and update hidden state\n                next_logits, hid_state = self.forward_hidden(current_ngram_tensor, hid_state)\n#                 print(next_logits.squeeze(0).shape)\n                \n                # Apply temperature to logits for scaling\n                next_logits = next_logits / temperature\n\n                # Convert logits to probabilities\n                p_next = F.softmax(next_logits.squeeze(0), dim=-1).cpu().numpy()\n                \n                # Sample the next token index based on the probability distribution\n                next_ix = np.random.choice(len(quotes_train_dataset.word_to_id), p=p_next[i, :])\n\n                # Decode the next token ID to a character\n                next_char = char_vocab_reversed[next_ix]\n\n                # Append the new character to the generated sequence\n                generated_sequence.append(next_char)\n\n                # Update current_ngram_tensor with the new character\n                current_ngram_tensor = quotes_train_dataset.transform_text(generated_sequence).unsqueeze(0)\n\n            return ''.join(generated_sequence)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:20:12.388775Z","iopub.execute_input":"2024-08-11T10:20:12.389172Z","iopub.status.idle":"2024-08-11T10:20:12.413893Z","shell.execute_reply.started":"2024-08-11T10:20:12.389142Z","shell.execute_reply":"2024-08-11T10:20:12.412892Z"},"trusted":true},"execution_count":375,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:20:13.915890Z","iopub.execute_input":"2024-08-11T10:20:13.916234Z","iopub.status.idle":"2024-08-11T10:20:13.920465Z","shell.execute_reply.started":"2024-08-11T10:20:13.916208Z","shell.execute_reply":"2024-08-11T10:20:13.919503Z"},"trusted":true},"execution_count":376,"outputs":[]},{"cell_type":"code","source":"num_gpus = torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:20:14.646194Z","iopub.execute_input":"2024-08-11T10:20:14.646800Z","iopub.status.idle":"2024-08-11T10:20:14.651236Z","shell.execute_reply.started":"2024-08-11T10:20:14.646768Z","shell.execute_reply":"2024-08-11T10:20:14.650233Z"},"trusted":true},"execution_count":377,"outputs":[]},{"cell_type":"code","source":"quotes_train_dataloader = DataLoader(\n    quotes_train_dataset, \n    batch_size=128, \n    shuffle=True, \n    num_workers=2 * num_gpus,  # 2 workers per GPU (adjust based on performance)\n    pin_memory=True\n)\n\nquotes_val_dataloader = DataLoader(\n    quotes_val_dataset, \n    batch_size=128, \n    num_workers=2 * num_gpus,  # 2 workers per GPU (adjust based on performance)\n    pin_memory=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:20:16.116037Z","iopub.execute_input":"2024-08-11T10:20:16.116401Z","iopub.status.idle":"2024-08-11T10:20:16.122669Z","shell.execute_reply.started":"2024-08-11T10:20:16.116372Z","shell.execute_reply":"2024-08-11T10:20:16.121643Z"},"trusted":true},"execution_count":378,"outputs":[]},{"cell_type":"code","source":"EMBEDDING_MATRIX.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T10:20:17.033272Z","iopub.execute_input":"2024-08-11T10:20:17.033628Z","iopub.status.idle":"2024-08-11T10:20:17.039707Z","shell.execute_reply.started":"2024-08-11T10:20:17.033600Z","shell.execute_reply":"2024-08-11T10:20:17.038797Z"},"trusted":true},"execution_count":379,"outputs":[{"execution_count":379,"output_type":"execute_result","data":{"text/plain":"torch.Size([33435, 300])"},"metadata":{}}]},{"cell_type":"code","source":"ft_emb_lstm_model = FastTextEmbLSTMLoop(device, num_tokens=num_words, num_embs=num_words, emb_size=EMB_SIZE, hidden_size=128, num_layers=10, embedding_matrix=EMBEDDING_MATRIX)\n\nopt = torch.optim.Adam(ft_emb_lstm_model.parameters(), lr=1e-4)\nsched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.4, patience=2)\ncriterion = nn.CrossEntropyLoss()\n\nhistory=[]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:53.372309Z","iopub.execute_input":"2024-08-11T09:41:53.372678Z","iopub.status.idle":"2024-08-11T09:41:53.443124Z","shell.execute_reply.started":"2024-08-11T09:41:53.372647Z","shell.execute_reply":"2024-08-11T09:41:53.442384Z"},"trusted":true},"execution_count":333,"outputs":[]},{"cell_type":"code","source":"# Move model to the first GPU device\nft_emb_lstm_model = ft_emb_lstm_model.to(device)\n\n# Use DataParallel to utilize multiple GPUs\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    ft_emb_lstm_model = nn.DataParallel(ft_emb_lstm_model)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:41:57.354886Z","iopub.execute_input":"2024-08-11T09:41:57.355570Z","iopub.status.idle":"2024-08-11T09:41:57.362994Z","shell.execute_reply.started":"2024-08-11T09:41:57.355538Z","shell.execute_reply":"2024-08-11T09:41:57.362098Z"},"trusted":true},"execution_count":334,"outputs":[{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Теперь для подсчета лосса мне нужно разобрать каждое предложение на n-граммы","metadata":{}},{"cell_type":"code","source":"batch_ix, batch_iy = next(iter(quotes_train_dataloader))","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.790047Z","start_time":"2019-11-05T18:21:23.715167Z"},"execution":{"iopub.status.busy":"2024-08-11T09:35:01.367675Z","iopub.execute_input":"2024-08-11T09:35:01.368451Z","iopub.status.idle":"2024-08-11T09:35:01.981579Z","shell.execute_reply.started":"2024-08-11T09:35:01.368418Z","shell.execute_reply":"2024-08-11T09:35:01.980209Z"},"trusted":true},"execution_count":306,"outputs":[]},{"cell_type":"code","source":"batch_ix.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:02.478124Z","iopub.execute_input":"2024-08-11T09:35:02.478513Z","iopub.status.idle":"2024-08-11T09:35:02.485452Z","shell.execute_reply.started":"2024-08-11T09:35:02.478483Z","shell.execute_reply":"2024-08-11T09:35:02.484394Z"},"trusted":true},"execution_count":307,"outputs":[{"execution_count":307,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 4, 423])"},"metadata":{}}]},{"cell_type":"code","source":"MAX_LEN","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:03.533988Z","iopub.execute_input":"2024-08-11T09:35:03.534761Z","iopub.status.idle":"2024-08-11T09:35:03.540493Z","shell.execute_reply.started":"2024-08-11T09:35:03.534731Z","shell.execute_reply":"2024-08-11T09:35:03.539565Z"},"trusted":true},"execution_count":308,"outputs":[{"execution_count":308,"output_type":"execute_result","data":{"text/plain":"423"},"metadata":{}}]},{"cell_type":"code","source":"batch_iy.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:04.517424Z","iopub.execute_input":"2024-08-11T09:35:04.518108Z","iopub.status.idle":"2024-08-11T09:35:04.523819Z","shell.execute_reply.started":"2024-08-11T09:35:04.518075Z","shell.execute_reply":"2024-08-11T09:35:04.522806Z"},"trusted":true},"execution_count":309,"outputs":[{"execution_count":309,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 423])"},"metadata":{}}]},{"cell_type":"code","source":"batch_ix.device","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:05.604588Z","iopub.execute_input":"2024-08-11T09:35:05.604965Z","iopub.status.idle":"2024-08-11T09:35:05.610864Z","shell.execute_reply.started":"2024-08-11T09:35:05.604935Z","shell.execute_reply":"2024-08-11T09:35:05.610006Z"},"trusted":true},"execution_count":310,"outputs":[{"execution_count":310,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"curr_batch_ix=batch_ix.to(device)\ncurr_batch_iy=batch_iy.to(device)\n\nlogp_seq = ft_emb_lstm_model(curr_batch_ix)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:06.685003Z","iopub.execute_input":"2024-08-11T09:35:06.685929Z","iopub.status.idle":"2024-08-11T09:35:06.941646Z","shell.execute_reply.started":"2024-08-11T09:35:06.685882Z","shell.execute_reply":"2024-08-11T09:35:06.940858Z"},"trusted":true},"execution_count":311,"outputs":[]},{"cell_type":"code","source":"logp_seq.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:07.944753Z","iopub.execute_input":"2024-08-11T09:35:07.945147Z","iopub.status.idle":"2024-08-11T09:35:07.951207Z","shell.execute_reply.started":"2024-08-11T09:35:07.945116Z","shell.execute_reply":"2024-08-11T09:35:07.950291Z"},"trusted":true},"execution_count":312,"outputs":[{"execution_count":312,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 423, 89])"},"metadata":{}}]},{"cell_type":"code","source":"# compute loss\npredictions_logp = logp_seq[:, :-1]\ncurr_batch_iy = curr_batch_iy[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:08.998540Z","iopub.execute_input":"2024-08-11T09:35:08.999262Z","iopub.status.idle":"2024-08-11T09:35:09.004921Z","shell.execute_reply.started":"2024-08-11T09:35:08.999211Z","shell.execute_reply":"2024-08-11T09:35:09.003795Z"},"trusted":true},"execution_count":313,"outputs":[]},{"cell_type":"code","source":"predictions_logp.shape, curr_batch_iy.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:10.239290Z","iopub.execute_input":"2024-08-11T09:35:10.239987Z","iopub.status.idle":"2024-08-11T09:35:10.245831Z","shell.execute_reply.started":"2024-08-11T09:35:10.239955Z","shell.execute_reply":"2024-08-11T09:35:10.245001Z"},"trusted":true},"execution_count":314,"outputs":[{"execution_count":314,"output_type":"execute_result","data":{"text/plain":"(torch.Size([128, 422, 89]), torch.Size([128, 422]))"},"metadata":{}}]},{"cell_type":"code","source":"loss = criterion(predictions_logp.permute(0,2,1), curr_batch_iy)\n\nloss.backward()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:11.347241Z","iopub.execute_input":"2024-08-11T09:35:11.347628Z","iopub.status.idle":"2024-08-11T09:35:11.675048Z","shell.execute_reply.started":"2024-08-11T09:35:11.347598Z","shell.execute_reply":"2024-08-11T09:35:11.674066Z"},"trusted":true},"execution_count":315,"outputs":[]},{"cell_type":"code","source":"from IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:14.603317Z","iopub.execute_input":"2024-08-11T09:35:14.603685Z","iopub.status.idle":"2024-08-11T09:35:14.608471Z","shell.execute_reply.started":"2024-08-11T09:35:14.603657Z","shell.execute_reply":"2024-08-11T09:35:14.607486Z"},"trusted":true},"execution_count":316,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:15.782739Z","iopub.execute_input":"2024-08-11T09:35:15.783598Z","iopub.status.idle":"2024-08-11T09:35:15.787659Z","shell.execute_reply.started":"2024-08-11T09:35:15.783564Z","shell.execute_reply":"2024-08-11T09:35:15.786559Z"},"trusted":true},"execution_count":317,"outputs":[]},{"cell_type":"code","source":"import copy","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:35:16.977803Z","iopub.execute_input":"2024-08-11T09:35:16.978523Z","iopub.status.idle":"2024-08-11T09:35:16.983269Z","shell.execute_reply.started":"2024-08-11T09:35:16.978491Z","shell.execute_reply":"2024-08-11T09:35:16.982219Z"},"trusted":true},"execution_count":318,"outputs":[]},{"cell_type":"code","source":"num_epochs=100\nbest_model=None\nbest_loss=float('inf')\nfor epoch in range(num_epochs):\n    ft_emb_lstm_model.train()\n    total_batches = len(quotes_train_dataloader)\n\n    # Wrap DataLoader iterator with tqdm\n    for i, (batch_ix, batch_iy) in enumerate(tqdm(quotes_train_dataloader, desc=f\"Train: Epoch {epoch+1}/{num_epochs}\", total=total_batches)):\n\n#         batch_ix = to_matrix(sample(quotes, 32), token_to_id, max_len=MAX_LENGTH)\n#         batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n        curr_batch_ix=batch_ix.to(device)\n        curr_batch_iy=batch_iy.to(device)\n\n        logp_seq = ft_emb_lstm_model(curr_batch_ix)\n\n        # compute loss\n        predictions_logp = logp_seq[:, :-1]\n        actual_next_tokens = curr_batch_iy[:, 1:]\n\n        loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n\n        # train with backprop\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n        # visualizing training process\n        history.append(loss.cpu().data.numpy())\n        if (i + 1) % 25 == 0:\n            clear_output(True)\n            plt.plot(history,label='loss')\n            plt.legend()\n            plt.show()\n    \n    # Validate the model and calculate the metric\n    ft_emb_lstm_model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for (batch_ix, batch_iy) in tqdm(quotes_val_dataloader, desc=f\"Validation: Epoch {epoch+1}/{num_epochs}\", total=len(quotes_val_dataloader)):\n            curr_batch_ix=batch_ix.to(device)\n            curr_batch_iy=batch_iy.to(device)\n\n            logp_seq = ft_emb_lstm_model(curr_batch_ix)\n\n            # compute loss\n            predictions_logp = logp_seq[:, :-1]\n            actual_next_tokens = curr_batch_iy[:, 1:]\n\n            loss = criterion(predictions_logp.permute(0,2,1), actual_next_tokens)\n            val_loss += loss.item()\n\n    val_loss /= len(quotes_val_dataloader)\n    \n    if val_loss<best_loss:\n        print(f'Новый лучший val лосс: {val_loss}')\n        best_loss=val_loss\n        best_model=copy.deepcopy(ft_emb_lstm_model)\n    \n    print(f'Текущий val loss: {val_loss}')\n    \n    # Step the scheduler\n    sched.step(val_loss)\n\n    assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\"","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.468107Z","start_time":"2019-11-05T18:21:23.792092Z"},"execution":{"iopub.status.busy":"2024-08-11T09:35:18.316150Z","iopub.execute_input":"2024-08-11T09:35:18.316776Z","iopub.status.idle":"2024-08-11T09:38:04.183151Z","shell.execute_reply.started":"2024-08-11T09:35:18.316746Z","shell.execute_reply":"2024-08-11T09:38:04.181428Z"},"trusted":true},"execution_count":319,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stderr","text":"Train: Epoch 1/100: 100%|██████████| 255/255 [02:31<00:00,  1.68it/s]\nValidation: Epoch 1/100: 100%|██████████| 29/29 [00:06<00:00,  4.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Новый лучший val лосс: 1.1073151621325263\nТекущий val loss: 1.1073151621325263\n","output_type":"stream"},{"name":"stderr","text":"Train: Epoch 2/100:   4%|▍         | 11/255 [00:07<02:46,  1.47it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[319], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# train with backprop\u001b[39;00m\n\u001b[1;32m     25\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# visualizing training process\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Assume your trained model is wrapped in DataParallel\n# trained_model = best_model\ntrained_model = ft_emb_lstm_model\n\n# Check if the model is wrapped with DataParallel\nif isinstance(trained_model, nn.DataParallel):\n    # Extract the original model\n    trained_model = trained_model.module","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:06.941695Z","iopub.execute_input":"2024-08-11T09:42:06.942064Z","iopub.status.idle":"2024-08-11T09:42:06.946749Z","shell.execute_reply.started":"2024-08-11T09:42:06.942036Z","shell.execute_reply":"2024-08-11T09:42:06.945837Z"},"trusted":true},"execution_count":335,"outputs":[]},{"cell_type":"code","source":"trained_model_cpu=trained_model.cpu()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:07.950335Z","iopub.execute_input":"2024-08-11T09:42:07.950745Z","iopub.status.idle":"2024-08-11T09:42:07.956444Z","shell.execute_reply.started":"2024-08-11T09:42:07.950714Z","shell.execute_reply":"2024-08-11T09:42:07.955520Z"},"trusted":true},"execution_count":336,"outputs":[]},{"cell_type":"code","source":"import os\n\nnewpath = 'models/task4_RNN_name_generator'\nif not os.path.exists(newpath):\n    os.makedirs(newpath)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.981093Z","iopub.status.idle":"2024-08-11T08:34:46.981481Z","shell.execute_reply.started":"2024-08-11T08:34:46.981271Z","shell.execute_reply":"2024-08-11T08:34:46.981285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle \n\n# with open('models/task4_RNN_name_generator/ngram_vocab_dict.pkl', 'wb+') as f:\n#     pickle.dump(NGRAM_VOCAB, f, protocol=pickle.HIGHEST_PROTOCOL)\n    \n# with open('models/task4_RNN_name_generator/char_vocab_dict.pkl', 'wb+') as f:\n#     pickle.dump(CHAR_VOCAB, f, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.982777Z","iopub.status.idle":"2024-08-11T08:34:46.983118Z","shell.execute_reply.started":"2024-08-11T08:34:46.982960Z","shell.execute_reply":"2024-08-11T08:34:46.982975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(trained_model_cpu.state_dict(), 'models/task4_RNN_name_generator/ft_emb_lstm_baseline.pth')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.984156Z","iopub.status.idle":"2024-08-11T08:34:46.984518Z","shell.execute_reply.started":"2024-08-11T08:34:46.984349Z","shell.execute_reply":"2024-08-11T08:34:46.984364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git add models/task4_RNN_name_generator","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.986743Z","iopub.status.idle":"2024-08-11T08:34:46.987104Z","shell.execute_reply.started":"2024-08-11T08:34:46.986933Z","shell.execute_reply":"2024-08-11T08:34:46.986947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git commit -m 'ft_emb_lstm_baseline'","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.988910Z","iopub.status.idle":"2024-08-11T08:34:46.989383Z","shell.execute_reply.started":"2024-08-11T08:34:46.989139Z","shell.execute_reply":"2024-08-11T08:34:46.989161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git push -u origin main","metadata":{"execution":{"iopub.status.busy":"2024-08-11T08:34:46.991091Z","iopub.status.idle":"2024-08-11T08:34:46.991521Z","shell.execute_reply.started":"2024-08-11T08:34:46.991297Z","shell.execute_reply":"2024-08-11T08:34:46.991315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:12.041080Z","iopub.execute_input":"2024-08-11T09:42:12.041718Z","iopub.status.idle":"2024-08-11T09:42:12.046097Z","shell.execute_reply.started":"2024-08-11T09:42:12.041685Z","shell.execute_reply":"2024-08-11T09:42:12.045081Z"},"trusted":true},"execution_count":337,"outputs":[]},{"cell_type":"code","source":"model = trained_model_cpu\nmodel.device=device\n# model = FastTextEmbLSTMLoop(device, num_tokens=NUM_CHARS, emb_size=EMB_SIZE, hidden_size=256, num_layers=4)\n# model.load_state_dict(torch.load('models/task4_RNN_name_generator/ft_emb_lstm_baseline.pth'))\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:13.177812Z","iopub.execute_input":"2024-08-11T09:42:13.178204Z","iopub.status.idle":"2024-08-11T09:42:13.184827Z","shell.execute_reply.started":"2024-08-11T09:42:13.178177Z","shell.execute_reply":"2024-08-11T09:42:13.183909Z"},"trusted":true},"execution_count":338,"outputs":[{"execution_count":338,"output_type":"execute_result","data":{"text/plain":"FastTextEmbLSTMLoop(\n  (emb): Embedding(39160, 100)\n  (rnn): LSTM(100, 256, num_layers=4, batch_first=True, dropout=0.5)\n  (to_logits): Sequential(\n    (0): Linear(in_features=256, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=256, out_features=89, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"print(model.generate_sample(seed_phrase='Time passes ', temperature=1, quotes_train_dataset=quotes_train_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:42:14.648589Z","iopub.execute_input":"2024-08-11T09:42:14.649106Z","iopub.status.idle":"2024-08-11T09:42:14.774640Z","shell.execute_reply.started":"2024-08-11T09:42:14.649068Z","shell.execute_reply":"2024-08-11T09:42:14.773310Z"},"trusted":true},"execution_count":339,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[339], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_phrase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime passes \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquotes_train_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotes_train_dataset\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[328], line 115\u001b[0m, in \u001b[0;36mFastTextEmbLSTMLoop.generate_sample\u001b[0;34m(self, seed_phrase, temperature, max_length, quotes_train_dataset)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Convert seed_phrase to token IDs and n-grams\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     seed_phrase_tokenized \u001b[38;5;241m=\u001b[39m [quotes_train_dataset\u001b[38;5;241m.\u001b[39mutils_tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<BEGIN>\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m+\u001b[39mword_tokenize(seed_phrase)\n\u001b[0;32m--> 115\u001b[0m     x_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mquotes_train_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msent_to_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_phrase_tokenized\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Initialize hidden state\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     hid_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_state(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","Cell \u001b[0;32mIn[293], line 46\u001b[0m, in \u001b[0;36mNGramDataset.sent_to_ngrams\u001b[0;34m(self, sentence_tokenized)\u001b[0m\n\u001b[1;32m     44\u001b[0m new_ngrams \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutils_tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<BEGIN>\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence_tokenized:\n\u001b[0;32m---> 46\u001b[0m     new_ngrams\u001b[38;5;241m.\u001b[39mextend(\u001b[43mextract_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     47\u001b[0m     new_ngrams\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m new_ngrams\u001b[38;5;241m.\u001b[39mpop()  \u001b[38;5;66;03m# Удаляем последний пробел\u001b[39;00m\n","Cell \u001b[0;32mIn[198], line 5\u001b[0m, in \u001b[0;36mextract_ngrams\u001b[0;34m(word, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m ngrams \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate over possible start position of n-grams in the text\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m, n):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Ensure the size does not exceed the remaining length of the text\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m+\u001b[39m n \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(word):\n\u001b[1;32m      8\u001b[0m         ngram \u001b[38;5;241m=\u001b[39m word[start:start \u001b[38;5;241m+\u001b[39m n]\n","\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"],"ename":"TypeError","evalue":"object of type 'int' has no len()","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}